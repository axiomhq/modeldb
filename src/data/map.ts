import type { Model } from '../schema';

export const modelsMap: Record<string, Model> = {
  "j2-light": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000003,
    "model_id": "j2-light",
    "model_name": "J2 Light",
    "provider_id": "ai21",
    "provider_name": "AI21 Labs",
    "input_cost_per_million": 3,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "j2-mid": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00001,
    "model_id": "j2-mid",
    "model_name": "J2 Mid",
    "provider_id": "ai21",
    "provider_name": "AI21 Labs",
    "input_cost_per_million": 10,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "j2-ultra": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "model_id": "j2-ultra",
    "model_name": "J2 Ultra",
    "provider_id": "ai21",
    "provider_name": "AI21 Labs",
    "input_cost_per_million": 15,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "jamba-large-1.6": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.000008,
    "supports_tool_choice": true,
    "model_id": "jamba-large-1.6",
    "model_name": "Jamba Large 1.6",
    "provider_id": "ai21",
    "provider_name": "AI21 Labs",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "jamba-large-1.7": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.000008,
    "supports_tool_choice": true,
    "model_id": "jamba-large-1.7",
    "model_name": "Jamba Large 1.7",
    "provider_id": "ai21",
    "provider_name": "AI21 Labs",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "jamba-mini-1.6": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 4e-7,
    "supports_tool_choice": true,
    "model_id": "jamba-mini-1.6",
    "model_name": "Jamba Mini 1.6",
    "provider_id": "ai21",
    "provider_name": "AI21 Labs",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "jamba-mini-1.7": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 4e-7,
    "supports_tool_choice": true,
    "model_id": "jamba-mini-1.7",
    "model_name": "Jamba Mini 1.7",
    "provider_id": "ai21",
    "provider_name": "AI21 Labs",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "aiml/dall-e-2": {
    "metadata": {
      "notes": "DALL-E 2 via AI/ML API - Reliable text-to-image generation"
    },
    "output_cost_per_image": 0.021,
    "source": "https://docs.aimlapi.com/",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "aiml/dall-e-2",
    "model_name": "Dall E 2",
    "provider_id": "aiml",
    "provider_name": "Aiml",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "aiml/dall-e-3": {
    "metadata": {
      "notes": "DALL-E 3 via AI/ML API - High-quality text-to-image generation"
    },
    "output_cost_per_image": 0.042,
    "source": "https://docs.aimlapi.com/",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "aiml/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "aiml",
    "provider_name": "Aiml",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "aiml/flux-pro": {
    "metadata": {
      "notes": "Flux Dev - Development version optimized for experimentation"
    },
    "output_cost_per_image": 0.053,
    "source": "https://docs.aimlapi.com/",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "aiml/flux-pro",
    "model_name": "Flux Pro",
    "provider_id": "aiml",
    "provider_name": "Aiml",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "aiml/flux-pro/v1.1": {
    "output_cost_per_image": 0.042,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "aiml/flux-pro/v1.1",
    "model_name": "V1.1",
    "provider_id": "aiml",
    "provider_name": "Aiml",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "aiml/flux-pro/v1.1-ultra": {
    "output_cost_per_image": 0.063,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "aiml/flux-pro/v1.1-ultra",
    "model_name": "V1.1 Ultra",
    "provider_id": "aiml",
    "provider_name": "Aiml",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "aiml/flux-realism": {
    "metadata": {
      "notes": "Flux Pro - Professional-grade image generation model"
    },
    "output_cost_per_image": 0.037,
    "source": "https://docs.aimlapi.com/",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "aiml/flux-realism",
    "model_name": "Flux Realism",
    "provider_id": "aiml",
    "provider_name": "Aiml",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "aiml/flux/dev": {
    "metadata": {
      "notes": "Flux Dev - Development version optimized for experimentation"
    },
    "output_cost_per_image": 0.026,
    "source": "https://docs.aimlapi.com/",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "aiml/flux/dev",
    "model_name": "Dev",
    "provider_id": "aiml",
    "provider_name": "Aiml",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "aiml/flux/kontext-max/text-to-image": {
    "metadata": {
      "notes": "Flux Pro v1.1 - Enhanced version with improved capabilities and 6x faster inference speed"
    },
    "output_cost_per_image": 0.084,
    "source": "https://docs.aimlapi.com/",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "aiml/flux/kontext-max/text-to-image",
    "model_name": "Text To Image",
    "provider_id": "aiml",
    "provider_name": "Aiml",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "aiml/flux/kontext-pro/text-to-image": {
    "metadata": {
      "notes": "Flux Pro v1.1 - Enhanced version with improved capabilities and 6x faster inference speed"
    },
    "output_cost_per_image": 0.042,
    "source": "https://docs.aimlapi.com/",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "aiml/flux/kontext-pro/text-to-image",
    "model_name": "Text To Image",
    "provider_id": "aiml",
    "provider_name": "Aiml",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "aiml/flux/schnell": {
    "metadata": {
      "notes": "Flux Schnell - Fast generation model optimized for speed"
    },
    "output_cost_per_image": 0.003,
    "source": "https://docs.aimlapi.com/",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "aiml/flux/schnell",
    "model_name": "Schnell",
    "provider_id": "aiml",
    "provider_name": "Aiml",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "luminous-base": {
    "input_cost_per_token": 0.00003,
    "max_tokens": 2048,
    "output_cost_per_token": 0.000033,
    "model_id": "luminous-base",
    "model_name": "Luminous Base",
    "provider_id": "aleph",
    "provider_name": "Aleph",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 30,
    "output_cost_per_million": 33,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "luminous-base-control": {
    "input_cost_per_token": 0.0000375,
    "max_tokens": 2048,
    "output_cost_per_token": 0.00004125,
    "model_id": "luminous-base-control",
    "model_name": "Luminous Base Control",
    "provider_id": "aleph",
    "provider_name": "Aleph",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 37.5,
    "output_cost_per_million": 41.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "luminous-extended": {
    "input_cost_per_token": 0.000045,
    "max_tokens": 2048,
    "output_cost_per_token": 0.0000495,
    "model_id": "luminous-extended",
    "model_name": "Luminous Extended",
    "provider_id": "aleph",
    "provider_name": "Aleph",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 45,
    "output_cost_per_million": 49.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "luminous-extended-control": {
    "input_cost_per_token": 0.00005625,
    "max_tokens": 2048,
    "output_cost_per_token": 0.000061875,
    "model_id": "luminous-extended-control",
    "model_name": "Luminous Extended Control",
    "provider_id": "aleph",
    "provider_name": "Aleph",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 56.25,
    "output_cost_per_million": 61.875,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "luminous-supreme": {
    "input_cost_per_token": 0.000175,
    "max_tokens": 2048,
    "output_cost_per_token": 0.0001925,
    "model_id": "luminous-supreme",
    "model_name": "Luminous Supreme",
    "provider_id": "aleph",
    "provider_name": "Aleph",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 175,
    "output_cost_per_million": 192.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "luminous-supreme-control": {
    "input_cost_per_token": 0.00021875,
    "max_tokens": 2048,
    "output_cost_per_token": 0.000240625,
    "model_id": "luminous-supreme-control",
    "model_name": "Luminous Supreme Control",
    "provider_id": "aleph",
    "provider_name": "Aleph",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 218.75,
    "output_cost_per_million": 240.625,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-5-haiku-20241022": {
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "deprecation_date": "2025-10-01",
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000004,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 264,
    "model_id": "claude-3-5-haiku-20241022",
    "model_name": "Claude 3.5 Haiku (Oct 2024)",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": 8e-8,
    "cache_read_cost_per_million": 0.08,
    "cache_write_cost_per_token": 0.000001,
    "cache_write_cost_per_million": 1,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-3-5-haiku-latest": {
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "deprecation_date": "2025-10-01",
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000005,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 264,
    "model_id": "claude-3-5-haiku-latest",
    "model_name": "Claude 3.5 Haiku",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 1,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": 1e-7,
    "cache_read_cost_per_million": 0.09999999999999999,
    "cache_write_cost_per_token": 0.00000125,
    "cache_write_cost_per_million": 1.25,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-3-5-sonnet-20240620": {
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "deprecation_date": "2025-06-01",
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-3-5-sonnet-20240620",
    "model_name": "Claude 3.5 Sonnet (Jun 2024)",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-3-5-sonnet-20241022": {
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "deprecation_date": "2025-10-01",
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-3-5-sonnet-20241022",
    "model_name": "Claude 3.5 Sonnet (Oct 2024)",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-3-5-sonnet-latest": {
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "deprecation_date": "2025-06-01",
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-3-5-sonnet-latest",
    "model_name": "Claude 3.5 Sonnet",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-3-7-sonnet-20250219": {
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "deprecation_date": "2026-02-01",
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-3-7-sonnet-20250219",
    "model_name": "Claude 3.7 Sonnet (Feb 2025)",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-3-7-sonnet-latest": {
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "deprecation_date": "2025-06-01",
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-3-7-sonnet-latest",
    "model_name": "Claude 3.7 Sonnet",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-3-haiku-20240307": {
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "deprecation_date": "2025-03-01",
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00000125,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 264,
    "model_id": "claude-3-haiku-20240307",
    "model_name": "Claude 3 Haiku",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1.25,
    "cache_read_cost_per_token": 3e-8,
    "cache_read_cost_per_million": 0.03,
    "cache_write_cost_per_token": 3e-7,
    "cache_write_cost_per_million": 0.3,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-3-opus-20240229": {
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "deprecation_date": "2025-03-01",
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 395,
    "model_id": "claude-3-opus-20240229",
    "model_name": "Claude 3 Opus (Feb 2024)",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-3-opus-latest": {
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "deprecation_date": "2025-03-01",
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 395,
    "model_id": "claude-3-opus-latest",
    "model_name": "Claude 3 Opus",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-4-opus-20250514": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-4-opus-20250514",
    "model_name": "Claude 4 Opus 20250514",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-4-sonnet-20250514": {
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6e-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "max_tokens": 1000000,
    "output_cost_per_token": 0.000015,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-4-sonnet-20250514",
    "model_name": "Claude 4 Sonnet 20250514",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-opus-4-1-20250805": {
    "cache_creation_input_token_cost_above_1hr": 0.00003,
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-opus-4-1-20250805",
    "model_name": "Claude Opus 4 1 20250805",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-opus-4-20250514": {
    "cache_creation_input_token_cost_above_1hr": 0.00003,
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-opus-4-20250514",
    "model_name": "Claude 4 Opus",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-sonnet-4-20250514": {
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-sonnet-4-20250514",
    "model_name": "Claude 4 Sonnet",
    "provider_id": "anthropic",
    "provider_name": "Anthropic",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "codellama/CodeLlama-34b-Instruct-hf": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000001,
    "model_id": "codellama/CodeLlama-34b-Instruct-hf",
    "model_name": "CodeLlama 34b Instruct Hf",
    "provider_id": "anyscale",
    "provider_name": "Anyscale",
    "input_cost_per_million": 1,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codellama/CodeLlama-70b-Instruct-hf": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000001,
    "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf",
    "model_id": "codellama/CodeLlama-70b-Instruct-hf",
    "model_name": "CodeLlama 70b Instruct Hf",
    "provider_id": "anyscale",
    "provider_name": "Anyscale",
    "input_cost_per_million": 1,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "google/gemma-7b-it": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 1.5e-7,
    "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it",
    "model_id": "google/gemma-7b-it",
    "model_name": "Gemma 7b IT",
    "provider_id": "anyscale",
    "provider_name": "Anyscale",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "HuggingFaceH4/zephyr-7b-beta": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 1.5e-7,
    "model_id": "HuggingFaceH4/zephyr-7b-beta",
    "model_name": "Zephyr 7b Beta",
    "provider_id": "anyscale",
    "provider_name": "Anyscale",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta-llama/Llama-2-13b-chat-hf": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 2.5e-7,
    "model_id": "meta-llama/Llama-2-13b-chat-hf",
    "model_name": "Llama 2 13b Chat Hf",
    "provider_id": "anyscale",
    "provider_name": "Anyscale",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 0.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta-llama/Llama-2-70b-chat-hf": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000001,
    "model_id": "meta-llama/Llama-2-70b-chat-hf",
    "model_name": "Llama 2 70b Chat Hf",
    "provider_id": "anyscale",
    "provider_name": "Anyscale",
    "input_cost_per_million": 1,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta-llama/Llama-2-7b-chat-hf": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 1.5e-7,
    "model_id": "meta-llama/Llama-2-7b-chat-hf",
    "model_name": "Llama 2 7b Chat Hf",
    "provider_id": "anyscale",
    "provider_name": "Anyscale",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta-llama/Meta-Llama-3-70B-Instruct": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000001,
    "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct",
    "model_id": "meta-llama/Meta-Llama-3-70B-Instruct",
    "model_name": "Meta Llama 3 70B Instruct",
    "provider_id": "anyscale",
    "provider_name": "Anyscale",
    "input_cost_per_million": 1,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistralai/Mixtral-8x22B-Instruct-v0.1": {
    "input_cost_per_token": 9e-7,
    "max_input_tokens": 65536,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 9e-7,
    "source": "https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1",
    "supports_function_calling": true,
    "model_id": "mistralai/Mixtral-8x22B-Instruct-v0.1",
    "model_name": "Mixtral 8x22B Instruct V0.1",
    "provider_id": "anyscale",
    "provider_name": "Anyscale",
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "assemblyai/best": {
    "input_cost_per_second": 0.00003333,
    "output_cost_per_second": 0,
    "model_id": "assemblyai/best",
    "model_name": "Best",
    "provider_id": "assemblyai",
    "provider_name": "AssemblyAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "assemblyai/nano": {
    "input_cost_per_second": 0.00010278,
    "output_cost_per_second": 0,
    "model_id": "assemblyai/nano",
    "model_name": "Nano",
    "provider_id": "assemblyai",
    "provider_name": "AssemblyAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Cohere-embed-v3-english": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 512,
    "max_tokens": 512,
    "output_cost_per_token": 0,
    "output_vector_size": 1024,
    "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice",
    "supports_embedding_image_input": true,
    "model_id": "azure_ai/Cohere-embed-v3-english",
    "model_name": "Cohere Embed V3 English",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Cohere-embed-v3-multilingual": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 512,
    "max_tokens": 512,
    "output_cost_per_token": 0,
    "output_vector_size": 1024,
    "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice",
    "supports_embedding_image_input": true,
    "model_id": "azure_ai/Cohere-embed-v3-multilingual",
    "model_name": "Cohere Embed V3 Multilingual",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/cohere-rerank-v3-english": {
    "input_cost_per_query": 0.002,
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_query_tokens": 2048,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "azure_ai/cohere-rerank-v3-english",
    "model_name": "Cohere Rerank V3 English",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/cohere-rerank-v3-multilingual": {
    "input_cost_per_query": 0.002,
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_query_tokens": 2048,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "azure_ai/cohere-rerank-v3-multilingual",
    "model_name": "Cohere Rerank V3 Multilingual",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/cohere-rerank-v3.5": {
    "input_cost_per_query": 0.002,
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_query_tokens": 2048,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "azure_ai/cohere-rerank-v3.5",
    "model_name": "Cohere Rerank V3.5",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/deepseek-r1": {
    "input_cost_per_token": 0.00000135,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000054,
    "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/deepseek-r1-improved-performance-higher-limits-and-transparent-pricing/4386367",
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "azure_ai/deepseek-r1",
    "model_name": "DeepSeek R1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.35,
    "output_cost_per_million": 5.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/deepseek-v3": {
    "input_cost_per_token": 0.00000114,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000456,
    "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438",
    "supports_tool_choice": true,
    "model_id": "azure_ai/deepseek-v3",
    "model_name": "DeepSeek V3",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.1400000000000001,
    "output_cost_per_million": 4.5600000000000005,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/deepseek-v3-0324": {
    "input_cost_per_token": 0.00000114,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000456,
    "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure_ai/deepseek-v3-0324",
    "model_name": "Deepseek V3 0324",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.1400000000000001,
    "output_cost_per_million": 4.5600000000000005,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/embed-v-4-0": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0,
    "output_vector_size": 3072,
    "source": "https://azuremarketplace.microsoft.com/pt-br/marketplace/apps/cohere.cohere-embed-4-offer?tab=PlansAndPrice",
    "supported_endpoints": [
      "/v1/embeddings"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supports_embedding_image_input": true,
    "model_id": "azure_ai/embed-v-4-0",
    "model_name": "Embed V 4 0",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_output_tokens": null,
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/FLUX-1.1-pro": {
    "output_cost_per_image": 0.04,
    "source": "https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/black-forest-labs-flux-1-kontext-pro-and-flux1-1-pro-now-available-in-azure-ai-f/4434659",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "azure_ai/FLUX-1.1-pro",
    "model_name": "FLUX 1.1 Pro",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/FLUX.1-Kontext-pro": {
    "output_cost_per_image": 0.04,
    "source": "https://azuremarketplace.microsoft.com/pt-br/marketplace/apps/cohere.cohere-embed-4-offer?tab=PlansAndPrice",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "azure_ai/FLUX.1-Kontext-pro",
    "model_name": "FLUX.1 Kontext Pro",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/global/grok-3": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000015,
    "source": "https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "azure_ai/global/grok-3",
    "model_name": "Grok 3",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "azure_ai/global/grok-3-mini": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.00000127,
    "source": "https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "azure_ai/global/grok-3-mini",
    "model_name": "Grok 3 Mini",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1.27,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "azure_ai/grok-3": {
    "input_cost_per_token": 0.0000033,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.0000165,
    "source": "https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "azure_ai/grok-3",
    "model_name": "Grok 3",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 3.3000000000000003,
    "output_cost_per_million": 16.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "azure_ai/grok-3-mini": {
    "input_cost_per_token": 2.75e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.00000138,
    "source": "https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "azure_ai/grok-3-mini",
    "model_name": "Grok 3 Mini",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.275,
    "output_cost_per_million": 1.38,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "azure_ai/jais-30b-chat": {
    "input_cost_per_token": 0.0032,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00971,
    "source": "https://azure.microsoft.com/en-us/products/ai-services/ai-foundry/models/jais-30b-chat",
    "model_id": "azure_ai/jais-30b-chat",
    "model_name": "Jais 30b Chat",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 3200,
    "output_cost_per_million": 9710,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/jamba-instruct": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 70000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 7e-7,
    "supports_tool_choice": true,
    "model_id": "azure_ai/jamba-instruct",
    "model_name": "Jamba Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 0.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Llama-3.2-11B-Vision-Instruct": {
    "input_cost_per_token": 3.7e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 3.7e-7,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure_ai/Llama-3.2-11B-Vision-Instruct",
    "model_name": "Llama 3.2 11B Vision Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.37,
    "output_cost_per_million": 0.37,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Llama-3.2-90B-Vision-Instruct": {
    "input_cost_per_token": 0.00000204,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0.00000204,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure_ai/Llama-3.2-90B-Vision-Instruct",
    "model_name": "Llama 3.2 90B Vision Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.04,
    "output_cost_per_million": 2.04,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Llama-3.3-70B-Instruct": {
    "input_cost_per_token": 7.1e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 7.1e-7,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.llama-3-3-70b-instruct-offer?tab=Overview",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure_ai/Llama-3.3-70B-Instruct",
    "model_name": "Llama 3.3 70B Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.71,
    "output_cost_per_million": 0.71,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8": {
    "input_cost_per_token": 0.00000141,
    "max_input_tokens": 1000000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 3.5e-7,
    "source": "https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "model_name": "Llama 4 Maverick 17B 128E Instruct FP8",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.4100000000000001,
    "output_cost_per_million": 0.35,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Llama-4-Scout-17B-16E-Instruct": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 10000000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 7.8e-7,
    "source": "https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure_ai/Llama-4-Scout-17B-16E-Instruct",
    "model_name": "Llama 4 Scout 17B 16E Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.78,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Meta-Llama-3-70B-Instruct": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 8192,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 3.7e-7,
    "supports_tool_choice": true,
    "model_id": "azure_ai/Meta-Llama-3-70B-Instruct",
    "model_name": "Meta Llama 3 70B Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 0.37,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Meta-Llama-3.1-405B-Instruct": {
    "input_cost_per_token": 0.00000533,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0.000016,
    "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice",
    "supports_tool_choice": true,
    "model_id": "azure_ai/Meta-Llama-3.1-405B-Instruct",
    "model_name": "Meta Llama 3.1 405B Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 5.33,
    "output_cost_per_million": 16,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Meta-Llama-3.1-70B-Instruct": {
    "input_cost_per_token": 0.00000268,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0.00000354,
    "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice",
    "supports_tool_choice": true,
    "model_id": "azure_ai/Meta-Llama-3.1-70B-Instruct",
    "model_name": "Meta Llama 3.1 70B Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.68,
    "output_cost_per_million": 3.54,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Meta-Llama-3.1-8B-Instruct": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 6.1e-7,
    "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice",
    "supports_tool_choice": true,
    "model_id": "azure_ai/Meta-Llama-3.1-8B-Instruct",
    "model_name": "Meta Llama 3.1 8B Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.61,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/ministral-3b": {
    "input_cost_per_token": 4e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 4e-8,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure_ai/ministral-3b",
    "model_name": "Ministral 3b",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.04,
    "output_cost_per_million": 0.04,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/mistral-large": {
    "input_cost_per_token": 0.000004,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000012,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure_ai/mistral-large",
    "model_name": "Mistral Large",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 4,
    "output_cost_per_million": 12,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/mistral-large-2407": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000006,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure_ai/mistral-large-2407",
    "model_name": "Mistral Large 2407",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/mistral-large-latest": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000006,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure_ai/mistral-large-latest",
    "model_name": "Mistral Large",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/mistral-medium-2505": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000002,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure_ai/mistral-medium-2505",
    "model_name": "Mistral Medium 2505",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/mistral-nemo": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 1.5e-7,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-nemo-12b-2407?tab=PlansAndPrice",
    "supports_function_calling": true,
    "model_id": "azure_ai/mistral-nemo",
    "model_name": "Mistral Nemo",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/mistral-small": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure_ai/mistral-small",
    "model_name": "Mistral Small",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/mistral-small-2503": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure_ai/mistral-small-2503",
    "model_name": "Mistral Small 2503",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Phi-3-medium-128k-instruct": {
    "input_cost_per_token": 1.7e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 6.8e-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure_ai/Phi-3-medium-128k-instruct",
    "model_name": "Phi 3 Medium 128k Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.16999999999999998,
    "output_cost_per_million": 0.6799999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Phi-3-medium-4k-instruct": {
    "input_cost_per_token": 1.7e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 6.8e-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure_ai/Phi-3-medium-4k-instruct",
    "model_name": "Phi 3 Medium 4k Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.16999999999999998,
    "output_cost_per_million": 0.6799999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Phi-3-mini-128k-instruct": {
    "input_cost_per_token": 1.3e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 5.2e-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure_ai/Phi-3-mini-128k-instruct",
    "model_name": "Phi 3 Mini 128k Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.13,
    "output_cost_per_million": 0.52,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Phi-3-mini-4k-instruct": {
    "input_cost_per_token": 1.3e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 5.2e-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure_ai/Phi-3-mini-4k-instruct",
    "model_name": "Phi 3 Mini 4k Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.13,
    "output_cost_per_million": 0.52,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Phi-3-small-128k-instruct": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 6e-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure_ai/Phi-3-small-128k-instruct",
    "model_name": "Phi 3 Small 128k Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Phi-3-small-8k-instruct": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 6e-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure_ai/Phi-3-small-8k-instruct",
    "model_name": "Phi 3 Small 8k Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Phi-3.5-mini-instruct": {
    "input_cost_per_token": 1.3e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 5.2e-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure_ai/Phi-3.5-mini-instruct",
    "model_name": "Phi 3.5 Mini Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.13,
    "output_cost_per_million": 0.52,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Phi-3.5-MoE-instruct": {
    "input_cost_per_token": 1.6e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 6.4e-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure_ai/Phi-3.5-MoE-instruct",
    "model_name": "Phi 3.5 MoE Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.16,
    "output_cost_per_million": 0.64,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Phi-3.5-vision-instruct": {
    "input_cost_per_token": 1.3e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 5.2e-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure_ai/Phi-3.5-vision-instruct",
    "model_name": "Phi 3.5 Vision Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.13,
    "output_cost_per_million": 0.52,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Phi-4": {
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 5e-7,
    "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/affordable-innovation-unveiling-the-pricing-of-phi-3-slms-on-models-as-a-service/4156495",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure_ai/Phi-4",
    "model_name": "Phi 4",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Phi-4-mini-instruct": {
    "input_cost_per_token": 7.5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 3e-7,
    "source": "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112",
    "supports_function_calling": true,
    "model_id": "azure_ai/Phi-4-mini-instruct",
    "model_name": "Phi 4 Mini Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure_ai/Phi-4-multimodal-instruct": {
    "input_cost_per_audio_token": 0.000004,
    "input_cost_per_token": 8e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 3.2e-7,
    "source": "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112",
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_vision": true,
    "model_id": "azure_ai/Phi-4-multimodal-instruct",
    "model_name": "Phi 4 Multimodal Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.08,
    "output_cost_per_million": 0.32,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/ada": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0,
    "model_id": "azure/ada",
    "model_name": "Ada",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/codex-mini": {
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.000006,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/codex-mini",
    "model_name": "Codex Mini",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": 3.75e-7,
    "cache_read_cost_per_million": 0.375,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/command-r-plus": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "model_id": "azure/command-r-plus",
    "model_name": "Command R Plus",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/computer-use-preview": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_token": 0.000012,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/computer-use-preview",
    "model_name": "Computer Use Preview",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 3,
    "output_cost_per_million": 12,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/eu/gpt-4o-2024-08-06": {
    "input_cost_per_token": 0.00000275,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.000011,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/eu/gpt-4o-2024-08-06",
    "model_name": "GPT 4o (Aug 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.75,
    "output_cost_per_million": 11,
    "cache_read_cost_per_token": 0.000001375,
    "cache_read_cost_per_million": 1.375,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/eu/gpt-4o-2024-11-20": {
    "input_cost_per_token": 0.00000275,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.000011,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/eu/gpt-4o-2024-11-20",
    "model_name": "GPT 4o (Nov 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.75,
    "output_cost_per_million": 11,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": 0.00000138,
    "cache_write_cost_per_million": 1.38,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/eu/gpt-4o-mini-2024-07-18": {
    "input_cost_per_token": 1.65e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 6.6e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/eu/gpt-4o-mini-2024-07-18",
    "model_name": "GPT 4o mini (Jul 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.165,
    "output_cost_per_million": 0.66,
    "cache_read_cost_per_token": 8.3e-8,
    "cache_read_cost_per_million": 0.083,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17": {
    "cache_creation_input_audio_token_cost": 3.3e-7,
    "input_cost_per_audio_token": 0.000011,
    "input_cost_per_token": 6.6e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.000022,
    "output_cost_per_token": 0.00000264,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17",
    "model_name": "GPT 4o Mini Realtime Preview 2024 12 17",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.66,
    "output_cost_per_million": 2.64,
    "cache_read_cost_per_token": 3.3e-7,
    "cache_read_cost_per_million": 0.33,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/eu/gpt-4o-realtime-preview-2024-10-01": {
    "cache_creation_input_audio_token_cost": 0.000022,
    "input_cost_per_audio_token": 0.00011,
    "input_cost_per_token": 0.0000055,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.00022,
    "output_cost_per_token": 0.000022,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "azure/eu/gpt-4o-realtime-preview-2024-10-01",
    "model_name": "GPT 4o Realtime Preview 2024 10 01",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 5.5,
    "output_cost_per_million": 22,
    "cache_read_cost_per_token": 0.00000275,
    "cache_read_cost_per_million": 2.75,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/eu/gpt-4o-realtime-preview-2024-12-17": {
    "cache_read_input_audio_token_cost": 0.0000025,
    "input_cost_per_audio_token": 0.000044,
    "input_cost_per_token": 0.0000055,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.000022,
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "azure/eu/gpt-4o-realtime-preview-2024-12-17",
    "model_name": "GPT 4o Realtime Preview 2024 12 17",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 5.5,
    "output_cost_per_million": 22,
    "cache_read_cost_per_token": 0.00000275,
    "cache_read_cost_per_million": 2.75,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/eu/o1-2024-12-17": {
    "input_cost_per_token": 0.0000165,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.000066,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/eu/o1-2024-12-17",
    "model_name": "O1 2024 12 17",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 16.5,
    "output_cost_per_million": 66,
    "cache_read_cost_per_token": 0.00000825,
    "cache_read_cost_per_million": 8.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/eu/o1-mini-2024-09-12": {
    "input_cost_per_token": 0.00000121,
    "input_cost_per_token_batches": 6.05e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0.00000484,
    "output_cost_per_token_batches": 0.00000242,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_vision": false,
    "model_id": "azure/eu/o1-mini-2024-09-12",
    "model_name": "O1 Mini 2024 09 12",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.21,
    "output_cost_per_million": 4.84,
    "cache_read_cost_per_token": 6.05e-7,
    "cache_read_cost_per_million": 0.605,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/eu/o1-preview-2024-09-12": {
    "input_cost_per_token": 0.0000165,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000066,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_vision": false,
    "model_id": "azure/eu/o1-preview-2024-09-12",
    "model_name": "O1 Preview 2024 09 12",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 16.5,
    "output_cost_per_million": 66,
    "cache_read_cost_per_token": 0.00000825,
    "cache_read_cost_per_million": 8.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/eu/o3-mini-2025-01-31": {
    "input_cost_per_token": 0.00000121,
    "input_cost_per_token_batches": 6.05e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00000484,
    "output_cost_per_token_batches": 0.00000242,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure/eu/o3-mini-2025-01-31",
    "model_name": "O3 Mini 2025 01 31",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.21,
    "output_cost_per_million": 4.84,
    "cache_read_cost_per_token": 6.05e-7,
    "cache_read_cost_per_million": 0.605,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/global-standard/gpt-4o-2024-08-06": {
    "deprecation_date": "2025-08-20",
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/global-standard/gpt-4o-2024-08-06",
    "model_name": "GPT 4o (Aug 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/global-standard/gpt-4o-2024-11-20": {
    "deprecation_date": "2025-12-20",
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/global-standard/gpt-4o-2024-11-20",
    "model_name": "GPT 4o (Nov 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/global-standard/gpt-4o-mini": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/global-standard/gpt-4o-mini",
    "model_name": "GPT 4o mini",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/global/gpt-4o-2024-08-06": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/global/gpt-4o-2024-08-06",
    "model_name": "GPT 4o (Aug 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/global/gpt-4o-2024-11-20": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/global/gpt-4o-2024-11-20",
    "model_name": "GPT 4o (Nov 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-3.5-turbo": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-3.5-turbo",
    "model_name": "GPT 3.5T",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-3.5-turbo-0125": {
    "deprecation_date": "2025-03-31",
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-3.5-turbo-0125",
    "model_name": "GPT 3.5T 0125",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/gpt-3.5-turbo-instruct-0914": {
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 4097,
    "max_tokens": 4097,
    "output_cost_per_token": 0.000002,
    "model_id": "azure/gpt-3.5-turbo-instruct-0914",
    "model_name": "GPT 3.5 Turbo Instruct 0914",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_output_tokens": null,
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-35-turbo": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-35-turbo",
    "model_name": "GPT 35 Turbo",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-35-turbo-0125": {
    "deprecation_date": "2025-05-31",
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-35-turbo-0125",
    "model_name": "GPT 35 Turbo 0125",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/gpt-35-turbo-0301": {
    "deprecation_date": "2025-02-13",
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "max_tokens": 4097,
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-35-turbo-0301",
    "model_name": "GPT 35 Turbo 0301",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/gpt-35-turbo-0613": {
    "deprecation_date": "2025-02-13",
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "max_tokens": 4097,
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-35-turbo-0613",
    "model_name": "GPT 35 Turbo 0613",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/gpt-35-turbo-1106": {
    "deprecation_date": "2025-03-31",
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 16384,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-35-turbo-1106",
    "model_name": "GPT 35 Turbo 1106",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/gpt-35-turbo-16k": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000004,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-35-turbo-16k",
    "model_name": "GPT 35 Turbo 16k",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 3,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-35-turbo-16k-0613": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000004,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-35-turbo-16k-0613",
    "model_name": "GPT 35 Turbo 16k 0613",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 3,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-35-turbo-instruct": {
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 4097,
    "max_tokens": 4097,
    "output_cost_per_token": 0.000002,
    "model_id": "azure/gpt-35-turbo-instruct",
    "model_name": "GPT 35 Turbo Instruct",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_output_tokens": null,
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-35-turbo-instruct-0914": {
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 4097,
    "max_tokens": 4097,
    "output_cost_per_token": 0.000002,
    "model_id": "azure/gpt-35-turbo-instruct-0914",
    "model_name": "GPT 35 Turbo Instruct 0914",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_output_tokens": null,
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-4": {
    "input_cost_per_token": 0.00003,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-4",
    "model_name": "GPT 4",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 30,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-4-0125-preview": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-4-0125-preview",
    "model_name": "GPT 4 0125 Preview",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/gpt-4-0613": {
    "input_cost_per_token": 0.00003,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-4-0613",
    "model_name": "GPT 4 0613",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 30,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-4-1106-preview": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-4-1106-preview",
    "model_name": "GPT 4 1106 Preview",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/gpt-4-32k": {
    "input_cost_per_token": 0.00006,
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00012,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-4-32k",
    "model_name": "GPT 4 32k",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 60,
    "output_cost_per_million": 120,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-4-32k-0613": {
    "input_cost_per_token": 0.00006,
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00012,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-4-32k-0613",
    "model_name": "GPT 4 32k 0613",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 60,
    "output_cost_per_million": 120,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-4-turbo": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-4-turbo",
    "model_name": "GPT 4 Turbo",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/gpt-4-turbo-2024-04-09": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-4-turbo-2024-04-09",
    "model_name": "GPT 4 Turbo 2024 04 09",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/gpt-4-turbo-vision-preview": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00003,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-4-turbo-vision-preview",
    "model_name": "GPT 4 Turbo Vision Preview",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-4.1": {
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_batches": 0.000004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": false,
    "model_id": "azure/gpt-4.1",
    "model_name": "GPT 4.1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-4.1-2025-04-14": {
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_batches": 0.000004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": false,
    "model_id": "azure/gpt-4.1-2025-04-14",
    "model_name": "GPT 4.1 (Apr 2025)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-4.1-mini": {
    "input_cost_per_token": 4e-7,
    "input_cost_per_token_batches": 2e-7,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.0000016,
    "output_cost_per_token_batches": 8e-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": false,
    "model_id": "azure/gpt-4.1-mini",
    "model_name": "GPT 4.1 mini",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.5999999999999999,
    "cache_read_cost_per_token": 1e-7,
    "cache_read_cost_per_million": 0.09999999999999999,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-4.1-mini-2025-04-14": {
    "input_cost_per_token": 4e-7,
    "input_cost_per_token_batches": 2e-7,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.0000016,
    "output_cost_per_token_batches": 8e-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": false,
    "model_id": "azure/gpt-4.1-mini-2025-04-14",
    "model_name": "GPT 4.1 Mini 2025 04 14",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.5999999999999999,
    "cache_read_cost_per_token": 1e-7,
    "cache_read_cost_per_million": 0.09999999999999999,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-4.1-nano": {
    "input_cost_per_token": 1e-7,
    "input_cost_per_token_batches": 5e-8,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 4e-7,
    "output_cost_per_token_batches": 2e-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-4.1-nano",
    "model_name": "GPT 4.1 nano",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-4.1-nano-2025-04-14": {
    "input_cost_per_token": 1e-7,
    "input_cost_per_token_batches": 5e-8,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 4e-7,
    "output_cost_per_token_batches": 2e-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-4.1-nano-2025-04-14",
    "model_name": "GPT 4.1 Nano 2025 04 14",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-4.5-preview": {
    "input_cost_per_token": 0.000075,
    "input_cost_per_token_batches": 0.0000375,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00015,
    "output_cost_per_token_batches": 0.000075,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-4.5-preview",
    "model_name": "GPT 4.5",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 75,
    "output_cost_per_million": 150,
    "cache_read_cost_per_token": 0.0000375,
    "cache_read_cost_per_million": 37.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-4o": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-4o",
    "model_name": "GPT 4o",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-4o-2024-05-13": {
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-4o-2024-05-13",
    "model_name": "GPT 4o (May 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 5,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/gpt-4o-2024-08-06": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-4o-2024-08-06",
    "model_name": "GPT 4o (Aug 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-4o-2024-11-20": {
    "input_cost_per_token": 0.00000275,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.000011,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-4o-2024-11-20",
    "model_name": "GPT 4o (Nov 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.75,
    "output_cost_per_million": 11,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-4o-audio-preview-2024-12-17": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure/gpt-4o-audio-preview-2024-12-17",
    "model_name": "GPT 4o Audio Preview 2024 12 17",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": true
  },
  "azure/gpt-4o-mini": {
    "input_cost_per_token": 1.65e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 6.6e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-4o-mini",
    "model_name": "GPT 4o mini",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.165,
    "output_cost_per_million": 0.66,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-4o-mini-2024-07-18": {
    "input_cost_per_token": 1.65e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 6.6e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-4o-mini-2024-07-18",
    "model_name": "GPT 4o mini (Jul 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.165,
    "output_cost_per_million": 0.66,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-4o-mini-audio-preview-2024-12-17": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure/gpt-4o-mini-audio-preview-2024-12-17",
    "model_name": "GPT 4o Mini Audio Preview 2024 12 17",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": true
  },
  "azure/gpt-4o-mini-realtime-preview-2024-12-17": {
    "cache_creation_input_audio_token_cost": 3e-7,
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-4o-mini-realtime-preview-2024-12-17",
    "model_name": "GPT 4o Mini Realtime Preview 2024 12 17",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 2.4,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/gpt-4o-mini-transcribe": {
    "input_cost_per_audio_token": 0.000003,
    "input_cost_per_token": 0.00000125,
    "max_input_tokens": 16000,
    "max_output_tokens": 2000,
    "output_cost_per_token": 0.000005,
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "azure/gpt-4o-mini-transcribe",
    "model_name": "GPT 4o Mini Transcribe",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-4o-mini-tts": {
    "input_cost_per_token": 0.0000025,
    "output_cost_per_audio_token": 0.000012,
    "output_cost_per_second": 0.00025,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/audio/speech"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "audio"
    ],
    "model_id": "azure/gpt-4o-mini-tts",
    "model_name": "GPT 4o Mini Tts",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-4o-realtime-preview-2024-10-01": {
    "cache_creation_input_audio_token_cost": 0.00002,
    "input_cost_per_audio_token": 0.0001,
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.0002,
    "output_cost_per_token": 0.00002,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-4o-realtime-preview-2024-10-01",
    "model_name": "GPT 4o Realtime Preview 2024 10 01",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 5,
    "output_cost_per_million": 20,
    "cache_read_cost_per_token": 0.0000025,
    "cache_read_cost_per_million": 2.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/gpt-4o-realtime-preview-2024-12-17": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00002,
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "azure/gpt-4o-realtime-preview-2024-12-17",
    "model_name": "GPT 4o Realtime Preview 2024 12 17",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 5,
    "output_cost_per_million": 20,
    "cache_read_cost_per_token": 0.0000025,
    "cache_read_cost_per_million": 2.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/gpt-4o-transcribe": {
    "input_cost_per_audio_token": 0.000006,
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 16000,
    "max_output_tokens": 2000,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "azure/gpt-4o-transcribe",
    "model_name": "GPT 4o Transcribe",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/gpt-5": {
    "input_cost_per_token": 0.00000125,
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-5",
    "model_name": "GPT 5",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 1.25e-7,
    "cache_read_cost_per_million": 0.125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-5-2025-08-07": {
    "input_cost_per_token": 0.00000125,
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-5-2025-08-07",
    "model_name": "GPT 5 2025 08 07",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 1.25e-7,
    "cache_read_cost_per_million": 0.125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-5-chat": {
    "input_cost_per_token": 0.00000125,
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00001,
    "source": "https://azure.microsoft.com/en-us/blog/gpt-5-in-azure-ai-foundry-the-future-of-ai-apps-and-agents-starts-here/",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true,
    "model_id": "azure/gpt-5-chat",
    "model_name": "GPT 5 Chat",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 1.25e-7,
    "cache_read_cost_per_million": 0.125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-5-chat-latest": {
    "input_cost_per_token": 0.00000125,
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true,
    "model_id": "azure/gpt-5-chat-latest",
    "model_name": "GPT 5 Chat Latest",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 1.25e-7,
    "cache_read_cost_per_million": 0.125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-5-mini": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-5-mini",
    "model_name": "GPT 5 Mini",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-5-mini-2025-08-07": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-5-mini-2025-08-07",
    "model_name": "GPT 5 Mini 2025 08 07",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-5-nano": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 4e-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-5-nano",
    "model_name": "GPT 5 Nano",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 5e-9,
    "cache_read_cost_per_million": 0.005,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-5-nano-2025-08-07": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 4e-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/gpt-5-nano-2025-08-07",
    "model_name": "GPT 5 Nano 2025 08 07",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 5e-9,
    "cache_read_cost_per_million": 0.005,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/gpt-image-1": {
    "input_cost_per_pixel": 4.0054321e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "azure/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/hd/1024-x-1024/dall-e-3": {
    "input_cost_per_pixel": 7.629e-8,
    "output_cost_per_token": 0,
    "model_id": "azure/hd/1024-x-1024/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/hd/1024-x-1792/dall-e-3": {
    "input_cost_per_pixel": 6.539e-8,
    "output_cost_per_token": 0,
    "model_id": "azure/hd/1024-x-1792/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/hd/1792-x-1024/dall-e-3": {
    "input_cost_per_pixel": 6.539e-8,
    "output_cost_per_token": 0,
    "model_id": "azure/hd/1792-x-1024/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/high/1024-x-1024/gpt-image-1": {
    "input_cost_per_pixel": 1.59263611e-7,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "azure/high/1024-x-1024/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/high/1024-x-1536/gpt-image-1": {
    "input_cost_per_pixel": 1.58945719e-7,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "azure/high/1024-x-1536/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/high/1536-x-1024/gpt-image-1": {
    "input_cost_per_pixel": 1.58945719e-7,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "azure/high/1536-x-1024/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/low/1024-x-1024/gpt-image-1": {
    "input_cost_per_pixel": 1.0490417e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "azure/low/1024-x-1024/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/low/1024-x-1536/gpt-image-1": {
    "input_cost_per_pixel": 1.0172526e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "azure/low/1024-x-1536/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/low/1536-x-1024/gpt-image-1": {
    "input_cost_per_pixel": 1.0172526e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "azure/low/1536-x-1024/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/medium/1024-x-1024/gpt-image-1": {
    "input_cost_per_pixel": 4.0054321e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "azure/medium/1024-x-1024/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/medium/1024-x-1536/gpt-image-1": {
    "input_cost_per_pixel": 4.0054321e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "azure/medium/1024-x-1536/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/medium/1536-x-1024/gpt-image-1": {
    "input_cost_per_pixel": 4.0054321e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "azure/medium/1536-x-1024/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/mistral-large-2402": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000024,
    "supports_function_calling": true,
    "model_id": "azure/mistral-large-2402",
    "model_name": "Mistral Large 2402",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_output_tokens": null,
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/mistral-large-latest": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000024,
    "supports_function_calling": true,
    "model_id": "azure/mistral-large-latest",
    "model_name": "Mistral Large",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_output_tokens": null,
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/o1": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/o1",
    "model_name": "O1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 15,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": 0.0000075,
    "cache_read_cost_per_million": 7.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/o1-2024-12-17": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/o1-2024-12-17",
    "model_name": "O1 2024 12 17",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 15,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": 0.0000075,
    "cache_read_cost_per_million": 7.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/o1-mini": {
    "input_cost_per_token": 0.00000121,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0.00000484,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": false,
    "model_id": "azure/o1-mini",
    "model_name": "O1 mini",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.21,
    "output_cost_per_million": 4.84,
    "cache_read_cost_per_token": 6.05e-7,
    "cache_read_cost_per_million": 0.605,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/o1-mini-2024-09-12": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": false,
    "model_id": "azure/o1-mini-2024-09-12",
    "model_name": "O1 Mini 2024 09 12",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": 5.5e-7,
    "cache_read_cost_per_million": 0.55,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/o1-preview": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": false,
    "model_id": "azure/o1-preview",
    "model_name": "O1 Preview",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 15,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": 0.0000075,
    "cache_read_cost_per_million": 7.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/o1-preview-2024-09-12": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": false,
    "model_id": "azure/o1-preview-2024-09-12",
    "model_name": "O1 Preview 2024 09 12",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 15,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": 0.0000075,
    "cache_read_cost_per_million": 7.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/o3": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.000008,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/o3",
    "model_name": "O3",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "azure/o3-2025-04-16": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/o3-2025-04-16",
    "model_name": "O3 2025 04 16",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 10,
    "output_cost_per_million": 40,
    "cache_read_cost_per_token": 0.0000025,
    "cache_read_cost_per_million": 2.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "azure/o3-deep-research": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "azure/o3-deep-research",
    "model_name": "O3 Deep Research",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 10,
    "output_cost_per_million": 40,
    "cache_read_cost_per_token": 0.0000025,
    "cache_read_cost_per_million": 2.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/o3-mini": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.0000044,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure/o3-mini",
    "model_name": "O3 mini",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": 5.5e-7,
    "cache_read_cost_per_million": 0.55,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_parallel_functions": false
  },
  "azure/o3-mini-2025-01-31": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.0000044,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure/o3-mini-2025-01-31",
    "model_name": "O3 Mini 2025 01 31",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": 5.5e-7,
    "cache_read_cost_per_million": 0.55,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/o3-pro": {
    "input_cost_per_token": 0.00002,
    "input_cost_per_token_batches": 0.00001,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00008,
    "output_cost_per_token_batches": 0.00004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/o3-pro",
    "model_name": "O3 Pro",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 20,
    "output_cost_per_million": 80,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "azure/o3-pro-2025-06-10": {
    "input_cost_per_token": 0.00002,
    "input_cost_per_token_batches": 0.00001,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00008,
    "output_cost_per_token_batches": 0.00004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/o3-pro-2025-06-10",
    "model_name": "O3 Pro 2025 06 10",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 20,
    "output_cost_per_million": 80,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "azure/o4-mini": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.0000044,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/o4-mini",
    "model_name": "O4 mini",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": 2.75e-7,
    "cache_read_cost_per_million": 0.275,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "azure/o4-mini-2025-04-16": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/o4-mini-2025-04-16",
    "model_name": "O4 Mini 2025 04 16",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": 2.75e-7,
    "cache_read_cost_per_million": 0.275,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "azure/standard/1024-x-1024/dall-e-2": {
    "input_cost_per_pixel": 0,
    "output_cost_per_token": 0,
    "model_id": "azure/standard/1024-x-1024/dall-e-2",
    "model_name": "Dall E 2",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/standard/1024-x-1024/dall-e-3": {
    "input_cost_per_pixel": 3.81469e-8,
    "output_cost_per_token": 0,
    "model_id": "azure/standard/1024-x-1024/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/standard/1024-x-1792/dall-e-3": {
    "input_cost_per_pixel": 4.359e-8,
    "output_cost_per_token": 0,
    "model_id": "azure/standard/1024-x-1792/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/standard/1792-x-1024/dall-e-3": {
    "input_cost_per_pixel": 4.359e-8,
    "output_cost_per_token": 0,
    "model_id": "azure/standard/1792-x-1024/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/text-embedding-3-large": {
    "input_cost_per_token": 1.3e-7,
    "max_input_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0,
    "model_id": "azure/text-embedding-3-large",
    "model_name": "Text Embedding 3 Large",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_output_tokens": null,
    "input_cost_per_million": 0.13,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/text-embedding-3-small": {
    "input_cost_per_token": 2e-8,
    "max_input_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0,
    "model_id": "azure/text-embedding-3-small",
    "model_name": "Text Embedding 3 Small",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_output_tokens": null,
    "input_cost_per_million": 0.02,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/text-embedding-ada-002": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0,
    "model_id": "azure/text-embedding-ada-002",
    "model_name": "Text Embedding Ada 002",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/tts-1": {
    "input_cost_per_character": 0.000015,
    "model_id": "azure/tts-1",
    "model_name": "Tts 1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/tts-1-hd": {
    "input_cost_per_character": 0.00003,
    "model_id": "azure/tts-1-hd",
    "model_name": "Tts 1 Hd",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/us/gpt-4o-2024-08-06": {
    "input_cost_per_token": 0.00000275,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.000011,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/us/gpt-4o-2024-08-06",
    "model_name": "GPT 4o (Aug 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.75,
    "output_cost_per_million": 11,
    "cache_read_cost_per_token": 0.000001375,
    "cache_read_cost_per_million": 1.375,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/us/gpt-4o-2024-11-20": {
    "input_cost_per_token": 0.00000275,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.000011,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/us/gpt-4o-2024-11-20",
    "model_name": "GPT 4o (Nov 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 2.75,
    "output_cost_per_million": 11,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": 0.00000138,
    "cache_write_cost_per_million": 1.38,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/us/gpt-4o-mini-2024-07-18": {
    "input_cost_per_token": 1.65e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 6.6e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/us/gpt-4o-mini-2024-07-18",
    "model_name": "GPT 4o mini (Jul 2024)",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.165,
    "output_cost_per_million": 0.66,
    "cache_read_cost_per_token": 8.3e-8,
    "cache_read_cost_per_million": 0.083,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "azure/us/gpt-4o-mini-realtime-preview-2024-12-17": {
    "cache_creation_input_audio_token_cost": 3.3e-7,
    "input_cost_per_audio_token": 0.000011,
    "input_cost_per_token": 6.6e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.000022,
    "output_cost_per_token": 0.00000264,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "azure/us/gpt-4o-mini-realtime-preview-2024-12-17",
    "model_name": "GPT 4o Mini Realtime Preview 2024 12 17",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 0.66,
    "output_cost_per_million": 2.64,
    "cache_read_cost_per_token": 3.3e-7,
    "cache_read_cost_per_million": 0.33,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/us/gpt-4o-realtime-preview-2024-10-01": {
    "cache_creation_input_audio_token_cost": 0.000022,
    "input_cost_per_audio_token": 0.00011,
    "input_cost_per_token": 0.0000055,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.00022,
    "output_cost_per_token": 0.000022,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "azure/us/gpt-4o-realtime-preview-2024-10-01",
    "model_name": "GPT 4o Realtime Preview 2024 10 01",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 5.5,
    "output_cost_per_million": 22,
    "cache_read_cost_per_token": 0.00000275,
    "cache_read_cost_per_million": 2.75,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/us/gpt-4o-realtime-preview-2024-12-17": {
    "cache_read_input_audio_token_cost": 0.0000025,
    "input_cost_per_audio_token": 0.000044,
    "input_cost_per_token": 0.0000055,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.000022,
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "azure/us/gpt-4o-realtime-preview-2024-12-17",
    "model_name": "GPT 4o Realtime Preview 2024 12 17",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 5.5,
    "output_cost_per_million": 22,
    "cache_read_cost_per_token": 0.00000275,
    "cache_read_cost_per_million": 2.75,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "azure/us/o1-2024-12-17": {
    "input_cost_per_token": 0.0000165,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.000066,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "azure/us/o1-2024-12-17",
    "model_name": "O1 2024 12 17",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 16.5,
    "output_cost_per_million": 66,
    "cache_read_cost_per_token": 0.00000825,
    "cache_read_cost_per_million": 8.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/us/o1-mini-2024-09-12": {
    "input_cost_per_token": 0.00000121,
    "input_cost_per_token_batches": 6.05e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0.00000484,
    "output_cost_per_token_batches": 0.00000242,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_vision": false,
    "model_id": "azure/us/o1-mini-2024-09-12",
    "model_name": "O1 Mini 2024 09 12",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.21,
    "output_cost_per_million": 4.84,
    "cache_read_cost_per_token": 6.05e-7,
    "cache_read_cost_per_million": 0.605,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/us/o1-preview-2024-09-12": {
    "input_cost_per_token": 0.0000165,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000066,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_vision": false,
    "model_id": "azure/us/o1-preview-2024-09-12",
    "model_name": "O1 Preview 2024 09 12",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 16.5,
    "output_cost_per_million": 66,
    "cache_read_cost_per_token": 0.00000825,
    "cache_read_cost_per_million": 8.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "azure/us/o3-mini-2025-01-31": {
    "input_cost_per_token": 0.00000121,
    "input_cost_per_token_batches": 6.05e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00000484,
    "output_cost_per_token_batches": 0.00000242,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "azure/us/o3-mini-2025-01-31",
    "model_name": "O3 Mini 2025 01 31",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 1.21,
    "output_cost_per_million": 4.84,
    "cache_read_cost_per_token": 6.05e-7,
    "cache_read_cost_per_million": 0.605,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "azure/whisper-1": {
    "input_cost_per_second": 0.0001,
    "output_cost_per_second": 0.0001,
    "model_id": "azure/whisper-1",
    "model_name": "Whisper 1",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "computer-use-preview": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_token": 0.000012,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "computer-use-preview",
    "model_name": "Computer Use Preview",
    "provider_id": "azure",
    "provider_name": "Microsoft Azure",
    "input_cost_per_million": 3,
    "output_cost_per_million": 12,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "*/1-month-commitment/cohere.command-light-text-v14": {
    "input_cost_per_second": 0.001902,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_second": 0.001902,
    "supports_tool_choice": true,
    "model_id": "*/1-month-commitment/cohere.command-light-text-v14",
    "model_name": "Cohere.command Light Text V14",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "*/1-month-commitment/cohere.command-text-v14": {
    "input_cost_per_second": 0.011,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_second": 0.011,
    "supports_tool_choice": true,
    "model_id": "*/1-month-commitment/cohere.command-text-v14",
    "model_name": "Cohere.command Text V14",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "*/6-month-commitment/cohere.command-light-text-v14": {
    "input_cost_per_second": 0.0011416,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_second": 0.0011416,
    "supports_tool_choice": true,
    "model_id": "*/6-month-commitment/cohere.command-light-text-v14",
    "model_name": "Cohere.command Light Text V14",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "*/6-month-commitment/cohere.command-text-v14": {
    "input_cost_per_second": 0.0066027,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_second": 0.0066027,
    "supports_tool_choice": true,
    "model_id": "*/6-month-commitment/cohere.command-text-v14",
    "model_name": "Cohere.command Text V14",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0": {
    "max_input_tokens": 2600,
    "output_cost_per_image": 0.06,
    "model_id": "1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0",
    "model_name": "Amazon.nova Canvas V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1": {
    "max_input_tokens": 77,
    "max_tokens": 77,
    "output_cost_per_image": 0.04,
    "model_id": "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1",
    "model_name": "Stability.stable Diffusion Xl V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1": {
    "max_input_tokens": 77,
    "max_tokens": 77,
    "output_cost_per_image": 0.08,
    "model_id": "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1",
    "model_name": "Stability.stable Diffusion Xl V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "512-x-512/50-steps/stability.stable-diffusion-xl-v0": {
    "max_input_tokens": 77,
    "max_tokens": 77,
    "output_cost_per_image": 0.018,
    "model_id": "512-x-512/50-steps/stability.stable-diffusion-xl-v0",
    "model_name": "Stability.stable Diffusion Xl V0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "512-x-512/max-steps/stability.stable-diffusion-xl-v0": {
    "max_input_tokens": 77,
    "max_tokens": 77,
    "output_cost_per_image": 0.036,
    "model_id": "512-x-512/max-steps/stability.stable-diffusion-xl-v0",
    "model_name": "Stability.stable Diffusion Xl V0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ai21.j2-mid-v1": {
    "input_cost_per_token": 0.0000125,
    "max_input_tokens": 8191,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.0000125,
    "model_id": "ai21.j2-mid-v1",
    "model_name": "Ai21.j2 Mid V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 12.5,
    "output_cost_per_million": 12.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ai21.j2-ultra-v1": {
    "input_cost_per_token": 0.0000188,
    "max_input_tokens": 8191,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.0000188,
    "model_id": "ai21.j2-ultra-v1",
    "model_name": "Ai21.j2 Ultra V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 18.8,
    "output_cost_per_million": 18.8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ai21.jamba-1-5-large-v1:0": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.000008,
    "model_id": "ai21.jamba-1-5-large-v1:0",
    "model_name": "Ai21.jamba 1 5 Large V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ai21.jamba-1-5-mini-v1:0": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 4e-7,
    "model_id": "ai21.jamba-1-5-mini-v1:0",
    "model_name": "Ai21.jamba 1 5 Mini V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ai21.jamba-instruct-v1:0": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 70000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 7e-7,
    "supports_system_messages": true,
    "model_id": "ai21.jamba-instruct-v1:0",
    "model_name": "Ai21.jamba Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 0.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "amazon.nova-lite-v1:0": {
    "input_cost_per_token": 6e-8,
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 2.4e-7,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true,
    "model_id": "amazon.nova-lite-v1:0",
    "model_name": "Amazon.nova Lite V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.06,
    "output_cost_per_million": 0.24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "amazon.nova-micro-v1:0": {
    "input_cost_per_token": 3.5e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 1.4e-7,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "model_id": "amazon.nova-micro-v1:0",
    "model_name": "Amazon.nova Micro V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.035,
    "output_cost_per_million": 0.14,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "amazon.nova-pro-v1:0": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 0.0000032,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true,
    "model_id": "amazon.nova-pro-v1:0",
    "model_name": "Amazon.nova Pro V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 3.1999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "amazon.rerank-v1:0": {
    "input_cost_per_query": 0.001,
    "input_cost_per_token": 0,
    "max_document_chunks_per_query": 100,
    "max_input_tokens": 32000,
    "max_output_tokens": 32000,
    "max_query_tokens": 32000,
    "max_tokens": 32000,
    "max_tokens_per_document_chunk": 512,
    "output_cost_per_token": 0,
    "model_id": "amazon.rerank-v1:0",
    "model_name": "Amazon.rerank V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "amazon.titan-embed-image-v1": {
    "input_cost_per_image": 0.00006,
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 128,
    "max_tokens": 128,
    "metadata": {
      "notes": "'supports_image_input' is a deprecated field. Use 'supports_embedding_image_input' instead."
    },
    "output_cost_per_token": 0,
    "output_vector_size": 1024,
    "source": "https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/providers?model=amazon.titan-image-generator-v1",
    "supports_embedding_image_input": true,
    "supports_image_input": true,
    "model_id": "amazon.titan-embed-image-v1",
    "model_name": "Amazon.titan Embed Image V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "amazon.titan-embed-text-v1": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "output_vector_size": 1536,
    "model_id": "amazon.titan-embed-text-v1",
    "model_name": "Amazon.titan Embed Text V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "amazon.titan-embed-text-v2:0": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "output_vector_size": 1024,
    "model_id": "amazon.titan-embed-text-v2:0",
    "model_name": "Amazon.titan Embed Text V2:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "amazon.titan-text-express-v1": {
    "input_cost_per_token": 0.0000013,
    "max_input_tokens": 42000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "output_cost_per_token": 0.0000017,
    "model_id": "amazon.titan-text-express-v1",
    "model_name": "Amazon.titan Text Express V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 1.3,
    "output_cost_per_million": 1.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "amazon.titan-text-lite-v1": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 42000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "output_cost_per_token": 4e-7,
    "model_id": "amazon.titan-text-lite-v1",
    "model_name": "Amazon.titan Text Lite V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "amazon.titan-text-premier-v1:0": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 42000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.0000015,
    "model_id": "amazon.titan-text-premier-v1:0",
    "model_name": "Amazon.titan Text Premier V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "anthropic.claude-3-5-haiku-20241022-v1:0": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000004,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "anthropic.claude-3-5-haiku-20241022-v1:0",
    "model_name": "Anthropic.claude 3 5 Haiku 20241022 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": 8e-8,
    "cache_read_cost_per_million": 0.08,
    "cache_write_cost_per_token": 0.000001,
    "cache_write_cost_per_million": 1,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "anthropic.claude-3-5-sonnet-20240620-v1:0",
    "model_name": "Anthropic.claude 3 5 Sonnet 20240620 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "anthropic.claude-3-5-sonnet-20241022-v2:0",
    "model_name": "Anthropic.claude 3 5 Sonnet 20241022 V2:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "anthropic.claude-3-7-sonnet-20250219-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "anthropic.claude-3-7-sonnet-20250219-v1:0",
    "model_name": "Anthropic.claude 3 7 Sonnet 20250219 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "anthropic.claude-3-haiku-20240307-v1:0": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00000125,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "anthropic.claude-3-haiku-20240307-v1:0",
    "model_name": "Anthropic.claude 3 Haiku 20240307 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "anthropic.claude-3-opus-20240229-v1:0": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000075,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "anthropic.claude-3-opus-20240229-v1:0",
    "model_name": "Anthropic.claude 3 Opus 20240229 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "anthropic.claude-3-sonnet-20240229-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "anthropic.claude-3-sonnet-20240229-v1:0",
    "model_name": "Anthropic.claude 3 Sonnet 20240229 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "anthropic.claude-instant-v1": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.0000024,
    "supports_tool_choice": true,
    "model_id": "anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 2.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "anthropic.claude-opus-4-1-20250805-v1:0": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "anthropic.claude-opus-4-1-20250805-v1:0",
    "model_name": "Anthropic.claude Opus 4 1 20250805 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "anthropic.claude-opus-4-20250514-v1:0": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "anthropic.claude-opus-4-20250514-v1:0",
    "model_name": "Anthropic.claude Opus 4 20250514 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "anthropic.claude-sonnet-4-20250514-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "anthropic.claude-sonnet-4-20250514-v1:0",
    "model_name": "Anthropic.claude Sonnet 4 20250514 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "anthropic.claude-v1": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "model_id": "anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "anthropic.claude-v2:1": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true,
    "model_id": "anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.01475,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.01475,
    "supports_tool_choice": true,
    "model_id": "ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ap-northeast-1/1-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.0455,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.0455,
    "model_id": "ap-northeast-1/1-month-commitment/anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ap-northeast-1/1-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.0455,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.0455,
    "supports_tool_choice": true,
    "model_id": "ap-northeast-1/1-month-commitment/anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.008194,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.008194,
    "supports_tool_choice": true,
    "model_id": "ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ap-northeast-1/6-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.02527,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.02527,
    "model_id": "ap-northeast-1/6-month-commitment/anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ap-northeast-1/6-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.02527,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.02527,
    "supports_tool_choice": true,
    "model_id": "ap-northeast-1/6-month-commitment/anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ap-northeast-1/anthropic.claude-instant-v1": {
    "input_cost_per_token": 0.00000223,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.00000755,
    "supports_tool_choice": true,
    "model_id": "ap-northeast-1/anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2.23,
    "output_cost_per_million": 7.55,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ap-northeast-1/anthropic.claude-v1": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true,
    "model_id": "ap-northeast-1/anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ap-northeast-1/anthropic.claude-v2:1": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true,
    "model_id": "ap-northeast-1/anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ap-south-1/meta.llama3-70b-instruct-v1:0": {
    "input_cost_per_token": 0.00000318,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000042,
    "model_id": "ap-south-1/meta.llama3-70b-instruct-v1:0",
    "model_name": "Meta.llama3 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3.18,
    "output_cost_per_million": 4.199999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ap-south-1/meta.llama3-8b-instruct-v1:0": {
    "input_cost_per_token": 3.6e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 7.2e-7,
    "model_id": "ap-south-1/meta.llama3-8b-instruct-v1:0",
    "model_name": "Meta.llama3 8b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.36,
    "output_cost_per_million": 0.72,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "apac.amazon.nova-lite-v1:0": {
    "input_cost_per_token": 6.3e-8,
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 2.52e-7,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true,
    "model_id": "apac.amazon.nova-lite-v1:0",
    "model_name": "Apac.amazon.nova Lite V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.063,
    "output_cost_per_million": 0.252,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "apac.amazon.nova-micro-v1:0": {
    "input_cost_per_token": 3.7e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 1.48e-7,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "model_id": "apac.amazon.nova-micro-v1:0",
    "model_name": "Apac.amazon.nova Micro V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.037,
    "output_cost_per_million": 0.148,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "apac.amazon.nova-pro-v1:0": {
    "input_cost_per_token": 8.4e-7,
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 0.00000336,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true,
    "model_id": "apac.amazon.nova-pro-v1:0",
    "model_name": "Apac.amazon.nova Pro V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.84,
    "output_cost_per_million": 3.36,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "apac.anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "apac.anthropic.claude-3-5-sonnet-20240620-v1:0",
    "model_name": "Apac.anthropic.claude 3 5 Sonnet 20240620 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "apac.anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "apac.anthropic.claude-3-5-sonnet-20241022-v2:0",
    "model_name": "Apac.anthropic.claude 3 5 Sonnet 20241022 V2:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "apac.anthropic.claude-3-haiku-20240307-v1:0": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00000125,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "apac.anthropic.claude-3-haiku-20240307-v1:0",
    "model_name": "Apac.anthropic.claude 3 Haiku 20240307 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "apac.anthropic.claude-3-sonnet-20240229-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "apac.anthropic.claude-3-sonnet-20240229-v1:0",
    "model_name": "Apac.anthropic.claude 3 Sonnet 20240229 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "apac.anthropic.claude-sonnet-4-20250514-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "apac.anthropic.claude-sonnet-4-20250514-v1:0",
    "model_name": "Apac.anthropic.claude Sonnet 4 20250514 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "ca-central-1/meta.llama3-70b-instruct-v1:0": {
    "input_cost_per_token": 0.00000305,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000403,
    "model_id": "ca-central-1/meta.llama3-70b-instruct-v1:0",
    "model_name": "Meta.llama3 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3.05,
    "output_cost_per_million": 4.03,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ca-central-1/meta.llama3-8b-instruct-v1:0": {
    "input_cost_per_token": 3.5e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 6.9e-7,
    "model_id": "ca-central-1/meta.llama3-8b-instruct-v1:0",
    "model_name": "Meta.llama3 8b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.35,
    "output_cost_per_million": 0.69,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "cohere.command-light-text-v14": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 6e-7,
    "supports_tool_choice": true,
    "model_id": "cohere.command-light-text-v14",
    "model_name": "Cohere.command Light Text V14",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "cohere.command-r-plus-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_tool_choice": true,
    "model_id": "cohere.command-r-plus-v1:0",
    "model_name": "Cohere.command R Plus V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "cohere.command-r-v1:0": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0000015,
    "supports_tool_choice": true,
    "model_id": "cohere.command-r-v1:0",
    "model_name": "Cohere.command R V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "cohere.command-text-v14": {
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000002,
    "supports_tool_choice": true,
    "model_id": "cohere.command-text-v14",
    "model_name": "Cohere.command Text V14",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "cohere.embed-english-v3": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 512,
    "max_tokens": 512,
    "output_cost_per_token": 0,
    "supports_embedding_image_input": true,
    "model_id": "cohere.embed-english-v3",
    "model_name": "Cohere.embed English V3",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "cohere.embed-multilingual-v3": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 512,
    "max_tokens": 512,
    "output_cost_per_token": 0,
    "supports_embedding_image_input": true,
    "model_id": "cohere.embed-multilingual-v3",
    "model_name": "Cohere.embed Multilingual V3",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "cohere.rerank-v3-5:0": {
    "input_cost_per_query": 0.002,
    "input_cost_per_token": 0,
    "max_document_chunks_per_query": 100,
    "max_input_tokens": 32000,
    "max_output_tokens": 32000,
    "max_query_tokens": 32000,
    "max_tokens": 32000,
    "max_tokens_per_document_chunk": 512,
    "output_cost_per_token": 0,
    "model_id": "cohere.rerank-v3-5:0",
    "model_name": "Cohere.rerank V3 5:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-central-1/1-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.01635,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.01635,
    "supports_tool_choice": true,
    "model_id": "eu-central-1/1-month-commitment/anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-central-1/1-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.0415,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.0415,
    "model_id": "eu-central-1/1-month-commitment/anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-central-1/1-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.0415,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.0415,
    "supports_tool_choice": true,
    "model_id": "eu-central-1/1-month-commitment/anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-central-1/6-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.009083,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.009083,
    "supports_tool_choice": true,
    "model_id": "eu-central-1/6-month-commitment/anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-central-1/6-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.02305,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.02305,
    "model_id": "eu-central-1/6-month-commitment/anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-central-1/6-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.02305,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.02305,
    "supports_tool_choice": true,
    "model_id": "eu-central-1/6-month-commitment/anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-central-1/anthropic.claude-instant-v1": {
    "input_cost_per_token": 0.00000248,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.00000838,
    "supports_tool_choice": true,
    "model_id": "eu-central-1/anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2.48,
    "output_cost_per_million": 8.379999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-central-1/anthropic.claude-v1": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "model_id": "eu-central-1/anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-central-1/anthropic.claude-v2:1": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true,
    "model_id": "eu-central-1/anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-west-1/meta.llama3-70b-instruct-v1:0": {
    "input_cost_per_token": 0.00000286,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000378,
    "model_id": "eu-west-1/meta.llama3-70b-instruct-v1:0",
    "model_name": "Meta.llama3 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2.8600000000000003,
    "output_cost_per_million": 3.78,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-west-1/meta.llama3-8b-instruct-v1:0": {
    "input_cost_per_token": 3.2e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 6.5e-7,
    "model_id": "eu-west-1/meta.llama3-8b-instruct-v1:0",
    "model_name": "Meta.llama3 8b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.32,
    "output_cost_per_million": 0.65,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-west-2/meta.llama3-70b-instruct-v1:0": {
    "input_cost_per_token": 0.00000345,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000455,
    "model_id": "eu-west-2/meta.llama3-70b-instruct-v1:0",
    "model_name": "Meta.llama3 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3.45,
    "output_cost_per_million": 4.55,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-west-2/meta.llama3-8b-instruct-v1:0": {
    "input_cost_per_token": 3.9e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 7.8e-7,
    "model_id": "eu-west-2/meta.llama3-8b-instruct-v1:0",
    "model_name": "Meta.llama3 8b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.39,
    "output_cost_per_million": 0.78,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-west-3/mistral.mistral-7b-instruct-v0:2": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 2.6e-7,
    "supports_tool_choice": true,
    "model_id": "eu-west-3/mistral.mistral-7b-instruct-v0:2",
    "model_name": "Mistral.mistral 7b Instruct V0:2",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.26,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-west-3/mistral.mistral-large-2402-v1:0": {
    "input_cost_per_token": 0.0000104,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.0000312,
    "supports_function_calling": true,
    "model_id": "eu-west-3/mistral.mistral-large-2402-v1:0",
    "model_name": "Mistral.mistral Large 2402 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 10.4,
    "output_cost_per_million": 31.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu-west-3/mistral.mixtral-8x7b-instruct-v0:1": {
    "input_cost_per_token": 5.9e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 9.1e-7,
    "supports_tool_choice": true,
    "model_id": "eu-west-3/mistral.mixtral-8x7b-instruct-v0:1",
    "model_name": "Mistral.mixtral 8x7b Instruct V0:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.59,
    "output_cost_per_million": 0.9099999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu.amazon.nova-lite-v1:0": {
    "input_cost_per_token": 7.8e-8,
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 3.12e-7,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true,
    "model_id": "eu.amazon.nova-lite-v1:0",
    "model_name": "Eu.amazon.nova Lite V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.078,
    "output_cost_per_million": 0.312,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "eu.amazon.nova-micro-v1:0": {
    "input_cost_per_token": 4.6e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 1.84e-7,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "model_id": "eu.amazon.nova-micro-v1:0",
    "model_name": "Eu.amazon.nova Micro V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.046,
    "output_cost_per_million": 0.184,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "eu.amazon.nova-pro-v1:0": {
    "input_cost_per_token": 0.00000105,
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 0.0000042,
    "source": "https://aws.amazon.com/bedrock/pricing/",
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true,
    "model_id": "eu.amazon.nova-pro-v1:0",
    "model_name": "Eu.amazon.nova Pro V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 1.0499999999999998,
    "output_cost_per_million": 4.199999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "eu.anthropic.claude-3-5-haiku-20241022-v1:0": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000125,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "eu.anthropic.claude-3-5-haiku-20241022-v1:0",
    "model_name": "Eu.anthropic.claude 3 5 Haiku 20241022 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "eu.anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
    "model_name": "Eu.anthropic.claude 3 5 Sonnet 20240620 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "eu.anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "eu.anthropic.claude-3-5-sonnet-20241022-v2:0",
    "model_name": "Eu.anthropic.claude 3 5 Sonnet 20241022 V2:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "eu.anthropic.claude-3-7-sonnet-20250219-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "eu.anthropic.claude-3-7-sonnet-20250219-v1:0",
    "model_name": "Eu.anthropic.claude 3 7 Sonnet 20250219 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "eu.anthropic.claude-3-haiku-20240307-v1:0": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00000125,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "eu.anthropic.claude-3-haiku-20240307-v1:0",
    "model_name": "Eu.anthropic.claude 3 Haiku 20240307 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "eu.anthropic.claude-3-opus-20240229-v1:0": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000075,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "eu.anthropic.claude-3-opus-20240229-v1:0",
    "model_name": "Eu.anthropic.claude 3 Opus 20240229 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "eu.anthropic.claude-3-sonnet-20240229-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "eu.anthropic.claude-3-sonnet-20240229-v1:0",
    "model_name": "Eu.anthropic.claude 3 Sonnet 20240229 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "eu.anthropic.claude-opus-4-1-20250805-v1:0": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "eu.anthropic.claude-opus-4-1-20250805-v1:0",
    "model_name": "Eu.anthropic.claude Opus 4 1 20250805 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "eu.anthropic.claude-opus-4-20250514-v1:0": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "eu.anthropic.claude-opus-4-20250514-v1:0",
    "model_name": "Eu.anthropic.claude Opus 4 20250514 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "eu.anthropic.claude-sonnet-4-20250514-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "eu.anthropic.claude-sonnet-4-20250514-v1:0",
    "model_name": "Eu.anthropic.claude Sonnet 4 20250514 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "eu.meta.llama3-2-1b-instruct-v1:0": {
    "input_cost_per_token": 1.3e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 1.3e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "eu.meta.llama3-2-1b-instruct-v1:0",
    "model_name": "Eu.meta.llama3 2 1b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.13,
    "output_cost_per_million": 0.13,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu.meta.llama3-2-3b-instruct-v1:0": {
    "input_cost_per_token": 1.9e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 1.9e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "eu.meta.llama3-2-3b-instruct-v1:0",
    "model_name": "Eu.meta.llama3 2 3b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.19,
    "output_cost_per_million": 0.19,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "eu.mistral.pixtral-large-2502-v1:0": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "eu.mistral.pixtral-large-2502-v1:0",
    "model_name": "Eu.mistral.pixtral Large 2502 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "invoke/anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "metadata": {
      "notes": "Anthropic via Invoke route does not currently support pdf input."
    },
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "invoke/anthropic.claude-3-5-sonnet-20240620-v1:0",
    "model_name": "Anthropic.claude 3 5 Sonnet 20240620 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "max-x-max/50-steps/stability.stable-diffusion-xl-v0": {
    "max_input_tokens": 77,
    "max_tokens": 77,
    "output_cost_per_image": 0.036,
    "model_id": "max-x-max/50-steps/stability.stable-diffusion-xl-v0",
    "model_name": "Stability.stable Diffusion Xl V0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "max-x-max/max-steps/stability.stable-diffusion-xl-v0": {
    "max_input_tokens": 77,
    "max_tokens": 77,
    "output_cost_per_image": 0.072,
    "model_id": "max-x-max/max-steps/stability.stable-diffusion-xl-v0",
    "model_name": "Stability.stable Diffusion Xl V0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama2-13b-chat-v1": {
    "input_cost_per_token": 7.5e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000001,
    "model_id": "meta.llama2-13b-chat-v1",
    "model_name": "Meta.llama2 13b Chat V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.75,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama2-70b-chat-v1": {
    "input_cost_per_token": 0.00000195,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00000256,
    "model_id": "meta.llama2-70b-chat-v1",
    "model_name": "Meta.llama2 70b Chat V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 1.95,
    "output_cost_per_million": 2.56,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama3-1-405b-instruct-v1:0": {
    "input_cost_per_token": 0.00000532,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000016,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "meta.llama3-1-405b-instruct-v1:0",
    "model_name": "Meta.llama3 1 405b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 5.32,
    "output_cost_per_million": 16,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama3-1-70b-instruct-v1:0": {
    "input_cost_per_token": 9.9e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 128000,
    "output_cost_per_token": 9.9e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "meta.llama3-1-70b-instruct-v1:0",
    "model_name": "Meta.llama3 1 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.9900000000000001,
    "output_cost_per_million": 0.9900000000000001,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama3-1-8b-instruct-v1:0": {
    "input_cost_per_token": 2.2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 128000,
    "output_cost_per_token": 2.2e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "meta.llama3-1-8b-instruct-v1:0",
    "model_name": "Meta.llama3 1 8b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.22,
    "output_cost_per_million": 0.22,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama3-2-11b-instruct-v1:0": {
    "input_cost_per_token": 3.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 3.5e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "supports_vision": true,
    "model_id": "meta.llama3-2-11b-instruct-v1:0",
    "model_name": "Meta.llama3 2 11b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.35,
    "output_cost_per_million": 0.35,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama3-2-1b-instruct-v1:0": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 1e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "meta.llama3-2-1b-instruct-v1:0",
    "model_name": "Meta.llama3 2 1b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama3-2-3b-instruct-v1:0": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 1.5e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "meta.llama3-2-3b-instruct-v1:0",
    "model_name": "Meta.llama3 2 3b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama3-2-90b-instruct-v1:0": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "supports_vision": true,
    "model_id": "meta.llama3-2-90b-instruct-v1:0",
    "model_name": "Meta.llama3 2 90b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama3-3-70b-instruct-v1:0": {
    "input_cost_per_token": 7.2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 7.2e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "meta.llama3-3-70b-instruct-v1:0",
    "model_name": "Meta.llama3 3 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.72,
    "output_cost_per_million": 0.72,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama3-70b-instruct-v1:0": {
    "input_cost_per_token": 0.00000265,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000035,
    "model_id": "meta.llama3-70b-instruct-v1:0",
    "model_name": "Meta.llama3 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2.65,
    "output_cost_per_million": 3.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama3-8b-instruct-v1:0": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 6e-7,
    "model_id": "meta.llama3-8b-instruct-v1:0",
    "model_name": "Meta.llama3 8b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama4-maverick-17b-instruct-v1:0": {
    "input_cost_per_token": 2.4e-7,
    "input_cost_per_token_batches": 1.2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 9.7e-7,
    "output_cost_per_token_batches": 4.85e-7,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "meta.llama4-maverick-17b-instruct-v1:0",
    "model_name": "Meta.llama4 Maverick 17b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.24,
    "output_cost_per_million": 0.9700000000000001,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta.llama4-scout-17b-instruct-v1:0": {
    "input_cost_per_token": 1.7e-7,
    "input_cost_per_token_batches": 8.5e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 6.6e-7,
    "output_cost_per_token_batches": 3.3e-7,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "meta.llama4-scout-17b-instruct-v1:0",
    "model_name": "Meta.llama4 Scout 17b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.16999999999999998,
    "output_cost_per_million": 0.66,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral.mistral-7b-instruct-v0:2": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 2e-7,
    "supports_tool_choice": true,
    "model_id": "mistral.mistral-7b-instruct-v0:2",
    "model_name": "Mistral.mistral 7b Instruct V0:2",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral.mistral-large-2402-v1:0": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "supports_function_calling": true,
    "model_id": "mistral.mistral-large-2402-v1:0",
    "model_name": "Mistral.mistral Large 2402 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral.mistral-large-2407-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000009,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "mistral.mistral-large-2407-v1:0",
    "model_name": "Mistral.mistral Large 2407 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 9,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral.mistral-small-2402-v1:0": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "model_id": "mistral.mistral-small-2402-v1:0",
    "model_name": "Mistral.mistral Small 2402 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral.mixtral-8x7b-instruct-v0:1": {
    "input_cost_per_token": 4.5e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 7e-7,
    "supports_tool_choice": true,
    "model_id": "mistral.mixtral-8x7b-instruct-v0:1",
    "model_name": "Mistral.mixtral 8x7b Instruct V0:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.44999999999999996,
    "output_cost_per_million": 0.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openai.gpt-oss-120b-1:0": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "openai.gpt-oss-120b-1:0",
    "model_name": "Openai.GPT Oss 120b 1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "openai.gpt-oss-20b-1:0": {
    "input_cost_per_token": 7e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "openai.gpt-oss-20b-1:0",
    "model_name": "Openai.GPT Oss 20b 1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.07,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "sa-east-1/meta.llama3-70b-instruct-v1:0": {
    "input_cost_per_token": 0.00000445,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000588,
    "model_id": "sa-east-1/meta.llama3-70b-instruct-v1:0",
    "model_name": "Meta.llama3 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 4.45,
    "output_cost_per_million": 5.88,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sa-east-1/meta.llama3-8b-instruct-v1:0": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000101,
    "model_id": "sa-east-1/meta.llama3-8b-instruct-v1:0",
    "model_name": "Meta.llama3 8b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.01,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "stability.sd3-5-large-v1:0": {
    "max_input_tokens": 77,
    "max_tokens": 77,
    "output_cost_per_image": 0.08,
    "model_id": "stability.sd3-5-large-v1:0",
    "model_name": "Stability.sd3 5 Large V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "stability.sd3-large-v1:0": {
    "max_input_tokens": 77,
    "max_tokens": 77,
    "output_cost_per_image": 0.08,
    "model_id": "stability.sd3-large-v1:0",
    "model_name": "Stability.sd3 Large V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "stability.stable-image-core-v1:0": {
    "max_input_tokens": 77,
    "max_tokens": 77,
    "output_cost_per_image": 0.04,
    "model_id": "stability.stable-image-core-v1:0",
    "model_name": "Stability.stable Image Core V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "stability.stable-image-core-v1:1": {
    "max_input_tokens": 77,
    "max_tokens": 77,
    "output_cost_per_image": 0.04,
    "model_id": "stability.stable-image-core-v1:1",
    "model_name": "Stability.stable Image Core V1:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "stability.stable-image-ultra-v1:0": {
    "max_input_tokens": 77,
    "max_tokens": 77,
    "output_cost_per_image": 0.14,
    "model_id": "stability.stable-image-ultra-v1:0",
    "model_name": "Stability.stable Image Ultra V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "stability.stable-image-ultra-v1:1": {
    "max_input_tokens": 77,
    "max_tokens": 77,
    "output_cost_per_image": 0.14,
    "model_id": "stability.stable-image-ultra-v1:1",
    "model_name": "Stability.stable Image Ultra V1:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/1-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.011,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.011,
    "supports_tool_choice": true,
    "model_id": "us-east-1/1-month-commitment/anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/1-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.0175,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.0175,
    "model_id": "us-east-1/1-month-commitment/anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/1-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.0175,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.0175,
    "supports_tool_choice": true,
    "model_id": "us-east-1/1-month-commitment/anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/6-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.00611,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.00611,
    "supports_tool_choice": true,
    "model_id": "us-east-1/6-month-commitment/anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/6-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.00972,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.00972,
    "model_id": "us-east-1/6-month-commitment/anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/6-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.00972,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.00972,
    "supports_tool_choice": true,
    "model_id": "us-east-1/6-month-commitment/anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/anthropic.claude-instant-v1": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.0000024,
    "supports_tool_choice": true,
    "model_id": "us-east-1/anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 2.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/anthropic.claude-v1": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true,
    "model_id": "us-east-1/anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/anthropic.claude-v2:1": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true,
    "model_id": "us-east-1/anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/meta.llama3-70b-instruct-v1:0": {
    "input_cost_per_token": 0.00000265,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000035,
    "model_id": "us-east-1/meta.llama3-70b-instruct-v1:0",
    "model_name": "Meta.llama3 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2.65,
    "output_cost_per_million": 3.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/meta.llama3-8b-instruct-v1:0": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 6e-7,
    "model_id": "us-east-1/meta.llama3-8b-instruct-v1:0",
    "model_name": "Meta.llama3 8b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/mistral.mistral-7b-instruct-v0:2": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 2e-7,
    "supports_tool_choice": true,
    "model_id": "us-east-1/mistral.mistral-7b-instruct-v0:2",
    "model_name": "Mistral.mistral 7b Instruct V0:2",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/mistral.mistral-large-2402-v1:0": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "supports_function_calling": true,
    "model_id": "us-east-1/mistral.mistral-large-2402-v1:0",
    "model_name": "Mistral.mistral Large 2402 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-east-1/mistral.mixtral-8x7b-instruct-v0:1": {
    "input_cost_per_token": 4.5e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 7e-7,
    "supports_tool_choice": true,
    "model_id": "us-east-1/mistral.mixtral-8x7b-instruct-v0:1",
    "model_name": "Mistral.mixtral 8x7b Instruct V0:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.44999999999999996,
    "output_cost_per_million": 0.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-east-1/amazon.nova-pro-v1:0": {
    "input_cost_per_token": 9.6e-7,
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 0.00000384,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true,
    "model_id": "us-gov-east-1/amazon.nova-pro-v1:0",
    "model_name": "Amazon.nova Pro V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.96,
    "output_cost_per_million": 3.84,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us-gov-east-1/amazon.titan-embed-text-v1": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "output_vector_size": 1536,
    "model_id": "us-gov-east-1/amazon.titan-embed-text-v1",
    "model_name": "Amazon.titan Embed Text V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-east-1/amazon.titan-embed-text-v2:0": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "output_vector_size": 1024,
    "model_id": "us-gov-east-1/amazon.titan-embed-text-v2:0",
    "model_name": "Amazon.titan Embed Text V2:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-east-1/amazon.titan-text-express-v1": {
    "input_cost_per_token": 0.0000013,
    "max_input_tokens": 42000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "output_cost_per_token": 0.0000017,
    "model_id": "us-gov-east-1/amazon.titan-text-express-v1",
    "model_name": "Amazon.titan Text Express V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 1.3,
    "output_cost_per_million": 1.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-east-1/amazon.titan-text-lite-v1": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 42000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "output_cost_per_token": 4e-7,
    "model_id": "us-gov-east-1/amazon.titan-text-lite-v1",
    "model_name": "Amazon.titan Text Lite V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-east-1/amazon.titan-text-premier-v1:0": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 42000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.0000015,
    "model_id": "us-gov-east-1/amazon.titan-text-premier-v1:0",
    "model_name": "Amazon.titan Text Premier V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.0000036,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000018,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0",
    "model_name": "Anthropic.claude 3 5 Sonnet 20240620 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3.5999999999999996,
    "output_cost_per_million": 18,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0",
    "model_name": "Anthropic.claude 3 Haiku 20240307 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us-gov-east-1/meta.llama3-70b-instruct-v1:0": {
    "input_cost_per_token": 0.00000265,
    "max_input_tokens": 8000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0.0000035,
    "supports_pdf_input": true,
    "model_id": "us-gov-east-1/meta.llama3-70b-instruct-v1:0",
    "model_name": "Meta.llama3 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2.65,
    "output_cost_per_million": 3.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-east-1/meta.llama3-8b-instruct-v1:0": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 8000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0.00000265,
    "supports_pdf_input": true,
    "model_id": "us-gov-east-1/meta.llama3-8b-instruct-v1:0",
    "model_name": "Meta.llama3 8b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 2.65,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-west-1/amazon.nova-pro-v1:0": {
    "input_cost_per_token": 9.6e-7,
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 0.00000384,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true,
    "model_id": "us-gov-west-1/amazon.nova-pro-v1:0",
    "model_name": "Amazon.nova Pro V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.96,
    "output_cost_per_million": 3.84,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us-gov-west-1/amazon.titan-embed-text-v1": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "output_vector_size": 1536,
    "model_id": "us-gov-west-1/amazon.titan-embed-text-v1",
    "model_name": "Amazon.titan Embed Text V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-west-1/amazon.titan-embed-text-v2:0": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "output_vector_size": 1024,
    "model_id": "us-gov-west-1/amazon.titan-embed-text-v2:0",
    "model_name": "Amazon.titan Embed Text V2:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-west-1/amazon.titan-text-express-v1": {
    "input_cost_per_token": 0.0000013,
    "max_input_tokens": 42000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "output_cost_per_token": 0.0000017,
    "model_id": "us-gov-west-1/amazon.titan-text-express-v1",
    "model_name": "Amazon.titan Text Express V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 1.3,
    "output_cost_per_million": 1.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-west-1/amazon.titan-text-lite-v1": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 42000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "output_cost_per_token": 4e-7,
    "model_id": "us-gov-west-1/amazon.titan-text-lite-v1",
    "model_name": "Amazon.titan Text Lite V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-west-1/amazon.titan-text-premier-v1:0": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 42000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.0000015,
    "model_id": "us-gov-west-1/amazon.titan-text-premier-v1:0",
    "model_name": "Amazon.titan Text Premier V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.0000036,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000018,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0",
    "model_name": "Anthropic.claude 3 5 Sonnet 20240620 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3.5999999999999996,
    "output_cost_per_million": 18,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0",
    "model_name": "Anthropic.claude 3 Haiku 20240307 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us-gov-west-1/meta.llama3-70b-instruct-v1:0": {
    "input_cost_per_token": 0.00000265,
    "max_input_tokens": 8000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0.0000035,
    "supports_pdf_input": true,
    "model_id": "us-gov-west-1/meta.llama3-70b-instruct-v1:0",
    "model_name": "Meta.llama3 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2.65,
    "output_cost_per_million": 3.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-gov-west-1/meta.llama3-8b-instruct-v1:0": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 8000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0.00000265,
    "supports_pdf_input": true,
    "model_id": "us-gov-west-1/meta.llama3-8b-instruct-v1:0",
    "model_name": "Meta.llama3 8b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 2.65,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-1/meta.llama3-70b-instruct-v1:0": {
    "input_cost_per_token": 0.00000265,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000035,
    "model_id": "us-west-1/meta.llama3-70b-instruct-v1:0",
    "model_name": "Meta.llama3 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2.65,
    "output_cost_per_million": 3.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-1/meta.llama3-8b-instruct-v1:0": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 6e-7,
    "model_id": "us-west-1/meta.llama3-8b-instruct-v1:0",
    "model_name": "Meta.llama3 8b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-2/1-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.011,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.011,
    "supports_tool_choice": true,
    "model_id": "us-west-2/1-month-commitment/anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-2/1-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.0175,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.0175,
    "model_id": "us-west-2/1-month-commitment/anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-2/1-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.0175,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.0175,
    "supports_tool_choice": true,
    "model_id": "us-west-2/1-month-commitment/anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-2/6-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.00611,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.00611,
    "supports_tool_choice": true,
    "model_id": "us-west-2/6-month-commitment/anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-2/6-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.00972,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.00972,
    "model_id": "us-west-2/6-month-commitment/anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-2/6-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.00972,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_second": 0.00972,
    "supports_tool_choice": true,
    "model_id": "us-west-2/6-month-commitment/anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-2/anthropic.claude-instant-v1": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.0000024,
    "supports_tool_choice": true,
    "model_id": "us-west-2/anthropic.claude-instant-v1",
    "model_name": "Anthropic.claude Instant V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 2.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-2/anthropic.claude-v1": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true,
    "model_id": "us-west-2/anthropic.claude-v1",
    "model_name": "Anthropic.claude V1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-2/anthropic.claude-v2:1": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true,
    "model_id": "us-west-2/anthropic.claude-v2:1",
    "model_name": "Anthropic.claude V2:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-2/mistral.mistral-7b-instruct-v0:2": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 2e-7,
    "supports_tool_choice": true,
    "model_id": "us-west-2/mistral.mistral-7b-instruct-v0:2",
    "model_name": "Mistral.mistral 7b Instruct V0:2",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-2/mistral.mistral-large-2402-v1:0": {
    "input_cost_per_token": 0.000008,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000024,
    "supports_function_calling": true,
    "model_id": "us-west-2/mistral.mistral-large-2402-v1:0",
    "model_name": "Mistral.mistral Large 2402 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us-west-2/mistral.mixtral-8x7b-instruct-v0:1": {
    "input_cost_per_token": 4.5e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 7e-7,
    "supports_tool_choice": true,
    "model_id": "us-west-2/mistral.mixtral-8x7b-instruct-v0:1",
    "model_name": "Mistral.mixtral 8x7b Instruct V0:1",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.44999999999999996,
    "output_cost_per_million": 0.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us.amazon.nova-lite-v1:0": {
    "input_cost_per_token": 6e-8,
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 2.4e-7,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true,
    "model_id": "us.amazon.nova-lite-v1:0",
    "model_name": "Us.amazon.nova Lite V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.06,
    "output_cost_per_million": 0.24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us.amazon.nova-micro-v1:0": {
    "input_cost_per_token": 3.5e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 1.4e-7,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "model_id": "us.amazon.nova-micro-v1:0",
    "model_name": "Us.amazon.nova Micro V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.035,
    "output_cost_per_million": 0.14,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "us.amazon.nova-premier-v1:0": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 1000000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 0.0000125,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": false,
    "supports_response_schema": true,
    "supports_vision": true,
    "model_id": "us.amazon.nova-premier-v1:0",
    "model_name": "Us.amazon.nova Premier V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 12.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us.amazon.nova-pro-v1:0": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "output_cost_per_token": 0.0000032,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true,
    "model_id": "us.amazon.nova-pro-v1:0",
    "model_name": "Us.amazon.nova Pro V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 3.1999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us.anthropic.claude-3-5-haiku-20241022-v1:0": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000004,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
    "model_name": "Us.anthropic.claude 3 5 Haiku 20241022 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": 8e-8,
    "cache_read_cost_per_million": 0.08,
    "cache_write_cost_per_token": 0.000001,
    "cache_write_cost_per_million": 1,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "us.anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
    "model_name": "Us.anthropic.claude 3 5 Sonnet 20240620 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
    "model_name": "Us.anthropic.claude 3 5 Sonnet 20241022 V2:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
    "model_name": "Us.anthropic.claude 3 7 Sonnet 20250219 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us.anthropic.claude-3-haiku-20240307-v1:0": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00000125,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "us.anthropic.claude-3-haiku-20240307-v1:0",
    "model_name": "Us.anthropic.claude 3 Haiku 20240307 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us.anthropic.claude-3-opus-20240229-v1:0": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000075,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "us.anthropic.claude-3-opus-20240229-v1:0",
    "model_name": "Us.anthropic.claude 3 Opus 20240229 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us.anthropic.claude-3-sonnet-20240229-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "us.anthropic.claude-3-sonnet-20240229-v1:0",
    "model_name": "Us.anthropic.claude 3 Sonnet 20240229 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us.anthropic.claude-opus-4-1-20250805-v1:0": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "us.anthropic.claude-opus-4-1-20250805-v1:0",
    "model_name": "Us.anthropic.claude Opus 4 1 20250805 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us.anthropic.claude-opus-4-20250514-v1:0": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "us.anthropic.claude-opus-4-20250514-v1:0",
    "model_name": "Us.anthropic.claude Opus 4 20250514 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us.anthropic.claude-sonnet-4-20250514-v1:0": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "us.anthropic.claude-sonnet-4-20250514-v1:0",
    "model_name": "Us.anthropic.claude Sonnet 4 20250514 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "us.deepseek.r1-v1:0": {
    "input_cost_per_token": 0.00000135,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0000054,
    "supports_function_calling": false,
    "supports_reasoning": true,
    "supports_tool_choice": false,
    "model_id": "us.deepseek.r1-v1:0",
    "model_name": "Us.deepseek.r1 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 1.35,
    "output_cost_per_million": 5.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us.meta.llama3-1-405b-instruct-v1:0": {
    "input_cost_per_token": 0.00000532,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000016,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "us.meta.llama3-1-405b-instruct-v1:0",
    "model_name": "Us.meta.llama3 1 405b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 5.32,
    "output_cost_per_million": 16,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us.meta.llama3-1-70b-instruct-v1:0": {
    "input_cost_per_token": 9.9e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 128000,
    "output_cost_per_token": 9.9e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "us.meta.llama3-1-70b-instruct-v1:0",
    "model_name": "Us.meta.llama3 1 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.9900000000000001,
    "output_cost_per_million": 0.9900000000000001,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us.meta.llama3-1-8b-instruct-v1:0": {
    "input_cost_per_token": 2.2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 128000,
    "output_cost_per_token": 2.2e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "us.meta.llama3-1-8b-instruct-v1:0",
    "model_name": "Us.meta.llama3 1 8b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.22,
    "output_cost_per_million": 0.22,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us.meta.llama3-2-11b-instruct-v1:0": {
    "input_cost_per_token": 3.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 3.5e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "supports_vision": true,
    "model_id": "us.meta.llama3-2-11b-instruct-v1:0",
    "model_name": "Us.meta.llama3 2 11b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.35,
    "output_cost_per_million": 0.35,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us.meta.llama3-2-1b-instruct-v1:0": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 1e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "us.meta.llama3-2-1b-instruct-v1:0",
    "model_name": "Us.meta.llama3 2 1b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us.meta.llama3-2-3b-instruct-v1:0": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 1.5e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "us.meta.llama3-2-3b-instruct-v1:0",
    "model_name": "Us.meta.llama3 2 3b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us.meta.llama3-2-90b-instruct-v1:0": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "supports_vision": true,
    "model_id": "us.meta.llama3-2-90b-instruct-v1:0",
    "model_name": "Us.meta.llama3 2 90b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us.meta.llama3-3-70b-instruct-v1:0": {
    "input_cost_per_token": 7.2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 7.2e-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "us.meta.llama3-3-70b-instruct-v1:0",
    "model_name": "Us.meta.llama3 3 70b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.72,
    "output_cost_per_million": 0.72,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us.meta.llama4-maverick-17b-instruct-v1:0": {
    "input_cost_per_token": 2.4e-7,
    "input_cost_per_token_batches": 1.2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 9.7e-7,
    "output_cost_per_token_batches": 4.85e-7,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "us.meta.llama4-maverick-17b-instruct-v1:0",
    "model_name": "Us.meta.llama4 Maverick 17b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.24,
    "output_cost_per_million": 0.9700000000000001,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us.meta.llama4-scout-17b-instruct-v1:0": {
    "input_cost_per_token": 1.7e-7,
    "input_cost_per_token_batches": 8.5e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 6.6e-7,
    "output_cost_per_token_batches": 3.3e-7,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "us.meta.llama4-scout-17b-instruct-v1:0",
    "model_name": "Us.meta.llama4 Scout 17b Instruct V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 0.16999999999999998,
    "output_cost_per_million": 0.66,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "us.mistral.pixtral-large-2502-v1:0": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "model_id": "us.mistral.pixtral-large-2502-v1:0",
    "model_name": "Us.mistral.pixtral Large 2502 V1:0",
    "provider_id": "bedrock",
    "provider_name": "AWS Bedrock",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "cerebras/llama-3.3-70b": {
    "input_cost_per_token": 8.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.0000012,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "cerebras/llama-3.3-70b",
    "model_name": "Llama 3.3 70b",
    "provider_id": "cerebras",
    "provider_name": "Cerebras",
    "input_cost_per_million": 0.85,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "cerebras/llama3.1-70b": {
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "cerebras/llama3.1-70b",
    "model_name": "Llama 3.1 70B",
    "provider_id": "cerebras",
    "provider_name": "Cerebras",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "cerebras/llama3.1-8b": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 1e-7,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "cerebras/llama3.1-8b",
    "model_name": "Llama 3.1 8B",
    "provider_id": "cerebras",
    "provider_name": "Cerebras",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "cerebras/openai/gpt-oss-120b": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 6.9e-7,
    "source": "https://www.cerebras.ai/blog/openai-gpt-oss-120b-runs-fastest-on-cerebras",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "cerebras/openai/gpt-oss-120b",
    "model_name": "GPT Oss 120b",
    "provider_id": "cerebras",
    "provider_name": "Cerebras",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 0.69,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "cerebras/qwen-3-32b": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 8e-7,
    "source": "https://inference-docs.cerebras.ai/support/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "cerebras/qwen-3-32b",
    "model_name": "Qwen 3 32b",
    "provider_id": "cerebras",
    "provider_name": "Cerebras",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 0.7999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "@cf/meta/llama-2-7b-chat-fp16": {
    "input_cost_per_token": 0.000001923,
    "max_input_tokens": 3072,
    "max_output_tokens": 3072,
    "max_tokens": 3072,
    "output_cost_per_token": 0.000001923,
    "model_id": "@cf/meta/llama-2-7b-chat-fp16",
    "model_name": "Llama 2 7b Chat Fp16",
    "provider_id": "cloudflare",
    "provider_name": "Cloudflare",
    "input_cost_per_million": 1.923,
    "output_cost_per_million": 1.923,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "@cf/meta/llama-2-7b-chat-int8": {
    "input_cost_per_token": 0.000001923,
    "max_input_tokens": 2048,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0.000001923,
    "model_id": "@cf/meta/llama-2-7b-chat-int8",
    "model_name": "Llama 2 7b Chat Int8",
    "provider_id": "cloudflare",
    "provider_name": "Cloudflare",
    "input_cost_per_million": 1.923,
    "output_cost_per_million": 1.923,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "@cf/mistral/mistral-7b-instruct-v0.1": {
    "input_cost_per_token": 0.000001923,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000001923,
    "model_id": "@cf/mistral/mistral-7b-instruct-v0.1",
    "model_name": "Mistral (7B) Instruct",
    "provider_id": "cloudflare",
    "provider_name": "Cloudflare",
    "input_cost_per_million": 1.923,
    "output_cost_per_million": 1.923,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "@hf/thebloke/codellama-7b-instruct-awq": {
    "input_cost_per_token": 0.000001923,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000001923,
    "model_id": "@hf/thebloke/codellama-7b-instruct-awq",
    "model_name": "Codellama 7b Instruct Awq",
    "provider_id": "cloudflare",
    "provider_name": "Cloudflare",
    "input_cost_per_million": 1.923,
    "output_cost_per_million": 1.923,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "command": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000002,
    "model_id": "command",
    "model_name": "Command",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 1,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "command-a-03-2025": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 256000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "command-a-03-2025",
    "model_name": "Command A 03 2025",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "command-light": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 6e-7,
    "supports_tool_choice": true,
    "model_id": "command-light",
    "model_name": "Command Light",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "command-nightly": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000002,
    "model_id": "command-nightly",
    "model_name": "Command Nightly",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 1,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "command-r": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "command-r",
    "model_name": "Command R",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "command-r-08-2024": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "command-r-08-2024",
    "model_name": "Command R 08 2024",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "command-r-plus": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "command-r-plus",
    "model_name": "Command R Plus",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "command-r-plus-08-2024": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "command-r-plus-08-2024",
    "model_name": "Command R Plus 08 2024",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "command-r7b-12-2024": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 3.75e-8,
    "source": "https://docs.cohere.com/v2/docs/command-r7b",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "command-r7b-12-2024",
    "model_name": "Command R7b 12 2024",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.0375,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "embed-english-light-v2.0": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_token": 0,
    "model_id": "embed-english-light-v2.0",
    "model_name": "Embed English Light V2.0",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "embed-english-light-v3.0": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_token": 0,
    "model_id": "embed-english-light-v3.0",
    "model_name": "Embed English Light V3.0",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "embed-english-v2.0": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "embed-english-v2.0",
    "model_name": "Embed English V2.0",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "embed-english-v3.0": {
    "input_cost_per_image": 0.0001,
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 1024,
    "max_tokens": 1024,
    "metadata": {
      "notes": "'supports_image_input' is a deprecated field. Use 'supports_embedding_image_input' instead."
    },
    "output_cost_per_token": 0,
    "supports_embedding_image_input": true,
    "supports_image_input": true,
    "model_id": "embed-english-v3.0",
    "model_name": "Embed English V3.0",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "embed-multilingual-v2.0": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 768,
    "max_tokens": 768,
    "output_cost_per_token": 0,
    "model_id": "embed-multilingual-v2.0",
    "model_name": "Embed Multilingual V2.0",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "embed-multilingual-v3.0": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_token": 0,
    "supports_embedding_image_input": true,
    "model_id": "embed-multilingual-v3.0",
    "model_name": "Embed Multilingual V3.0",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "rerank-english-v2.0": {
    "input_cost_per_query": 0.002,
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_query_tokens": 2048,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "rerank-english-v2.0",
    "model_name": "Rerank English V2.0",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "rerank-english-v3.0": {
    "input_cost_per_query": 0.002,
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_query_tokens": 2048,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "rerank-english-v3.0",
    "model_name": "Rerank English V3.0",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "rerank-multilingual-v2.0": {
    "input_cost_per_query": 0.002,
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_query_tokens": 2048,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "rerank-multilingual-v2.0",
    "model_name": "Rerank Multilingual V2.0",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "rerank-multilingual-v3.0": {
    "input_cost_per_query": 0.002,
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_query_tokens": 2048,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "rerank-multilingual-v3.0",
    "model_name": "Rerank Multilingual V3.0",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "rerank-v3.5": {
    "input_cost_per_query": 0.002,
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_query_tokens": 2048,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "rerank-v3.5",
    "model_name": "Rerank V3.5",
    "provider_id": "cohere",
    "provider_name": "Cohere",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-coder": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 1000000,
    "max_output_tokens": 16384,
    "max_tokens": 1000000,
    "output_cost_per_token": 0.0000015,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "dashscope/qwen-coder",
    "model_name": "Qwen Coder",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-flash": {
    "max_input_tokens": 997952,
    "max_output_tokens": 32768,
    "max_tokens": 1000000,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 5e-8,
        "output_cost_per_token": 4e-7,
        "range": [
          0,
          256000
        ]
      },
      {
        "input_cost_per_token": 2.5e-7,
        "output_cost_per_token": 0.000002,
        "range": [
          256000,
          1000000
        ]
      }
    ],
    "model_id": "dashscope/qwen-flash",
    "model_name": "Qwen Flash",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-flash-2025-07-28": {
    "max_input_tokens": 997952,
    "max_output_tokens": 32768,
    "max_tokens": 1000000,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 5e-8,
        "output_cost_per_token": 4e-7,
        "range": [
          0,
          256000
        ]
      },
      {
        "input_cost_per_token": 2.5e-7,
        "output_cost_per_token": 0.000002,
        "range": [
          256000,
          1000000
        ]
      }
    ],
    "model_id": "dashscope/qwen-flash-2025-07-28",
    "model_name": "Qwen Flash 2025 07 28",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-max": {
    "input_cost_per_token": 0.0000016,
    "max_input_tokens": 30720,
    "max_output_tokens": 8192,
    "max_tokens": 32768,
    "output_cost_per_token": 0.0000064,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "dashscope/qwen-max",
    "model_name": "Qwen Max",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_million": 1.5999999999999999,
    "output_cost_per_million": 6.3999999999999995,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-plus": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 129024,
    "max_output_tokens": 16384,
    "max_tokens": 131072,
    "output_cost_per_token": 0.0000012,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "dashscope/qwen-plus",
    "model_name": "Qwen Plus",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-plus-2025-01-25": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 129024,
    "max_output_tokens": 8192,
    "max_tokens": 131072,
    "output_cost_per_token": 0.0000012,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "dashscope/qwen-plus-2025-01-25",
    "model_name": "Qwen Plus 2025 01 25",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-plus-2025-04-28": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 129024,
    "max_output_tokens": 16384,
    "max_tokens": 131072,
    "output_cost_per_reasoning_token": 0.000004,
    "output_cost_per_token": 0.0000012,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "dashscope/qwen-plus-2025-04-28",
    "model_name": "Qwen Plus 2025 04 28",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-plus-2025-07-14": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 129024,
    "max_output_tokens": 16384,
    "max_tokens": 131072,
    "output_cost_per_reasoning_token": 0.000004,
    "output_cost_per_token": 0.0000012,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "dashscope/qwen-plus-2025-07-14",
    "model_name": "Qwen Plus 2025 07 14",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-plus-2025-07-28": {
    "max_input_tokens": 997952,
    "max_output_tokens": 32768,
    "max_tokens": 1000000,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 4e-7,
        "output_cost_per_reasoning_token": 0.000004,
        "output_cost_per_token": 0.0000012,
        "range": [
          0,
          256000
        ]
      },
      {
        "input_cost_per_token": 0.0000012,
        "output_cost_per_reasoning_token": 0.000012,
        "output_cost_per_token": 0.0000036,
        "range": [
          256000,
          1000000
        ]
      }
    ],
    "model_id": "dashscope/qwen-plus-2025-07-28",
    "model_name": "Qwen Plus 2025 07 28",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-plus-2025-09-11": {
    "max_input_tokens": 997952,
    "max_output_tokens": 32768,
    "max_tokens": 1000000,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 4e-7,
        "output_cost_per_reasoning_token": 0.000004,
        "output_cost_per_token": 0.0000012,
        "range": [
          0,
          256000
        ]
      },
      {
        "input_cost_per_token": 0.0000012,
        "output_cost_per_reasoning_token": 0.000012,
        "output_cost_per_token": 0.0000036,
        "range": [
          256000,
          1000000
        ]
      }
    ],
    "model_id": "dashscope/qwen-plus-2025-09-11",
    "model_name": "Qwen Plus 2025 09 11",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-plus-latest": {
    "max_input_tokens": 997952,
    "max_output_tokens": 32768,
    "max_tokens": 1000000,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 4e-7,
        "output_cost_per_reasoning_token": 0.000004,
        "output_cost_per_token": 0.0000012,
        "range": [
          0,
          256000
        ]
      },
      {
        "input_cost_per_token": 0.0000012,
        "output_cost_per_reasoning_token": 0.000012,
        "output_cost_per_token": 0.0000036,
        "range": [
          256000,
          1000000
        ]
      }
    ],
    "model_id": "dashscope/qwen-plus-latest",
    "model_name": "Qwen Plus Latest",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-turbo": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 129024,
    "max_output_tokens": 16384,
    "max_tokens": 131072,
    "output_cost_per_reasoning_token": 5e-7,
    "output_cost_per_token": 2e-7,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "dashscope/qwen-turbo",
    "model_name": "Qwen Turbo",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-turbo-2024-11-01": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 1000000,
    "output_cost_per_token": 2e-7,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "dashscope/qwen-turbo-2024-11-01",
    "model_name": "Qwen Turbo 2024 11 01",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-turbo-2025-04-28": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 1000000,
    "max_output_tokens": 16384,
    "max_tokens": 1000000,
    "output_cost_per_reasoning_token": 5e-7,
    "output_cost_per_token": 2e-7,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "dashscope/qwen-turbo-2025-04-28",
    "model_name": "Qwen Turbo 2025 04 28",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen-turbo-latest": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 1000000,
    "max_output_tokens": 16384,
    "max_tokens": 1000000,
    "output_cost_per_reasoning_token": 5e-7,
    "output_cost_per_token": 2e-7,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "dashscope/qwen-turbo-latest",
    "model_name": "Qwen Turbo Latest",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen3-30b-a3b": {
    "max_input_tokens": 129024,
    "max_output_tokens": 16384,
    "max_tokens": 131072,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "dashscope/qwen3-30b-a3b",
    "model_name": "Qwen3 30b A3b",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen3-coder-flash": {
    "max_input_tokens": 997952,
    "max_output_tokens": 65536,
    "max_tokens": 1000000,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "cache_read_input_token_cost": 8e-8,
        "input_cost_per_token": 3e-7,
        "output_cost_per_token": 0.0000015,
        "range": [
          0,
          32000
        ]
      },
      {
        "cache_read_input_token_cost": 1.2e-7,
        "input_cost_per_token": 5e-7,
        "output_cost_per_token": 0.0000025,
        "range": [
          32000,
          128000
        ]
      },
      {
        "cache_read_input_token_cost": 2e-7,
        "input_cost_per_token": 8e-7,
        "output_cost_per_token": 0.000004,
        "range": [
          128000,
          256000
        ]
      },
      {
        "cache_read_input_token_cost": 4e-7,
        "input_cost_per_token": 0.0000016,
        "output_cost_per_token": 0.0000096,
        "range": [
          256000,
          1000000
        ]
      }
    ],
    "model_id": "dashscope/qwen3-coder-flash",
    "model_name": "Qwen3 Coder Flash",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen3-coder-flash-2025-07-28": {
    "max_input_tokens": 997952,
    "max_output_tokens": 65536,
    "max_tokens": 1000000,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 3e-7,
        "output_cost_per_token": 0.0000015,
        "range": [
          0,
          32000
        ]
      },
      {
        "input_cost_per_token": 5e-7,
        "output_cost_per_token": 0.0000025,
        "range": [
          32000,
          128000
        ]
      },
      {
        "input_cost_per_token": 8e-7,
        "output_cost_per_token": 0.000004,
        "range": [
          128000,
          256000
        ]
      },
      {
        "input_cost_per_token": 0.0000016,
        "output_cost_per_token": 0.0000096,
        "range": [
          256000,
          1000000
        ]
      }
    ],
    "model_id": "dashscope/qwen3-coder-flash-2025-07-28",
    "model_name": "Qwen3 Coder Flash 2025 07 28",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen3-coder-plus": {
    "max_input_tokens": 997952,
    "max_output_tokens": 65536,
    "max_tokens": 1000000,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "cache_read_input_token_cost": 1e-7,
        "input_cost_per_token": 0.000001,
        "output_cost_per_token": 0.000005,
        "range": [
          0,
          32000
        ]
      },
      {
        "cache_read_input_token_cost": 1.8e-7,
        "input_cost_per_token": 0.0000018,
        "output_cost_per_token": 0.000009,
        "range": [
          32000,
          128000
        ]
      },
      {
        "cache_read_input_token_cost": 3e-7,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "range": [
          128000,
          256000
        ]
      },
      {
        "cache_read_input_token_cost": 6e-7,
        "input_cost_per_token": 0.000006,
        "output_cost_per_token": 0.00006,
        "range": [
          256000,
          1000000
        ]
      }
    ],
    "model_id": "dashscope/qwen3-coder-plus",
    "model_name": "Qwen3 Coder Plus",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen3-coder-plus-2025-07-22": {
    "max_input_tokens": 997952,
    "max_output_tokens": 65536,
    "max_tokens": 1000000,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 0.000001,
        "output_cost_per_token": 0.000005,
        "range": [
          0,
          32000
        ]
      },
      {
        "input_cost_per_token": 0.0000018,
        "output_cost_per_token": 0.000009,
        "range": [
          32000,
          128000
        ]
      },
      {
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "range": [
          128000,
          256000
        ]
      },
      {
        "input_cost_per_token": 0.000006,
        "output_cost_per_token": 0.00006,
        "range": [
          256000,
          1000000
        ]
      }
    ],
    "model_id": "dashscope/qwen3-coder-plus-2025-07-22",
    "model_name": "Qwen3 Coder Plus 2025 07 22",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwen3-max-preview": {
    "max_input_tokens": 258048,
    "max_output_tokens": 65536,
    "max_tokens": 262144,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 0.0000012,
        "output_cost_per_token": 0.000006,
        "range": [
          0,
          32000
        ]
      },
      {
        "input_cost_per_token": 0.0000024,
        "output_cost_per_token": 0.000012,
        "range": [
          32000,
          128000
        ]
      },
      {
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "range": [
          128000,
          252000
        ]
      }
    ],
    "model_id": "dashscope/qwen3-max-preview",
    "model_name": "Qwen3 Max Preview",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dashscope/qwq-plus": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 98304,
    "max_output_tokens": 8192,
    "max_tokens": 131072,
    "output_cost_per_token": 0.0000024,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "dashscope/qwq-plus",
    "model_name": "Qwq Plus",
    "provider_id": "dashscope",
    "provider_name": "Dashscope",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 2.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "databricks-bge-large-en": {
    "input_cost_per_token": 1.0003e-7,
    "input_dbu_cost_per_token": 0.000001429,
    "max_input_tokens": 512,
    "max_tokens": 512,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "output_cost_per_token": 0,
    "output_dbu_cost_per_token": 0,
    "output_vector_size": 1024,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "model_id": "databricks-bge-large-en",
    "model_name": "Databricks Bge Large En",
    "provider_id": "databricks",
    "provider_name": "Databricks",
    "max_output_tokens": null,
    "input_cost_per_million": 0.10003000000000001,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "databricks-claude-3-7-sonnet": {
    "input_cost_per_token": 0.0000025,
    "input_dbu_cost_per_token": 0.00003571,
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 200000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Claude 3.7 conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "output_cost_per_token": 0.000017857,
    "output_db_cost_per_token": 0.000214286,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "databricks-claude-3-7-sonnet",
    "model_name": "Databricks Claude 3 7 Sonnet",
    "provider_id": "databricks",
    "provider_name": "Databricks",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 17.857,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "databricks-gte-large-en": {
    "input_cost_per_token": 1.2999e-7,
    "input_dbu_cost_per_token": 0.000001857,
    "max_input_tokens": 8192,
    "max_tokens": 8192,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "output_cost_per_token": 0,
    "output_dbu_cost_per_token": 0,
    "output_vector_size": 1024,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "model_id": "databricks-gte-large-en",
    "model_name": "Databricks Gte Large En",
    "provider_id": "databricks",
    "provider_name": "Databricks",
    "max_output_tokens": null,
    "input_cost_per_million": 0.12999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "databricks-llama-2-70b-chat": {
    "input_cost_per_token": 5.0001e-7,
    "input_dbu_cost_per_token": 0.000007143,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "output_cost_per_token": 0.0000015,
    "output_dbu_cost_per_token": 0.000021429,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_tool_choice": true,
    "model_id": "databricks-llama-2-70b-chat",
    "model_name": "Databricks Llama 2 70b Chat",
    "provider_id": "databricks",
    "provider_name": "Databricks",
    "input_cost_per_million": 0.5000100000000001,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "databricks-llama-4-maverick": {
    "input_cost_per_token": 0.000005,
    "input_dbu_cost_per_token": 0.00007143,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Databricks documentation now provides both DBU costs (_dbu_cost_per_token) and dollar costs(_cost_per_token)."
    },
    "output_cost_per_token": 0.000015,
    "output_dbu_cost_per_token": 0.00021429,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_tool_choice": true,
    "model_id": "databricks-llama-4-maverick",
    "model_name": "Databricks Llama 4 Maverick",
    "provider_id": "databricks",
    "provider_name": "Databricks",
    "input_cost_per_million": 5,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "databricks-meta-llama-3-1-405b-instruct": {
    "input_cost_per_token": 0.000005,
    "input_dbu_cost_per_token": 0.000071429,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "output_cost_per_token": 0.00001500002,
    "output_db_cost_per_token": 0.000214286,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_tool_choice": true,
    "model_id": "databricks-meta-llama-3-1-405b-instruct",
    "model_name": "Databricks Meta Llama 3 1 405b Instruct",
    "provider_id": "databricks",
    "provider_name": "Databricks",
    "input_cost_per_million": 5,
    "output_cost_per_million": 15.00002,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "databricks-meta-llama-3-3-70b-instruct": {
    "input_cost_per_token": 0.00000100002,
    "input_dbu_cost_per_token": 0.000014286,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "output_cost_per_token": 0.00000299999,
    "output_dbu_cost_per_token": 0.000042857,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_tool_choice": true,
    "model_id": "databricks-meta-llama-3-3-70b-instruct",
    "model_name": "Databricks Meta Llama 3 3 70b Instruct",
    "provider_id": "databricks",
    "provider_name": "Databricks",
    "input_cost_per_million": 1.0000200000000001,
    "output_cost_per_million": 2.99999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "databricks-meta-llama-3-70b-instruct": {
    "input_cost_per_token": 0.00000100002,
    "input_dbu_cost_per_token": 0.000014286,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "output_cost_per_token": 0.00000299999,
    "output_dbu_cost_per_token": 0.000042857,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_tool_choice": true,
    "model_id": "databricks-meta-llama-3-70b-instruct",
    "model_name": "Databricks Meta Llama 3 70b Instruct",
    "provider_id": "databricks",
    "provider_name": "Databricks",
    "input_cost_per_million": 1.0000200000000001,
    "output_cost_per_million": 2.99999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "databricks-mixtral-8x7b-instruct": {
    "input_cost_per_token": 5.0001e-7,
    "input_dbu_cost_per_token": 0.000007143,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "output_cost_per_token": 9.9902e-7,
    "output_dbu_cost_per_token": 0.000014286,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_tool_choice": true,
    "model_id": "databricks-mixtral-8x7b-instruct",
    "model_name": "Databricks Mixtral 8x7b Instruct",
    "provider_id": "databricks",
    "provider_name": "Databricks",
    "input_cost_per_million": 0.5000100000000001,
    "output_cost_per_million": 0.99902,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "databricks-mpt-30b-instruct": {
    "input_cost_per_token": 9.9902e-7,
    "input_dbu_cost_per_token": 0.000014286,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "output_cost_per_token": 9.9902e-7,
    "output_dbu_cost_per_token": 0.000014286,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_tool_choice": true,
    "model_id": "databricks-mpt-30b-instruct",
    "model_name": "Databricks Mpt 30b Instruct",
    "provider_id": "databricks",
    "provider_name": "Databricks",
    "input_cost_per_million": 0.99902,
    "output_cost_per_million": 0.99902,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "databricks-mpt-7b-instruct": {
    "input_cost_per_token": 5.0001e-7,
    "input_dbu_cost_per_token": 0.000007143,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "output_cost_per_token": 0,
    "output_dbu_cost_per_token": 0,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_tool_choice": true,
    "model_id": "databricks-mpt-7b-instruct",
    "model_name": "Databricks Mpt 7b Instruct",
    "provider_id": "databricks",
    "provider_name": "Databricks",
    "input_cost_per_million": 0.5000100000000001,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/base": {
    "input_cost_per_second": 0.00020833,
    "metadata": {
      "calculation": "$0.0125/60 seconds = $0.00020833 per second",
      "original_pricing_per_minute": 0.0125
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/base",
    "model_name": "Base",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/base-conversationalai": {
    "input_cost_per_second": 0.00020833,
    "metadata": {
      "calculation": "$0.0125/60 seconds = $0.00020833 per second",
      "original_pricing_per_minute": 0.0125
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/base-conversationalai",
    "model_name": "Base Conversationalai",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/base-finance": {
    "input_cost_per_second": 0.00020833,
    "metadata": {
      "calculation": "$0.0125/60 seconds = $0.00020833 per second",
      "original_pricing_per_minute": 0.0125
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/base-finance",
    "model_name": "Base Finance",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/base-general": {
    "input_cost_per_second": 0.00020833,
    "metadata": {
      "calculation": "$0.0125/60 seconds = $0.00020833 per second",
      "original_pricing_per_minute": 0.0125
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/base-general",
    "model_name": "Base General",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/base-meeting": {
    "input_cost_per_second": 0.00020833,
    "metadata": {
      "calculation": "$0.0125/60 seconds = $0.00020833 per second",
      "original_pricing_per_minute": 0.0125
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/base-meeting",
    "model_name": "Base Meeting",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/base-phonecall": {
    "input_cost_per_second": 0.00020833,
    "metadata": {
      "calculation": "$0.0125/60 seconds = $0.00020833 per second",
      "original_pricing_per_minute": 0.0125
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/base-phonecall",
    "model_name": "Base Phonecall",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/base-video": {
    "input_cost_per_second": 0.00020833,
    "metadata": {
      "calculation": "$0.0125/60 seconds = $0.00020833 per second",
      "original_pricing_per_minute": 0.0125
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/base-video",
    "model_name": "Base Video",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/base-voicemail": {
    "input_cost_per_second": 0.00020833,
    "metadata": {
      "calculation": "$0.0125/60 seconds = $0.00020833 per second",
      "original_pricing_per_minute": 0.0125
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/base-voicemail",
    "model_name": "Base Voicemail",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/enhanced": {
    "input_cost_per_second": 0.00024167,
    "metadata": {
      "calculation": "$0.0145/60 seconds = $0.00024167 per second",
      "original_pricing_per_minute": 0.0145
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/enhanced",
    "model_name": "Enhanced",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/enhanced-finance": {
    "input_cost_per_second": 0.00024167,
    "metadata": {
      "calculation": "$0.0145/60 seconds = $0.00024167 per second",
      "original_pricing_per_minute": 0.0145
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/enhanced-finance",
    "model_name": "Enhanced Finance",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/enhanced-general": {
    "input_cost_per_second": 0.00024167,
    "metadata": {
      "calculation": "$0.0145/60 seconds = $0.00024167 per second",
      "original_pricing_per_minute": 0.0145
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/enhanced-general",
    "model_name": "Enhanced General",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/enhanced-meeting": {
    "input_cost_per_second": 0.00024167,
    "metadata": {
      "calculation": "$0.0145/60 seconds = $0.00024167 per second",
      "original_pricing_per_minute": 0.0145
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/enhanced-meeting",
    "model_name": "Enhanced Meeting",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/enhanced-phonecall": {
    "input_cost_per_second": 0.00024167,
    "metadata": {
      "calculation": "$0.0145/60 seconds = $0.00024167 per second",
      "original_pricing_per_minute": 0.0145
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/enhanced-phonecall",
    "model_name": "Enhanced Phonecall",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova",
    "model_name": "Nova",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-2": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-2",
    "model_name": "Nova 2",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-2-atc": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-2-atc",
    "model_name": "Nova 2 Atc",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-2-automotive": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-2-automotive",
    "model_name": "Nova 2 Automotive",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-2-conversationalai": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-2-conversationalai",
    "model_name": "Nova 2 Conversationalai",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-2-drivethru": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-2-drivethru",
    "model_name": "Nova 2 Drivethru",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-2-finance": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-2-finance",
    "model_name": "Nova 2 Finance",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-2-general": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-2-general",
    "model_name": "Nova 2 General",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-2-meeting": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-2-meeting",
    "model_name": "Nova 2 Meeting",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-2-phonecall": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-2-phonecall",
    "model_name": "Nova 2 Phonecall",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-2-video": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-2-video",
    "model_name": "Nova 2 Video",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-2-voicemail": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-2-voicemail",
    "model_name": "Nova 2 Voicemail",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-3": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-3",
    "model_name": "Nova 3",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-3-general": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-3-general",
    "model_name": "Nova 3 General",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-3-medical": {
    "input_cost_per_second": 0.00008667,
    "metadata": {
      "calculation": "$0.0052/60 seconds = $0.00008667 per second (multilingual)",
      "original_pricing_per_minute": 0.0052
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-3-medical",
    "model_name": "Nova 3 Medical",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-general": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-general",
    "model_name": "Nova General",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/nova-phonecall": {
    "input_cost_per_second": 0.00007167,
    "metadata": {
      "calculation": "$0.0043/60 seconds = $0.00007167 per second",
      "original_pricing_per_minute": 0.0043
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/nova-phonecall",
    "model_name": "Nova Phonecall",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/whisper": {
    "input_cost_per_second": 0.0001,
    "metadata": {
      "notes": "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models"
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/whisper",
    "model_name": "Whisper",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/whisper-base": {
    "input_cost_per_second": 0.0001,
    "metadata": {
      "notes": "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models"
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/whisper-base",
    "model_name": "Whisper Base",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/whisper-large": {
    "input_cost_per_second": 0.0001,
    "metadata": {
      "notes": "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models"
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/whisper-large",
    "model_name": "Whisper Large",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/whisper-medium": {
    "input_cost_per_second": 0.0001,
    "metadata": {
      "notes": "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models"
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/whisper-medium",
    "model_name": "Whisper Medium",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/whisper-small": {
    "input_cost_per_second": 0.0001,
    "metadata": {
      "notes": "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models"
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/whisper-small",
    "model_name": "Whisper Small",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepgram/whisper-tiny": {
    "input_cost_per_second": 0.0001,
    "metadata": {
      "notes": "Deepgram's hosted OpenAI Whisper models - pricing may differ from native Deepgram models"
    },
    "output_cost_per_second": 0,
    "source": "https://deepgram.com/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "deepgram/whisper-tiny",
    "model_name": "Whisper Tiny",
    "provider_id": "deepgram",
    "provider_name": "Deepgram",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "allenai/olmOCR-7B-0725-FP8": {
    "input_cost_per_token": 2.7e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.0000015,
    "supports_tool_choice": false,
    "model_id": "allenai/olmOCR-7B-0725-FP8",
    "model_name": "OlmOCR 7B 0725 FP8",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.27,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "anthropic/claude-3-7-sonnet-latest": {
    "input_cost_per_token": 0.0000033,
    "max_input_tokens": 200000,
    "max_output_tokens": 200000,
    "max_tokens": 200000,
    "output_cost_per_token": 0.0000165,
    "supports_tool_choice": true,
    "model_id": "anthropic/claude-3-7-sonnet-latest",
    "model_name": "Claude 3.7 Sonnet",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 3.3000000000000003,
    "output_cost_per_million": 16.5,
    "cache_read_cost_per_token": 3.3e-7,
    "cache_read_cost_per_million": 0.33,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "anthropic/claude-4-opus": {
    "input_cost_per_token": 0.0000165,
    "max_input_tokens": 200000,
    "max_output_tokens": 200000,
    "max_tokens": 200000,
    "output_cost_per_token": 0.0000825,
    "supports_tool_choice": true,
    "model_id": "anthropic/claude-4-opus",
    "model_name": "Claude 4 Opus",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 16.5,
    "output_cost_per_million": 82.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "anthropic/claude-4-sonnet": {
    "input_cost_per_token": 0.0000033,
    "max_input_tokens": 200000,
    "max_output_tokens": 200000,
    "max_tokens": 200000,
    "output_cost_per_token": 0.0000165,
    "supports_tool_choice": true,
    "model_id": "anthropic/claude-4-sonnet",
    "model_name": "Claude 4 Sonnet",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 3.3000000000000003,
    "output_cost_per_million": 16.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek-ai/DeepSeek-R1-0528": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "output_cost_per_token": 0.00000215,
    "supports_tool_choice": true,
    "model_id": "deepseek-ai/DeepSeek-R1-0528",
    "model_name": "DeepSeek R1 0528",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 2.1500000000000004,
    "cache_read_cost_per_token": 4e-7,
    "cache_read_cost_per_million": 0.39999999999999997,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek-ai/DeepSeek-R1-0528-Turbo": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000003,
    "supports_tool_choice": true,
    "model_id": "deepseek-ai/DeepSeek-R1-0528-Turbo",
    "model_name": "DeepSeek R1 0528 Turbo",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 4e-7,
    "supports_tool_choice": false,
    "model_id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek R1 Distill Llama 70B",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
    "input_cost_per_token": 7.5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 1.5e-7,
    "supports_tool_choice": true,
    "model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "model_name": "DeepSeek R1 Distill Qwen 32B",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek-ai/DeepSeek-R1-Turbo": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 40960,
    "max_output_tokens": 40960,
    "max_tokens": 40960,
    "output_cost_per_token": 0.000003,
    "supports_tool_choice": true,
    "model_id": "deepseek-ai/DeepSeek-R1-Turbo",
    "model_name": "DeepSeek R1 Turbo",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek-ai/DeepSeek-V3-0324": {
    "input_cost_per_token": 2.8e-7,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "output_cost_per_token": 8.8e-7,
    "supports_tool_choice": true,
    "model_id": "deepseek-ai/DeepSeek-V3-0324",
    "model_name": "DeepSeek V3 0324",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.28,
    "output_cost_per_million": 0.88,
    "cache_read_cost_per_token": 2.24e-7,
    "cache_read_cost_per_million": 0.224,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "google/gemini-2.0-flash-001": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "max_tokens": 1000000,
    "output_cost_per_token": 4e-7,
    "supports_tool_choice": true,
    "model_id": "google/gemini-2.0-flash-001",
    "model_name": "Gemini 2.0 Flash 001",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "google/gemini-2.5-flash": {
    "input_cost_per_token": 2.1e-7,
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "max_tokens": 1000000,
    "output_cost_per_token": 0.00000175,
    "supports_tool_choice": true,
    "model_id": "google/gemini-2.5-flash",
    "model_name": "Gemini 2.5 Flash",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.21,
    "output_cost_per_million": 1.75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "google/gemini-2.5-pro": {
    "input_cost_per_token": 8.75e-7,
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "max_tokens": 1000000,
    "output_cost_per_token": 0.000007,
    "supports_tool_choice": true,
    "model_id": "google/gemini-2.5-pro",
    "model_name": "Gemini 2.5 Pro",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.875,
    "output_cost_per_million": 7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "google/gemma-3-12b-it": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 1e-7,
    "supports_tool_choice": true,
    "model_id": "google/gemma-3-12b-it",
    "model_name": "Gemma 3 12b It",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "google/gemma-3-27b-it": {
    "input_cost_per_token": 9e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 1.7e-7,
    "supports_tool_choice": true,
    "model_id": "google/gemma-3-27b-it",
    "model_name": "Gemma 3 27b It",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.09,
    "output_cost_per_million": 0.16999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "google/gemma-3-4b-it": {
    "input_cost_per_token": 4e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 8e-8,
    "supports_tool_choice": true,
    "model_id": "google/gemma-3-4b-it",
    "model_name": "Gemma 3 4b It",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.04,
    "output_cost_per_million": 0.08,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Gryphe/MythoMax-L2-13b": {
    "input_cost_per_token": 7.2e-8,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 7.2e-8,
    "supports_tool_choice": true,
    "model_id": "Gryphe/MythoMax-L2-13b",
    "model_name": "MythoMax L2 13b",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.072,
    "output_cost_per_million": 0.072,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta-llama/Llama-3.2-11B-Vision-Instruct": {
    "input_cost_per_token": 4.9e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 4.9e-8,
    "supports_tool_choice": false,
    "model_id": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "model_name": "Llama 3.2 11B Vision Instruct",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.049,
    "output_cost_per_million": 0.049,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta-llama/Llama-3.2-3B-Instruct": {
    "input_cost_per_token": 1.2e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 2.4e-8,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Llama-3.2-3B-Instruct",
    "model_name": "Llama 3.2 3B Instruct",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.012,
    "output_cost_per_million": 0.024,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta-llama/Llama-3.3-70B-Instruct": {
    "input_cost_per_token": 2.3e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 4e-7,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama 3.3 70B Instruct",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.22999999999999998,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta-llama/Llama-Guard-3-8B": {
    "input_cost_per_token": 5.5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 5.5e-8,
    "supports_tool_choice": false,
    "model_id": "meta-llama/Llama-Guard-3-8B",
    "model_name": "Llama Guard 3 8B",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.055,
    "output_cost_per_million": 0.055,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta-llama/Llama-Guard-4-12B": {
    "input_cost_per_token": 1.8e-7,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "output_cost_per_token": 1.8e-7,
    "supports_tool_choice": false,
    "model_id": "meta-llama/Llama-Guard-4-12B",
    "model_name": "Llama Guard 4 12B",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.18,
    "output_cost_per_million": 0.18,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta-llama/Meta-Llama-3-8B-Instruct": {
    "input_cost_per_token": 3e-8,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 6e-8,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
    "model_name": "Meta Llama 3 8B Instruct",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.03,
    "output_cost_per_million": 0.06,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta-llama/Meta-Llama-3.1-70B-Instruct": {
    "input_cost_per_token": 2.3e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 4e-7,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Meta-Llama-3.1-70B-Instruct",
    "model_name": "Meta Llama 3.1 70B Instruct",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.22999999999999998,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta-llama/Meta-Llama-3.1-8B-Instruct": {
    "input_cost_per_token": 3e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 5e-8,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "model_name": "Meta Llama 3.1 8B Instruct",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.03,
    "output_cost_per_million": 0.049999999999999996,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "microsoft/phi-4": {
    "input_cost_per_token": 7e-8,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 1.4e-7,
    "supports_tool_choice": true,
    "model_id": "microsoft/phi-4",
    "model_name": "Phi 4",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.07,
    "output_cost_per_million": 0.14,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "microsoft/WizardLM-2-8x22B": {
    "input_cost_per_token": 4.8e-7,
    "max_input_tokens": 65536,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 4.8e-7,
    "supports_tool_choice": false,
    "model_id": "microsoft/WizardLM-2-8x22B",
    "model_name": "WizardLM 2 8x22B",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.48,
    "output_cost_per_million": 0.48,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistralai/Mistral-Nemo-Instruct-2407": {
    "input_cost_per_token": 2e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 4e-8,
    "supports_tool_choice": true,
    "model_id": "mistralai/Mistral-Nemo-Instruct-2407",
    "model_name": "Mistral Nemo Instruct 2407",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.02,
    "output_cost_per_million": 0.04,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistralai/Mistral-Small-3.2-24B-Instruct-2506": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 1e-7,
    "supports_tool_choice": true,
    "model_id": "mistralai/Mistral-Small-3.2-24B-Instruct-2506",
    "model_name": "Mistral Small 3.2 24B Instruct 2506",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "NousResearch/Hermes-3-Llama-3.1-405B": {
    "input_cost_per_token": 7e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 8e-7,
    "supports_tool_choice": true,
    "model_id": "NousResearch/Hermes-3-Llama-3.1-405B",
    "model_name": "Hermes 3 Llama 3.1 405B",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.7,
    "output_cost_per_million": 0.7999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "NousResearch/Hermes-3-Llama-3.1-70B": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 2.8e-7,
    "supports_tool_choice": false,
    "model_id": "NousResearch/Hermes-3-Llama-3.1-70B",
    "model_name": "Hermes 3 Llama 3.1 70B",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nvidia/Llama-3.1-Nemotron-70B-Instruct": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 3e-7,
    "supports_tool_choice": true,
    "model_id": "nvidia/Llama-3.1-Nemotron-70B-Instruct",
    "model_name": "Llama 3.1 Nemotron 70B Instruct",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Qwen/Qwen2.5-72B-Instruct": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 3.9e-7,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen2.5-72B-Instruct",
    "model_name": "Qwen2.5 72B Instruct",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.39,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Qwen/Qwen2.5-7B-Instruct": {
    "input_cost_per_token": 4e-8,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 1e-7,
    "supports_tool_choice": false,
    "model_id": "Qwen/Qwen2.5-7B-Instruct",
    "model_name": "Qwen2.5 7B Instruct",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.04,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Qwen/Qwen2.5-VL-32B-Instruct": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 6e-7,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen2.5-VL-32B-Instruct",
    "model_name": "Qwen2.5 VL 32B Instruct",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Qwen/Qwen3-14B": {
    "input_cost_per_token": 6e-8,
    "max_input_tokens": 40960,
    "max_output_tokens": 40960,
    "max_tokens": 40960,
    "output_cost_per_token": 2.4e-7,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen3-14B",
    "model_name": "Qwen3 14B",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.06,
    "output_cost_per_million": 0.24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Qwen/Qwen3-235B-A22B": {
    "input_cost_per_token": 1.3e-7,
    "max_input_tokens": 40960,
    "max_output_tokens": 40960,
    "max_tokens": 40960,
    "output_cost_per_token": 6e-7,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen3-235B-A22B",
    "model_name": "Qwen3 235B A22B",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.13,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Qwen/Qwen3-235B-A22B-Instruct-2507": {
    "input_cost_per_token": 1.3e-7,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "output_cost_per_token": 6e-7,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
    "model_name": "Qwen3 235B A22B Instruct 2507",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.13,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Qwen/Qwen3-30B-A3B": {
    "input_cost_per_token": 8e-8,
    "max_input_tokens": 40960,
    "max_output_tokens": 40960,
    "max_tokens": 40960,
    "output_cost_per_token": 2.9e-7,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen3-30B-A3B",
    "model_name": "Qwen3 30B A3B",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.08,
    "output_cost_per_million": 0.29,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Qwen/Qwen3-32B": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 40960,
    "max_output_tokens": 40960,
    "max_tokens": 40960,
    "output_cost_per_token": 3e-7,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen3-32B",
    "model_name": "Qwen3 32B",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Qwen/Qwen3-Coder-480B-A35B-Instruct": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "output_cost_per_token": 0.0000016,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    "model_name": "Qwen3 Coder 480B A35B Instruct",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.5999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "output_cost_per_token": 0.0000012,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
    "model_name": "Qwen3 Coder 480B A35B Instruct Turbo",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": 2.4e-7,
    "cache_read_cost_per_million": 0.24,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Qwen/QwQ-32B": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 4e-7,
    "supports_tool_choice": true,
    "model_id": "Qwen/QwQ-32B",
    "model_name": "QwQ 32B",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Sao10K/L3-8B-Lunaris-v1-Turbo": {
    "input_cost_per_token": 2e-8,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 5e-8,
    "supports_tool_choice": false,
    "model_id": "Sao10K/L3-8B-Lunaris-v1-Turbo",
    "model_name": "L3 8B Lunaris V1 Turbo",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.02,
    "output_cost_per_million": 0.049999999999999996,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Sao10K/L3.1-70B-Euryale-v2.2": {
    "input_cost_per_token": 6.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 7.5e-7,
    "supports_tool_choice": false,
    "model_id": "Sao10K/L3.1-70B-Euryale-v2.2",
    "model_name": "L3.1 70B Euryale V2.2",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.65,
    "output_cost_per_million": 0.75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "Sao10K/L3.3-70B-Euryale-v2.3": {
    "input_cost_per_token": 6.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 7.5e-7,
    "supports_tool_choice": false,
    "model_id": "Sao10K/L3.3-70B-Euryale-v2.3",
    "model_name": "L3.3 70B Euryale V2.3",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.65,
    "output_cost_per_million": 0.75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "zai-org/GLM-4.5": {
    "input_cost_per_token": 5.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000002,
    "supports_tool_choice": true,
    "model_id": "zai-org/GLM-4.5",
    "model_name": "GLM 4.5",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.55,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "zai-org/GLM-4.5-Air": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.0000011,
    "supports_tool_choice": true,
    "model_id": "zai-org/GLM-4.5-Air",
    "model_name": "GLM 4.5 Air",
    "provider_id": "deepinfra",
    "provider_name": "DeepInfra",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 1.1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek/deepseek-chat": {
    "input_cost_per_token": 2.7e-7,
    "input_cost_per_token_cache_hit": 7e-8,
    "max_input_tokens": 65536,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000011,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "model_id": "deepseek/deepseek-chat",
    "model_name": "Deepseek Chat",
    "provider_id": "deepseek",
    "provider_name": "DeepSeek",
    "input_cost_per_million": 0.27,
    "output_cost_per_million": 1.1,
    "cache_read_cost_per_token": 7e-8,
    "cache_read_cost_per_million": 0.07,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek/deepseek-coder": {
    "input_cost_per_token": 1.4e-7,
    "input_cost_per_token_cache_hit": 1.4e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 2.8e-7,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "model_id": "deepseek/deepseek-coder",
    "model_name": "Deepseek Coder",
    "provider_id": "deepseek",
    "provider_name": "DeepSeek",
    "input_cost_per_million": 0.14,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek/deepseek-r1": {
    "input_cost_per_token": 5.5e-7,
    "input_cost_per_token_cache_hit": 1.4e-7,
    "max_input_tokens": 65536,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000219,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "deepseek/deepseek-r1",
    "model_name": "DeepSeek R1",
    "provider_id": "deepseek",
    "provider_name": "DeepSeek",
    "input_cost_per_million": 0.55,
    "output_cost_per_million": 2.1900000000000004,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek/deepseek-reasoner": {
    "input_cost_per_token": 5.5e-7,
    "input_cost_per_token_cache_hit": 1.4e-7,
    "max_input_tokens": 65536,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000219,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "deepseek/deepseek-reasoner",
    "model_name": "Deepseek Reasoner",
    "provider_id": "deepseek",
    "provider_name": "DeepSeek",
    "input_cost_per_million": 0.55,
    "output_cost_per_million": 2.1900000000000004,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek/deepseek-v3": {
    "input_cost_per_token": 2.7e-7,
    "input_cost_per_token_cache_hit": 7e-8,
    "max_input_tokens": 65536,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000011,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "model_id": "deepseek/deepseek-v3",
    "model_name": "DeepSeek V3",
    "provider_id": "deepseek",
    "provider_name": "DeepSeek",
    "input_cost_per_million": 0.27,
    "output_cost_per_million": 1.1,
    "cache_read_cost_per_token": 7e-8,
    "cache_read_cost_per_million": 0.07,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "elevenlabs/scribe_v1": {
    "input_cost_per_second": 0.0000611,
    "metadata": {
      "calculation": "$0.22/hour = $0.00366/minute = $0.0000611 per second (enterprise pricing)",
      "notes": "ElevenLabs Scribe v1 - state-of-the-art speech recognition model with 99 language support",
      "original_pricing_per_hour": 0.22
    },
    "output_cost_per_second": 0,
    "source": "https://elevenlabs.io/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "elevenlabs/scribe_v1",
    "model_name": "Scribe_v1",
    "provider_id": "elevenlabs",
    "provider_name": "ElevenLabs",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "elevenlabs/scribe_v1_experimental": {
    "input_cost_per_second": 0.0000611,
    "metadata": {
      "calculation": "$0.22/hour = $0.00366/minute = $0.0000611 per second (enterprise pricing)",
      "notes": "ElevenLabs Scribe v1 experimental - enhanced version of the main Scribe model",
      "original_pricing_per_hour": 0.22
    },
    "output_cost_per_second": 0,
    "source": "https://elevenlabs.io/pricing",
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "elevenlabs/scribe_v1_experimental",
    "model_name": "Scribe_v1_experimental",
    "provider_id": "elevenlabs",
    "provider_name": "ElevenLabs",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "featherless_ai/featherless-ai/Qwerky-72B": {
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "max_tokens": 32768,
    "model_id": "featherless_ai/featherless-ai/Qwerky-72B",
    "model_name": "Qwerky 72B",
    "provider_id": "featherless",
    "provider_name": "Featherless",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "featherless_ai/featherless-ai/Qwerky-QwQ-32B": {
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "max_tokens": 32768,
    "model_id": "featherless_ai/featherless-ai/Qwerky-QwQ-32B",
    "model_name": "Qwerky QwQ 32B",
    "provider_id": "featherless",
    "provider_name": "Featherless",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct": {
    "input_cost_per_token": 0.0000012,
    "max_input_tokens": 65536,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0.0000012,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct",
    "model_name": "Deepseek Coder V2 Instruct",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 1.2,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 20480,
    "max_tokens": 20480,
    "output_cost_per_token": 0.000008,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1",
    "model_name": "DeepSeek R1",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 160000,
    "max_output_tokens": 160000,
    "max_tokens": 160000,
    "output_cost_per_token": 0.000008,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528",
    "model_name": "Deepseek R1 0528",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic": {
    "input_cost_per_token": 5.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 20480,
    "max_tokens": 20480,
    "output_cost_per_token": 0.00000219,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic",
    "model_name": "Deepseek R1 Basic",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.55,
    "output_cost_per_million": 2.1900000000000004,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-v3": {
    "input_cost_per_token": 9e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 9e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/deepseek-v3",
    "model_name": "DeepSeek V3",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-v3-0324": {
    "input_cost_per_token": 9e-7,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "output_cost_per_token": 9e-7,
    "source": "https://fireworks.ai/models/fireworks/deepseek-v3-0324",
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/deepseek-v3-0324",
    "model_name": "Deepseek V3 0324",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-v3p1": {
    "input_cost_per_token": 5.6e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000168,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "fireworks_ai/accounts/fireworks/models/deepseek-v3p1",
    "model_name": "Deepseek V3p1",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.56,
    "output_cost_per_million": 1.68,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/firefunction-v2": {
    "input_cost_per_token": 9e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 9e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "fireworks_ai/accounts/fireworks/models/firefunction-v2",
    "model_name": "Firefunction V2",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/glm-4p5": {
    "input_cost_per_token": 5.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 96000,
    "max_tokens": 96000,
    "output_cost_per_token": 0.00000219,
    "source": "https://fireworks.ai/models/fireworks/glm-4p5",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "fireworks_ai/accounts/fireworks/models/glm-4p5",
    "model_name": "Glm 4p5",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.55,
    "output_cost_per_million": 2.1900000000000004,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/glm-4p5-air": {
    "input_cost_per_token": 2.2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 96000,
    "max_tokens": 96000,
    "output_cost_per_token": 8.8e-7,
    "source": "https://artificialanalysis.ai/models/glm-4-5-air",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "fireworks_ai/accounts/fireworks/models/glm-4p5-air",
    "model_name": "Glm 4p5 Air",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.22,
    "output_cost_per_million": 0.88,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/gpt-oss-120b": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 6e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "fireworks_ai/accounts/fireworks/models/gpt-oss-120b",
    "model_name": "GPT Oss 120b",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/gpt-oss-20b": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 2e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "fireworks_ai/accounts/fireworks/models/gpt-oss-20b",
    "model_name": "GPT Oss 20b",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct": {
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 16384,
    "max_tokens": 131072,
    "output_cost_per_token": 0.0000025,
    "source": "https://fireworks.ai/models/fireworks/kimi-k2-instruct",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct",
    "model_name": "Kimi K2 Instruct",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 2.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.000003,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct",
    "model_name": "Llama V3p1 405b Instruct",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 1e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct",
    "model_name": "Llama V3p1 8b Instruct",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 2e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "supports_vision": true,
    "model_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct",
    "model_name": "Llama V3p2 11b Vision Instruct",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 1e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct",
    "model_name": "Llama V3p2 1b Instruct",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 1e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct",
    "model_name": "Llama V3p2 3b Instruct",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
    "input_cost_per_token": 9e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 9e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "supports_vision": true,
    "model_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct",
    "model_name": "Llama V3p2 90b Vision Instruct",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic": {
    "input_cost_per_token": 2.2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 8.8e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic",
    "model_name": "Llama4 Maverick Instruct Basic",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.22,
    "output_cost_per_million": 0.88,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 6e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic",
    "model_name": "Llama4 Scout Instruct Basic",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf": {
    "input_cost_per_token": 0.0000012,
    "max_input_tokens": 65536,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0.0000012,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf",
    "model_name": "Mixtral 8x22b Instruct Hf",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 1.2,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct": {
    "input_cost_per_token": 9e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 9e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct",
    "model_name": "Qwen2 72b Instruct",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct": {
    "input_cost_per_token": 9e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 9e-7,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct",
    "model_name": "Qwen2p5 Coder 32b Instruct",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/accounts/fireworks/models/yi-large": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000003,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "fireworks_ai/accounts/fireworks/models/yi-large",
    "model_name": "Yi Large",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/nomic-ai/nomic-embed-text-v1": {
    "input_cost_per_token": 8e-9,
    "max_input_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "source": "https://fireworks.ai/pricing",
    "model_id": "fireworks_ai/nomic-ai/nomic-embed-text-v1",
    "model_name": "Nomic Embed Text V1",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.008,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/nomic-ai/nomic-embed-text-v1.5": {
    "input_cost_per_token": 8e-9,
    "max_input_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "source": "https://fireworks.ai/pricing",
    "model_id": "fireworks_ai/nomic-ai/nomic-embed-text-v1.5",
    "model_name": "Nomic Embed Text V1.5",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.008,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/thenlper/gte-base": {
    "input_cost_per_token": 8e-9,
    "max_input_tokens": 512,
    "max_tokens": 512,
    "output_cost_per_token": 0,
    "source": "https://fireworks.ai/pricing",
    "model_id": "fireworks_ai/thenlper/gte-base",
    "model_name": "Gte Base",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.008,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/thenlper/gte-large": {
    "input_cost_per_token": 1.6e-8,
    "max_input_tokens": 512,
    "max_tokens": 512,
    "output_cost_per_token": 0,
    "source": "https://fireworks.ai/pricing",
    "model_id": "fireworks_ai/thenlper/gte-large",
    "model_name": "Gte Large",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.016,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks_ai/WhereIsAI/UAE-Large-V1": {
    "input_cost_per_token": 1.6e-8,
    "max_input_tokens": 512,
    "max_tokens": 512,
    "output_cost_per_token": 0,
    "source": "https://fireworks.ai/pricing",
    "model_id": "fireworks_ai/WhereIsAI/UAE-Large-V1",
    "model_name": "UAE Large V1",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.016,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks-ai-4.1b-to-16b": {
    "input_cost_per_token": 2e-7,
    "output_cost_per_token": 2e-7,
    "model_id": "fireworks-ai-4.1b-to-16b",
    "model_name": "Fireworks Ai 4.1b To 16b",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks-ai-56b-to-176b": {
    "input_cost_per_token": 0.0000012,
    "output_cost_per_token": 0.0000012,
    "model_id": "fireworks-ai-56b-to-176b",
    "model_name": "Fireworks Ai 56b To 176b",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 1.2,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks-ai-above-16b": {
    "input_cost_per_token": 9e-7,
    "output_cost_per_token": 9e-7,
    "model_id": "fireworks-ai-above-16b",
    "model_name": "Fireworks Ai Above 16b",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks-ai-default": {
    "input_cost_per_token": 0,
    "output_cost_per_token": 0,
    "model_id": "fireworks-ai-default",
    "model_name": "Fireworks Ai Default",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks-ai-embedding-150m-to-350m": {
    "input_cost_per_token": 1.6e-8,
    "output_cost_per_token": 0,
    "model_id": "fireworks-ai-embedding-150m-to-350m",
    "model_name": "Fireworks Ai Embedding 150m To 350m",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.016,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks-ai-embedding-up-to-150m": {
    "input_cost_per_token": 8e-9,
    "output_cost_per_token": 0,
    "model_id": "fireworks-ai-embedding-up-to-150m",
    "model_name": "Fireworks Ai Embedding Up To 150m",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.008,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks-ai-moe-up-to-56b": {
    "input_cost_per_token": 5e-7,
    "output_cost_per_token": 5e-7,
    "model_id": "fireworks-ai-moe-up-to-56b",
    "model_name": "Fireworks Ai Moe Up To 56b",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "fireworks-ai-up-to-4b": {
    "input_cost_per_token": 2e-7,
    "output_cost_per_token": 2e-7,
    "model_id": "fireworks-ai-up-to-4b",
    "model_name": "Fireworks Ai Up To 4b",
    "provider_id": "fireworks",
    "provider_name": "Fireworks AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "friendliai/meta-llama-3.1-70b-instruct": {
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "friendliai/meta-llama-3.1-70b-instruct",
    "model_name": "Meta Llama 3.1 70b Instruct",
    "provider_id": "friendliai",
    "provider_name": "Friendliai",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "friendliai/meta-llama-3.1-8b-instruct": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 1e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "friendliai/meta-llama-3.1-8b-instruct",
    "model_name": "Meta Llama 3.1 8b Instruct",
    "provider_id": "friendliai",
    "provider_name": "Friendliai",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "1.5-flash": {
    "input_cost_per_token": 7.5e-8,
    "input_cost_per_token_above_128k_tokens": 1.5e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 3e-7,
    "output_cost_per_token_above_128k_tokens": 6e-7,
    "rpm": 2000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-flash",
    "model_name": "1.5 Flash",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-flash-001": {
    "deprecation_date": "2025-05-24",
    "input_cost_per_token": 7.5e-8,
    "input_cost_per_token_above_128k_tokens": 1.5e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 3e-7,
    "output_cost_per_token_above_128k_tokens": 6e-7,
    "rpm": 2000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-flash-001",
    "model_name": "1.5 Flash 001",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": 1.875e-8,
    "cache_read_cost_per_million": 0.01875,
    "cache_write_cost_per_token": 0.000001,
    "cache_write_cost_per_million": 1,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-flash-002": {
    "deprecation_date": "2025-09-24",
    "input_cost_per_token": 7.5e-8,
    "input_cost_per_token_above_128k_tokens": 1.5e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 3e-7,
    "output_cost_per_token_above_128k_tokens": 6e-7,
    "rpm": 2000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-flash-002",
    "model_name": "1.5 Flash 002",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": 1.875e-8,
    "cache_read_cost_per_million": 0.01875,
    "cache_write_cost_per_token": 0.000001,
    "cache_write_cost_per_million": 1,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-flash-8b": {
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 4000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-flash-8b",
    "model_name": "1.5 Flash 8b",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-flash-8b-exp-0827": {
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 4000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-flash-8b-exp-0827",
    "model_name": "1.5 Flash 8b Exp 0827",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-flash-8b-exp-0924": {
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 4000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-flash-8b-exp-0924",
    "model_name": "1.5 Flash 8b Exp 0924",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-flash-exp-0827": {
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 2000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-flash-exp-0827",
    "model_name": "1.5 Flash Exp 0827",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-flash-latest": {
    "input_cost_per_token": 7.5e-8,
    "input_cost_per_token_above_128k_tokens": 1.5e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 3e-7,
    "output_cost_per_token_above_128k_tokens": 6e-7,
    "rpm": 2000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-flash-latest",
    "model_name": "1.5 Flash Latest",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-pro": {
    "input_cost_per_token": 0.0000035,
    "input_cost_per_token_above_128k_tokens": 0.000007,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000105,
    "output_cost_per_token_above_128k_tokens": 0.000021,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-pro",
    "model_name": "1.5 Pro",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 3.5,
    "output_cost_per_million": 10.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-pro-001": {
    "deprecation_date": "2025-05-24",
    "input_cost_per_token": 0.0000035,
    "input_cost_per_token_above_128k_tokens": 0.000007,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000105,
    "output_cost_per_token_above_128k_tokens": 0.000021,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-pro-001",
    "model_name": "1.5 Pro 001",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 3.5,
    "output_cost_per_million": 10.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-pro-002": {
    "deprecation_date": "2025-09-24",
    "input_cost_per_token": 0.0000035,
    "input_cost_per_token_above_128k_tokens": 0.000007,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000105,
    "output_cost_per_token_above_128k_tokens": 0.000021,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-pro-002",
    "model_name": "1.5 Pro 002",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 3.5,
    "output_cost_per_million": 10.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-pro-exp-0801": {
    "input_cost_per_token": 0.0000035,
    "input_cost_per_token_above_128k_tokens": 0.000007,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000105,
    "output_cost_per_token_above_128k_tokens": 0.000021,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-pro-exp-0801",
    "model_name": "1.5 Pro Exp 0801",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 3.5,
    "output_cost_per_million": 10.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-pro-exp-0827": {
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-pro-exp-0827",
    "model_name": "1.5 Pro Exp 0827",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "1.5-pro-latest": {
    "input_cost_per_token": 0.0000035,
    "input_cost_per_token_above_128k_tokens": 0.000007,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000105,
    "output_cost_per_token_above_128k_tokens": 0.000021,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "1.5-pro-latest",
    "model_name": "1.5 Pro Latest",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 3.5,
    "output_cost_per_million": 1.0499999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.0-flash": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 1e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 4e-7,
    "rpm": 10000,
    "source": "https://ai.google.dev/pricing#2_0flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000,
    "model_id": "2.0-flash",
    "model_name": "2.0 Flash",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.0-flash-001": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 1e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 4e-7,
    "rpm": 10000,
    "source": "https://ai.google.dev/pricing#2_0flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000,
    "model_id": "2.0-flash-001",
    "model_name": "2.0 Flash 001",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.0-flash-exp": {
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 10,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 4000000,
    "model_id": "2.0-flash-exp",
    "model_name": "2.0 Flash Exp",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.0-flash-lite": {
    "input_cost_per_audio_token": 7.5e-8,
    "input_cost_per_token": 7.5e-8,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 50,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 3e-7,
    "rpm": 4000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 4000000,
    "model_id": "2.0-flash-lite",
    "model_name": "2.0 Flash Lite",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": 1.875e-8,
    "cache_read_cost_per_million": 0.01875,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.0-flash-lite-preview-02-05": {
    "input_cost_per_audio_token": 7.5e-8,
    "input_cost_per_token": 7.5e-8,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 3e-7,
    "rpm": 60000,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash-lite",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000,
    "model_id": "2.0-flash-lite-preview-02-05",
    "model_name": "2.0 Flash Lite Preview 02 05",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": 1.875e-8,
    "cache_read_cost_per_million": 0.01875,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.0-flash-live-001": {
    "input_cost_per_audio_token": 0.0000021,
    "input_cost_per_image": 0.0000021,
    "input_cost_per_token": 3.5e-7,
    "input_cost_per_video_per_second": 0.0000021,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_audio_token": 0.0000085,
    "output_cost_per_token": 0.0000015,
    "rpm": 10,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2-0-flash-live-001",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000,
    "model_id": "2.0-flash-live-001",
    "model_name": "2.0 Flash Live 001",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.35,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.0-flash-preview-image-generation": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 1e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 4e-7,
    "rpm": 10000,
    "source": "https://ai.google.dev/pricing#2_0flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000,
    "model_id": "2.0-flash-preview-image-generation",
    "model_name": "2.0 Flash Preview Image Generation",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.0-flash-thinking-exp": {
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 10,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 4000000,
    "model_id": "2.0-flash-thinking-exp",
    "model_name": "2.0 Flash Thinking Exp",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.0-flash-thinking-exp-01-21": {
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 10,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 4000000,
    "model_id": "2.0-flash-thinking-exp-01-21",
    "model_name": "2.0 Flash Thinking Exp 01 21",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.0-pro-exp-02-05": {
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 2,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 1000000,
    "model_id": "2.0-pro-exp-02-05",
    "model_name": "2.0 Pro Exp 02 05",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.5-flash": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 8000000,
    "model_id": "2.5-flash",
    "model_name": "2.5 Flash",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 2.5,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "2.5-flash-image-preview": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_image": 0.039,
    "output_cost_per_reasoning_token": 0.00003,
    "output_cost_per_token": 0.00003,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 8000000,
    "model_id": "2.5-flash-image-preview",
    "model_name": "2.5 Flash Image Preview",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "2.5-flash-lite": {
    "input_cost_per_audio_token": 5e-7,
    "input_cost_per_token": 1e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_reasoning_token": 4e-7,
    "output_cost_per_token": 4e-7,
    "rpm": 15,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000,
    "model_id": "2.5-flash-lite",
    "model_name": "2.5 Flash Lite",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "2.5-flash-lite-preview-06-17": {
    "input_cost_per_audio_token": 5e-7,
    "input_cost_per_token": 1e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_reasoning_token": 4e-7,
    "output_cost_per_token": 4e-7,
    "rpm": 15,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000,
    "model_id": "2.5-flash-lite-preview-06-17",
    "model_name": "2.5 Flash Lite Preview 06 17",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "2.5-flash-preview-04-17": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 1.5e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_reasoning_token": 0.0000035,
    "output_cost_per_token": 6e-7,
    "rpm": 10,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000,
    "model_id": "2.5-flash-preview-04-17",
    "model_name": "2.5 Flash Preview 04 17",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": 3.75e-8,
    "cache_read_cost_per_million": 0.0375,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.5-flash-preview-05-20": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "rpm": 10,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000,
    "model_id": "2.5-flash-preview-05-20",
    "model_name": "2.5 Flash Preview 05 20",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 2.5,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.5-flash-preview-tts": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 1.5e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_reasoning_token": 0.0000035,
    "output_cost_per_token": 6e-7,
    "rpm": 10,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "audio"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000,
    "model_id": "2.5-flash-preview-tts",
    "model_name": "2.5 Flash Preview Tts",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": 3.75e-8,
    "cache_read_cost_per_million": 0.0375,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.5-pro": {
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 2000,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 800000,
    "model_id": "2.5-pro",
    "model_name": "2.5 Pro",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 3.125e-7,
    "cache_read_cost_per_million": 0.3125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.5-pro-exp-03-25": {
    "input_cost_per_token": 0,
    "input_cost_per_token_above_200k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_200k_tokens": 0,
    "rpm": 5,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000,
    "model_id": "2.5-pro-exp-03-25",
    "model_name": "2.5 Pro Exp 03 25",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.5-pro-preview-03-25": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 10000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000,
    "model_id": "2.5-pro-preview-03-25",
    "model_name": "2.5 Pro Preview 03 25",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 3.125e-7,
    "cache_read_cost_per_million": 0.3125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.5-pro-preview-05-06": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 10000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000,
    "model_id": "2.5-pro-preview-05-06",
    "model_name": "2.5 Pro Preview 05 06",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 3.125e-7,
    "cache_read_cost_per_million": 0.3125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.5-pro-preview-06-05": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 10000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000,
    "model_id": "2.5-pro-preview-06-05",
    "model_name": "2.5 Pro Preview 06 05",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 3.125e-7,
    "cache_read_cost_per_million": 0.3125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "2.5-pro-preview-tts": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 10000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "audio"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000,
    "model_id": "2.5-pro-preview-tts",
    "model_name": "2.5 Pro Preview Tts",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 3.125e-7,
    "cache_read_cost_per_million": 0.3125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "exp-1114": {
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "metadata": {
      "notes": "Rate limits not documented for gemini-exp-1114. Assuming same as gemini-1.5-pro.",
      "supports_tool_choice": true
    },
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "exp-1114",
    "model_name": "Exp 1114",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "exp-1206": {
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "metadata": {
      "notes": "Rate limits not documented for gemini-exp-1206. Assuming same as gemini-1.5-pro.",
      "supports_tool_choice": true
    },
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000,
    "model_id": "exp-1206",
    "model_name": "Exp 1206",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "gemma-2-27b-it": {
    "input_cost_per_token": 3.5e-7,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000105,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemma-2-27b-it",
    "model_name": "Gemma-2 Instruct (27B)",
    "provider_id": "google",
    "provider_name": "Google",
    "max_input_tokens": null,
    "input_cost_per_million": 0.35,
    "output_cost_per_million": 1.0499999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gemma-2-9b-it": {
    "input_cost_per_token": 3.5e-7,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000105,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemma-2-9b-it",
    "model_name": "Gemma-2 Instruct (9B)",
    "provider_id": "google",
    "provider_name": "Google",
    "max_input_tokens": null,
    "input_cost_per_million": 0.35,
    "output_cost_per_million": 1.0499999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gemma-3-27b-it": {
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "source": "https://aistudio.google.com",
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemma-3-27b-it",
    "model_name": "Gemma 3 27b It",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "learnlm-1.5-pro-experimental": {
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "max_input_tokens": 32767,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "source": "https://aistudio.google.com",
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "learnlm-1.5-pro-experimental",
    "model_name": "Learnlm 1.5 Pro Experimental",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "pro": {
    "input_cost_per_token": 3.5e-7,
    "input_cost_per_token_above_128k_tokens": 7e-7,
    "max_input_tokens": 32760,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000105,
    "output_cost_per_token_above_128k_tokens": 0.0000021,
    "rpd": 30000,
    "rpm": 360,
    "source": "https://ai.google.dev/gemini-api/docs/models/gemini",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "tpm": 120000,
    "model_id": "pro",
    "model_name": "Pro",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.35,
    "output_cost_per_million": 1.0499999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "pro-vision": {
    "input_cost_per_token": 3.5e-7,
    "input_cost_per_token_above_128k_tokens": 7e-7,
    "max_input_tokens": 30720,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0.00000105,
    "output_cost_per_token_above_128k_tokens": 0.0000021,
    "rpd": 30000,
    "rpm": 360,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 120000,
    "model_id": "pro-vision",
    "model_name": "Pro Vision",
    "provider_id": "google",
    "provider_name": "Google",
    "input_cost_per_million": 0.35,
    "output_cost_per_million": 1.0499999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/alibaba-qwen3-32b": {
    "max_tokens": 2048,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/alibaba-qwen3-32b",
    "model_name": "Alibaba Qwen3 32b",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/anthropic-claude-3-opus": {
    "input_cost_per_token": 0.000015,
    "max_tokens": 1024,
    "output_cost_per_token": 0.000075,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/anthropic-claude-3-opus",
    "model_name": "Anthropic Claude 3 Opus",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/anthropic-claude-3.5-haiku": {
    "input_cost_per_token": 8e-7,
    "max_tokens": 1024,
    "output_cost_per_token": 0.000004,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/anthropic-claude-3.5-haiku",
    "model_name": "Anthropic Claude 3.5 Haiku",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/anthropic-claude-3.5-sonnet": {
    "input_cost_per_token": 0.000003,
    "max_tokens": 1024,
    "output_cost_per_token": 0.000015,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/anthropic-claude-3.5-sonnet",
    "model_name": "Anthropic Claude 3.5 Sonnet",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/anthropic-claude-3.7-sonnet": {
    "input_cost_per_token": 0.000003,
    "max_tokens": 1024,
    "output_cost_per_token": 0.000015,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/anthropic-claude-3.7-sonnet",
    "model_name": "Anthropic Claude 3.7 Sonnet",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/deepseek-r1-distill-llama-70b": {
    "input_cost_per_token": 9.9e-7,
    "max_tokens": 8000,
    "output_cost_per_token": 9.9e-7,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/deepseek-r1-distill-llama-70b",
    "model_name": "DeepSeek R1 Distill Llama 70B",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.9900000000000001,
    "output_cost_per_million": 0.9900000000000001,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/llama3-8b-instruct": {
    "input_cost_per_token": 2e-7,
    "max_tokens": 512,
    "output_cost_per_token": 2e-7,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/llama3-8b-instruct",
    "model_name": "Llama3 8b Instruct",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/llama3.3-70b-instruct": {
    "input_cost_per_token": 6.5e-7,
    "max_tokens": 2048,
    "output_cost_per_token": 6.5e-7,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/llama3.3-70b-instruct",
    "model_name": "Llama3.3 70b Instruct",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.65,
    "output_cost_per_million": 0.65,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/mistral-nemo-instruct-2407": {
    "input_cost_per_token": 3e-7,
    "max_tokens": 512,
    "output_cost_per_token": 3e-7,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/mistral-nemo-instruct-2407",
    "model_name": "Mistral Nemo Instruct 2407",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/openai-gpt-4o": {
    "max_tokens": 16384,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/openai-gpt-4o",
    "model_name": "Openai GPT 4o",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/openai-gpt-4o-mini": {
    "max_tokens": 16384,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/openai-gpt-4o-mini",
    "model_name": "Openai GPT 4o Mini",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/openai-o3": {
    "input_cost_per_token": 0.000002,
    "max_tokens": 100000,
    "output_cost_per_token": 0.000008,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/openai-o3",
    "model_name": "Openai O3",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gradient_ai/openai-o3-mini": {
    "input_cost_per_token": 0.0000011,
    "max_tokens": 100000,
    "output_cost_per_token": 0.0000044,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text"
    ],
    "supports_tool_choice": false,
    "model_id": "gradient_ai/openai-o3-mini",
    "model_name": "Openai O3 Mini",
    "provider_id": "gradient",
    "provider_name": "Gradient",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek-r1-distill-llama-70b": {
    "input_cost_per_token": 7.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 9.9e-7,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "deepseek-r1-distill-llama-70b",
    "model_name": "DeepSeek R1 Distill Llama 70B",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.75,
    "output_cost_per_million": 0.9900000000000001,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "distil-whisper-large-v3-en": {
    "input_cost_per_second": 0.00000556,
    "output_cost_per_second": 0,
    "model_id": "distil-whisper-large-v3-en",
    "model_name": "Distil Whisper Large V3 En",
    "provider_id": "groq",
    "provider_name": "Groq",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gemma-7b-it": {
    "deprecation_date": "2024-12-18",
    "input_cost_per_token": 7e-8,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 7e-8,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "gemma-7b-it",
    "model_name": "Gemma 7b IT",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.07,
    "output_cost_per_million": 0.07,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "gemma2-9b-it": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 2e-7,
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "gemma2-9b-it",
    "model_name": "Gemma 2 9B",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "llama-3.1-405b-reasoning": {
    "input_cost_per_token": 5.9e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 7.9e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "llama-3.1-405b-reasoning",
    "model_name": "Llama 3.1 405b Reasoning",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.59,
    "output_cost_per_million": 0.7899999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "llama-3.1-70b-versatile": {
    "deprecation_date": "2025-01-24",
    "input_cost_per_token": 5.9e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 7.9e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "llama-3.1-70b-versatile",
    "model_name": "Llama 3.1 70b Versatile",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.59,
    "output_cost_per_million": 0.7899999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "llama-3.1-8b-instant": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 8e-8,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "llama-3.1-8b-instant",
    "model_name": "Llama 3.1 8b Instant",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.08,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "llama-3.2-11b-text-preview": {
    "deprecation_date": "2024-10-28",
    "input_cost_per_token": 1.8e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 1.8e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "llama-3.2-11b-text-preview",
    "model_name": "Llama 3.2 11b Text Preview",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.18,
    "output_cost_per_million": 0.18,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "llama-3.2-11b-vision-preview": {
    "deprecation_date": "2025-04-14",
    "input_cost_per_token": 1.8e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 1.8e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "llama-3.2-11b-vision-preview",
    "model_name": "Llama 3.2 11b Vision Preview",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.18,
    "output_cost_per_million": 0.18,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "llama-3.2-1b-preview": {
    "deprecation_date": "2025-04-14",
    "input_cost_per_token": 4e-8,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 4e-8,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "llama-3.2-1b-preview",
    "model_name": "Llama 3.2 1b Preview",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.04,
    "output_cost_per_million": 0.04,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "llama-3.2-3b-preview": {
    "deprecation_date": "2025-04-14",
    "input_cost_per_token": 6e-8,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 6e-8,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "llama-3.2-3b-preview",
    "model_name": "Llama 3.2 3b Preview",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.06,
    "output_cost_per_million": 0.06,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "llama-3.2-90b-text-preview": {
    "deprecation_date": "2024-11-25",
    "input_cost_per_token": 9e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 9e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "llama-3.2-90b-text-preview",
    "model_name": "Llama 3.2 90b Text Preview",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "llama-3.2-90b-vision-preview": {
    "deprecation_date": "2025-04-14",
    "input_cost_per_token": 9e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 9e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "llama-3.2-90b-vision-preview",
    "model_name": "Llama 3.2 90b Vision Preview",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "llama-3.3-70b-specdec": {
    "deprecation_date": "2025-04-14",
    "input_cost_per_token": 5.9e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 9.9e-7,
    "supports_tool_choice": true,
    "model_id": "llama-3.3-70b-specdec",
    "model_name": "Llama 3.3 70b Specdec",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.59,
    "output_cost_per_million": 0.9900000000000001,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "llama-3.3-70b-versatile": {
    "input_cost_per_token": 5.9e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 7.9e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "llama-3.3-70b-versatile",
    "model_name": "Llama 3.3 70b Versatile",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.59,
    "output_cost_per_million": 0.7899999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "llama-guard-3-8b": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 2e-7,
    "model_id": "llama-guard-3-8b",
    "model_name": "Llama Guard 3 8b",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "llama2-70b-4096": {
    "input_cost_per_token": 7e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 8e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "llama2-70b-4096",
    "model_name": "Llama2 70b 4096",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.7,
    "output_cost_per_million": 0.7999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "llama3-groq-70b-8192-tool-use-preview": {
    "deprecation_date": "2025-01-06",
    "input_cost_per_token": 8.9e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 8.9e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "llama3-groq-70b-8192-tool-use-preview",
    "model_name": "Llama3 Groq 70b 8192 Tool Use Preview",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.8899999999999999,
    "output_cost_per_million": 0.8899999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "llama3-groq-8b-8192-tool-use-preview": {
    "deprecation_date": "2025-01-06",
    "input_cost_per_token": 1.9e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 1.9e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "llama3-groq-8b-8192-tool-use-preview",
    "model_name": "Llama3 Groq 8b 8192 Tool Use Preview",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.19,
    "output_cost_per_million": 0.19,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "meta-llama/llama-4-maverick-17b-128e-instruct": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "meta-llama/llama-4-maverick-17b-128e-instruct",
    "model_name": "Llama 4 Maverick Instruct (17Bx128E)",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "meta-llama/llama-4-scout-17b-16e-instruct": {
    "input_cost_per_token": 1.1e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 3.4e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "meta-llama/llama-4-scout-17b-16e-instruct",
    "model_name": "Llama 4 Scout Instruct (17Bx16E)",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.11,
    "output_cost_per_million": 0.33999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "mistral-saba-24b": {
    "input_cost_per_token": 7.9e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 7.9e-7,
    "model_id": "mistral-saba-24b",
    "model_name": "Mistral Saba 24b",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.7899999999999999,
    "output_cost_per_million": 0.7899999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mixtral-8x7b-32768": {
    "deprecation_date": "2025-03-20",
    "input_cost_per_token": 2.4e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 2.4e-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mixtral-8x7b-32768",
    "model_name": "Mixtral 8x7b 32768",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.24,
    "output_cost_per_million": 0.24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "moonshotai/kimi-k2-instruct": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 131072,
    "max_output_tokens": 16384,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "moonshotai/kimi-k2-instruct",
    "model_name": "Kimi K2 Instruct",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "playai-tts": {
    "input_cost_per_character": 0.00005,
    "max_input_tokens": 10000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "model_id": "playai-tts",
    "model_name": "Playai Tts",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "qwen/qwen3-32b": {
    "input_cost_per_token": 2.9e-7,
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "output_cost_per_token": 5.9e-7,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "qwen/qwen3-32b",
    "model_name": "Qwen3 32b",
    "provider_id": "groq",
    "provider_name": "Groq",
    "input_cost_per_million": 0.29,
    "output_cost_per_million": 0.59,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "whisper-large-v3": {
    "input_cost_per_second": 0.00003083,
    "output_cost_per_second": 0,
    "model_id": "whisper-large-v3",
    "model_name": "Whisper Large V3",
    "provider_id": "groq",
    "provider_name": "Groq",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "whisper-large-v3-turbo": {
    "input_cost_per_second": 0.00001111,
    "output_cost_per_second": 0,
    "model_id": "whisper-large-v3-turbo",
    "model_name": "Whisper Large V3 Turbo",
    "provider_id": "groq",
    "provider_name": "Groq",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "heroku/claude-3-5-haiku": {
    "max_tokens": 4096,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "heroku/claude-3-5-haiku",
    "model_name": "Claude 3 5 Haiku",
    "provider_id": "heroku",
    "provider_name": "Heroku",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "heroku/claude-3-5-sonnet-latest": {
    "max_tokens": 8192,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "heroku/claude-3-5-sonnet-latest",
    "model_name": "Claude 3.5 Sonnet",
    "provider_id": "heroku",
    "provider_name": "Heroku",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "heroku/claude-3-7-sonnet": {
    "max_tokens": 8192,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "heroku/claude-3-7-sonnet",
    "model_name": "Claude 3 7 Sonnet",
    "provider_id": "heroku",
    "provider_name": "Heroku",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "heroku/claude-4-sonnet": {
    "max_tokens": 8192,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "heroku/claude-4-sonnet",
    "model_name": "Claude 4 Sonnet",
    "provider_id": "heroku",
    "provider_name": "Heroku",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "hyperbolic/deepseek-ai/DeepSeek-R1": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 4e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/deepseek-ai/DeepSeek-R1",
    "model_name": "DeepSeek R1",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/deepseek-ai/DeepSeek-R1-0528": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 2.5e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/deepseek-ai/DeepSeek-R1-0528",
    "model_name": "DeepSeek R1 0528",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 0.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/deepseek-ai/DeepSeek-V3": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 2e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/deepseek-ai/DeepSeek-V3",
    "model_name": "DeepSeek V3",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/deepseek-ai/DeepSeek-V3-0324": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 4e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/deepseek-ai/DeepSeek-V3-0324",
    "model_name": "DeepSeek V3 0324",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/meta-llama/Llama-3.2-3B-Instruct": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/meta-llama/Llama-3.2-3B-Instruct",
    "model_name": "Llama 3.2 3B Instruct",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/meta-llama/Llama-3.3-70B-Instruct": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/meta-llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama 3.3 70B Instruct",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct",
    "model_name": "Meta Llama 3 70B Instruct",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct",
    "model_name": "Meta Llama 3.1 405B Instruct",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct",
    "model_name": "Meta Llama 3.1 70B Instruct",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct",
    "model_name": "Meta Llama 3.1 8B Instruct",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/moonshotai/Kimi-K2-Instruct": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/moonshotai/Kimi-K2-Instruct",
    "model_name": "Kimi K2 Instruct",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 2,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B",
    "model_name": "Hermes 3 Llama 3.1 70B",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/Qwen/Qwen2.5-72B-Instruct": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/Qwen/Qwen2.5-72B-Instruct",
    "model_name": "Qwen2.5 72B Instruct",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct",
    "model_name": "Qwen2.5 Coder 32B Instruct",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/Qwen/Qwen3-235B-A22B": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/Qwen/Qwen3-235B-A22B",
    "model_name": "Qwen3 235B A22B",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 2,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hyperbolic/Qwen/QwQ-32B": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 2e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "hyperbolic/Qwen/QwQ-32B",
    "model_name": "QwQ 32B",
    "provider_id": "hyperbolic",
    "provider_name": "Hyperbolic",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "jina-reranker-v2-base-multilingual": {
    "input_cost_per_token": 1.8e-8,
    "max_document_chunks_per_query": 2048,
    "max_input_tokens": 1024,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_token": 1.8e-8,
    "model_id": "jina-reranker-v2-base-multilingual",
    "model_name": "Jina Reranker V2 Base Multilingual",
    "provider_id": "jina",
    "provider_name": "Jina",
    "input_cost_per_million": 0.018,
    "output_cost_per_million": 0.018,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "lambda_ai/deepseek-llama3.3-70b": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/deepseek-llama3.3-70b",
    "model_name": "Deepseek Llama3.3 70b",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/deepseek-r1-0528": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/deepseek-r1-0528",
    "model_name": "Deepseek R1 0528",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/deepseek-r1-671b": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 8e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/deepseek-r1-671b",
    "model_name": "Deepseek R1 671b",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 0.7999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/deepseek-v3-0324": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/deepseek-v3-0324",
    "model_name": "Deepseek V3 0324",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/hermes3-405b": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 8e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/hermes3-405b",
    "model_name": "Hermes3 405b",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 0.7999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/hermes3-70b": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/hermes3-70b",
    "model_name": "Hermes3 70b",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/hermes3-8b": {
    "input_cost_per_token": 2.5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 4e-8,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/hermes3-8b",
    "model_name": "Hermes3 8b",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.024999999999999998,
    "output_cost_per_million": 0.04,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/lfm-40b": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 2e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/lfm-40b",
    "model_name": "Lfm 40b",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/lfm-7b": {
    "input_cost_per_token": 2.5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 4e-8,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/lfm-7b",
    "model_name": "Lfm 7b",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.024999999999999998,
    "output_cost_per_million": 0.04,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/llama-4-maverick-17b-128e-instruct-fp8": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 131072,
    "output_cost_per_token": 1e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/llama-4-maverick-17b-128e-instruct-fp8",
    "model_name": "Llama 4 Maverick 17b 128e Instruct Fp8",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/llama-4-scout-17b-16e-instruct": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 16384,
    "max_output_tokens": 8192,
    "max_tokens": 16384,
    "output_cost_per_token": 1e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/llama-4-scout-17b-16e-instruct",
    "model_name": "Llama 4 Scout Instruct (17Bx16E)",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/llama3.1-405b-instruct-fp8": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 8e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/llama3.1-405b-instruct-fp8",
    "model_name": "Llama3.1 405b Instruct Fp8",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 0.7999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/llama3.1-70b-instruct-fp8": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/llama3.1-70b-instruct-fp8",
    "model_name": "Llama3.1 70b Instruct Fp8",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/llama3.1-8b-instruct": {
    "input_cost_per_token": 2.5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 4e-8,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/llama3.1-8b-instruct",
    "model_name": "Llama3.1 8b Instruct",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.024999999999999998,
    "output_cost_per_million": 0.04,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/llama3.1-nemotron-70b-instruct-fp8": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/llama3.1-nemotron-70b-instruct-fp8",
    "model_name": "Llama3.1 Nemotron 70b Instruct Fp8",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/llama3.2-11b-vision-instruct": {
    "input_cost_per_token": 1.5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 2.5e-8,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "lambda_ai/llama3.2-11b-vision-instruct",
    "model_name": "Llama3.2 11b Vision Instruct",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.015,
    "output_cost_per_million": 0.024999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "lambda_ai/llama3.2-3b-instruct": {
    "input_cost_per_token": 1.5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 2.5e-8,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/llama3.2-3b-instruct",
    "model_name": "Llama3.2 3b Instruct",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.015,
    "output_cost_per_million": 0.024999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/llama3.3-70b-instruct-fp8": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/llama3.3-70b-instruct-fp8",
    "model_name": "Llama3.3 70b Instruct Fp8",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/qwen25-coder-32b-instruct": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 1e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/qwen25-coder-32b-instruct",
    "model_name": "Qwen25 Coder 32b Instruct",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "lambda_ai/qwen3-32b-fp8": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 1e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "lambda_ai/qwen3-32b-fp8",
    "model_name": "Qwen3 32b Fp8",
    "provider_id": "lambda",
    "provider_name": "Lambda",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "meta_llama/Llama-3.3-70B-Instruct": {
    "max_input_tokens": 128000,
    "max_output_tokens": 4028,
    "max_tokens": 128000,
    "source": "https://llama.developer.meta.com/docs/models",
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "meta_llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama 3.3 70B Instruct",
    "provider_id": "meta",
    "provider_name": "Meta",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta_llama/Llama-3.3-8B-Instruct": {
    "max_input_tokens": 128000,
    "max_output_tokens": 4028,
    "max_tokens": 128000,
    "source": "https://llama.developer.meta.com/docs/models",
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "meta_llama/Llama-3.3-8B-Instruct",
    "model_name": "Llama 3.3 8B Instruct",
    "provider_id": "meta",
    "provider_name": "Meta",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
    "max_input_tokens": 1000000,
    "max_output_tokens": 4028,
    "max_tokens": 128000,
    "source": "https://llama.developer.meta.com/docs/models",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "model_name": "Llama 4 Maverick 17B 128E Instruct FP8",
    "provider_id": "meta",
    "provider_name": "Meta",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8": {
    "max_input_tokens": 10000000,
    "max_output_tokens": 4028,
    "max_tokens": 128000,
    "source": "https://llama.developer.meta.com/docs/models",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8",
    "model_name": "Llama 4 Scout 17B 16E Instruct FP8",
    "provider_id": "meta",
    "provider_name": "Meta",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codestral-2405": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000003,
    "supports_assistant_prefill": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "codestral-2405",
    "model_name": "Codestral 2405",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "codestral-latest": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000003,
    "supports_assistant_prefill": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "codestral-latest",
    "model_name": "Codestral",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "codestral-mamba-latest": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 2.5e-7,
    "source": "https://mistral.ai/technology/",
    "supports_assistant_prefill": true,
    "supports_tool_choice": true,
    "model_id": "codestral-mamba-latest",
    "model_name": "Codestral Mamba Latest",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 0.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codestral/codestral-2405": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0,
    "source": "https://docs.mistral.ai/capabilities/code_generation/",
    "supports_assistant_prefill": true,
    "supports_tool_choice": true,
    "model_id": "codestral/codestral-2405",
    "model_name": "Codestral 2405",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codestral/codestral-latest": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0,
    "source": "https://docs.mistral.ai/capabilities/code_generation/",
    "supports_assistant_prefill": true,
    "supports_tool_choice": true,
    "model_id": "codestral/codestral-latest",
    "model_name": "Codestral",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "devstral-medium-2507": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000002,
    "source": "https://mistral.ai/news/devstral",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "devstral-medium-2507",
    "model_name": "Devstral Medium 2507",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "devstral-small-2505": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 3e-7,
    "source": "https://mistral.ai/news/devstral",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "devstral-small-2505",
    "model_name": "Devstral Small 2505",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "devstral-small-2507": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 3e-7,
    "source": "https://mistral.ai/news/devstral",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "devstral-small-2507",
    "model_name": "Devstral Small 2507",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "magistral-medium-2506": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 40000,
    "max_output_tokens": 40000,
    "max_tokens": 40000,
    "output_cost_per_token": 0.000005,
    "source": "https://mistral.ai/news/magistral",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "magistral-medium-2506",
    "model_name": "Magistral Medium 2506",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "magistral-medium-latest": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 40000,
    "max_output_tokens": 40000,
    "max_tokens": 40000,
    "output_cost_per_token": 0.000005,
    "source": "https://mistral.ai/news/magistral",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "magistral-medium-latest",
    "model_name": "Magistral Medium Latest",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "magistral-small-2506": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 40000,
    "max_output_tokens": 40000,
    "max_tokens": 40000,
    "output_cost_per_token": 0.0000015,
    "source": "https://mistral.ai/pricing#api-pricing",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "magistral-small-2506",
    "model_name": "Magistral Small 2506",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "magistral-small-latest": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 40000,
    "max_output_tokens": 40000,
    "max_tokens": 40000,
    "output_cost_per_token": 0.0000015,
    "source": "https://mistral.ai/pricing#api-pricing",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "magistral-small-latest",
    "model_name": "Magistral Small Latest",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "mistral-embed": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 8192,
    "max_tokens": 8192,
    "model_id": "mistral-embed",
    "model_name": "Mistral Embed",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral-large-2402": {
    "input_cost_per_token": 0.000004,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000012,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mistral-large-2402",
    "model_name": "Mistral Large 2402",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 4,
    "output_cost_per_million": 12,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "mistral-large-2407": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000009,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mistral-large-2407",
    "model_name": "Mistral Large 2407",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 9,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "mistral-large-latest": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000006,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mistral-large-latest",
    "model_name": "Mistral Large",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "mistral-medium": {
    "input_cost_per_token": 0.0000027,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.0000081,
    "supports_assistant_prefill": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mistral-medium",
    "model_name": "Mistral Medium",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 2.7,
    "output_cost_per_million": 8.1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "mistral-medium-2312": {
    "input_cost_per_token": 0.0000027,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.0000081,
    "supports_assistant_prefill": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mistral-medium-2312",
    "model_name": "Mistral Medium 2312",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 2.7,
    "output_cost_per_million": 8.1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "mistral-medium-2505": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000002,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mistral-medium-2505",
    "model_name": "Mistral Medium 2505",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "mistral-medium-latest": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000002,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mistral-medium-latest",
    "model_name": "Mistral Medium 3",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "mistral-small": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 3e-7,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mistral-small",
    "model_name": "Mistral Small",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "mistral-small-latest": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 3e-7,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mistral-small-latest",
    "model_name": "Mistral Small",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "mistral-tiny": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 2.5e-7,
    "supports_assistant_prefill": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mistral-tiny",
    "model_name": "Mistral Tiny",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 0.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "open-codestral-mamba": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 2.5e-7,
    "source": "https://mistral.ai/technology/",
    "supports_assistant_prefill": true,
    "supports_tool_choice": true,
    "model_id": "open-codestral-mamba",
    "model_name": "Codestral Mamba",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 0.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "open-mistral-7b": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 2.5e-7,
    "supports_assistant_prefill": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "open-mistral-7b",
    "model_name": "Open Mistral 7b",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 0.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "open-mistral-nemo": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 3e-7,
    "source": "https://mistral.ai/technology/",
    "supports_assistant_prefill": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "open-mistral-nemo",
    "model_name": "Mistral NeMo",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "open-mistral-nemo-2407": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 3e-7,
    "source": "https://mistral.ai/technology/",
    "supports_assistant_prefill": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "open-mistral-nemo-2407",
    "model_name": "Open Mistral Nemo 2407",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "open-mixtral-8x22b": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 65336,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000006,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "open-mixtral-8x22b",
    "model_name": "Mixtral 8x22B",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "open-mixtral-8x7b": {
    "input_cost_per_token": 7e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 7e-7,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "open-mixtral-8x7b",
    "model_name": "Open Mixtral 8x7b",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.7,
    "output_cost_per_million": 0.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "pixtral-12b-2409": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 1.5e-7,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "pixtral-12b-2409",
    "model_name": "Pixtral 12B",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "pixtral-large-2411": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000006,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "pixtral-large-2411",
    "model_name": "Pixtral Large 2411",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "pixtral-large-latest": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000006,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "pixtral-large-latest",
    "model_name": "Pixtral Large",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "text-completion-codestral/codestral-2405": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0,
    "source": "https://docs.mistral.ai/capabilities/code_generation/",
    "model_id": "text-completion-codestral/codestral-2405",
    "model_name": "Codestral 2405",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-completion-codestral/codestral-latest": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0,
    "source": "https://docs.mistral.ai/capabilities/code_generation/",
    "model_id": "text-completion-codestral/codestral-latest",
    "model_name": "Codestral",
    "provider_id": "mistral",
    "provider_name": "Mistral AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/kimi-k2-0711-preview": {
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.0000025,
    "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "moonshot/kimi-k2-0711-preview",
    "model_name": "Kimi K2 0711 Preview",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 2.5,
    "cache_read_cost_per_token": 1.5e-7,
    "cache_read_cost_per_million": 0.15,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/kimi-latest": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000005,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "moonshot/kimi-latest",
    "model_name": "Kimi Latest",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": 1.5e-7,
    "cache_read_cost_per_million": 0.15,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/kimi-latest-128k": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000005,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "moonshot/kimi-latest-128k",
    "model_name": "Kimi Latest 128k",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": 1.5e-7,
    "cache_read_cost_per_million": 0.15,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/kimi-latest-32k": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000003,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "moonshot/kimi-latest-32k",
    "model_name": "Kimi Latest 32k",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": 1.5e-7,
    "cache_read_cost_per_million": 0.15,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/kimi-latest-8k": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000002,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "moonshot/kimi-latest-8k",
    "model_name": "Kimi Latest 8k",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": 1.5e-7,
    "cache_read_cost_per_million": 0.15,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/kimi-thinking-preview": {
    "input_cost_per_token": 0.00003,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.00003,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_vision": true,
    "model_id": "moonshot/kimi-thinking-preview",
    "model_name": "Kimi Thinking Preview",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 30,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/moonshot-v1-128k": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000005,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "moonshot/moonshot-v1-128k",
    "model_name": "Moonshot V1 128k",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/moonshot-v1-128k-0430": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000005,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "moonshot/moonshot-v1-128k-0430",
    "model_name": "Moonshot V1 128k 0430",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/moonshot-v1-128k-vision-preview": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000005,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "moonshot/moonshot-v1-128k-vision-preview",
    "model_name": "Moonshot V1 128k Vision Preview",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/moonshot-v1-32k": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000003,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "moonshot/moonshot-v1-32k",
    "model_name": "Moonshot V1 32k",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/moonshot-v1-32k-0430": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000003,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "moonshot/moonshot-v1-32k-0430",
    "model_name": "Moonshot V1 32k 0430",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/moonshot-v1-32k-vision-preview": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000003,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "moonshot/moonshot-v1-32k-vision-preview",
    "model_name": "Moonshot V1 32k Vision Preview",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/moonshot-v1-8k": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000002,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "moonshot/moonshot-v1-8k",
    "model_name": "Moonshot V1 8k",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/moonshot-v1-8k-0430": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000002,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "moonshot/moonshot-v1-8k-0430",
    "model_name": "Moonshot V1 8k 0430",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/moonshot-v1-8k-vision-preview": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000002,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "moonshot/moonshot-v1-8k-vision-preview",
    "model_name": "Moonshot V1 8k Vision Preview",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "moonshot/moonshot-v1-auto": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000005,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "moonshot/moonshot-v1-auto",
    "model_name": "Moonshot V1 Auto",
    "provider_id": "moonshot",
    "provider_name": "Moonshot AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "morph/morph-v3-fast": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 16000,
    "max_output_tokens": 16000,
    "max_tokens": 16000,
    "output_cost_per_token": 0.0000012,
    "supports_function_calling": false,
    "supports_parallel_function_calling": false,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": false,
    "model_id": "morph/morph-v3-fast",
    "model_name": "Morph V3 Fast",
    "provider_id": "morph",
    "provider_name": "Morph",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": false,
    "supports_json_mode": false
  },
  "morph/morph-v3-large": {
    "input_cost_per_token": 9e-7,
    "max_input_tokens": 16000,
    "max_output_tokens": 16000,
    "max_tokens": 16000,
    "output_cost_per_token": 0.0000019,
    "supports_function_calling": false,
    "supports_parallel_function_calling": false,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": false,
    "model_id": "morph/morph-v3-large",
    "model_name": "Morph V3 Large",
    "provider_id": "morph",
    "provider_name": "Morph",
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 1.9,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": false,
    "supports_json_mode": false
  },
  "chatdolphin": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 5e-7,
    "model_id": "chatdolphin",
    "model_name": "Chatdolphin",
    "provider_id": "nlp",
    "provider_name": "Nlp",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "dolphin": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 5e-7,
    "model_id": "dolphin",
    "model_name": "Dolphin",
    "provider_id": "nlp",
    "provider_name": "Nlp",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/black-forest-labs/FLUX.1-schnell": {
    "input_cost_per_pixel": 1.3e-9,
    "output_cost_per_pixel": 0,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#image-models",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "nscale/black-forest-labs/FLUX.1-schnell",
    "model_name": "FLUX.1 Schnell",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
    "input_cost_per_token": 3.75e-7,
    "metadata": {
      "notes": "Pricing listed as $0.75/1M tokens total. Assumed 50/50 split for input/output."
    },
    "output_cost_per_token": 3.75e-7,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek R1 Distill Llama 70B",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.375,
    "output_cost_per_million": 0.375,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B": {
    "input_cost_per_token": 2.5e-8,
    "metadata": {
      "notes": "Pricing listed as $0.05/1M tokens total. Assumed 50/50 split for input/output."
    },
    "output_cost_per_token": 2.5e-8,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
    "model_name": "DeepSeek R1 Distill Llama 8B",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.024999999999999998,
    "output_cost_per_million": 0.024999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": {
    "input_cost_per_token": 9e-8,
    "metadata": {
      "notes": "Pricing listed as $0.18/1M tokens total. Assumed 50/50 split for input/output."
    },
    "output_cost_per_token": 9e-8,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
    "model_name": "DeepSeek R1 Distill Qwen 1.5B",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.09,
    "output_cost_per_million": 0.09,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
    "input_cost_per_token": 7e-8,
    "metadata": {
      "notes": "Pricing listed as $0.14/1M tokens total. Assumed 50/50 split for input/output."
    },
    "output_cost_per_token": 7e-8,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
    "model_name": "DeepSeek R1 Distill Qwen 14B",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.07,
    "output_cost_per_million": 0.07,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
    "input_cost_per_token": 1.5e-7,
    "metadata": {
      "notes": "Pricing listed as $0.30/1M tokens total. Assumed 50/50 split for input/output."
    },
    "output_cost_per_token": 1.5e-7,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "model_name": "DeepSeek R1 Distill Qwen 32B",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
    "input_cost_per_token": 2e-7,
    "metadata": {
      "notes": "Pricing listed as $0.40/1M tokens total. Assumed 50/50 split for input/output."
    },
    "output_cost_per_token": 2e-7,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "model_name": "DeepSeek R1 Distill Qwen 7B",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/meta-llama/Llama-3.1-8B-Instruct": {
    "input_cost_per_token": 3e-8,
    "metadata": {
      "notes": "Pricing listed as $0.06/1M tokens total. Assumed 50/50 split for input/output."
    },
    "output_cost_per_token": 3e-8,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/meta-llama/Llama-3.1-8B-Instruct",
    "model_name": "Llama 3.1 8B Instruct",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.03,
    "output_cost_per_million": 0.03,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/meta-llama/Llama-3.3-70B-Instruct": {
    "input_cost_per_token": 2e-7,
    "metadata": {
      "notes": "Pricing listed as $0.40/1M tokens total. Assumed 50/50 split for input/output."
    },
    "output_cost_per_token": 2e-7,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/meta-llama/Llama-3.3-70B-Instruct",
    "model_name": "Llama 3.3 70B Instruct",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
    "input_cost_per_token": 9e-8,
    "output_cost_per_token": 2.9e-7,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "model_name": "Llama 4 Scout 17B 16E Instruct",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.09,
    "output_cost_per_million": 0.29,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/mistralai/mixtral-8x22b-instruct-v0.1": {
    "input_cost_per_token": 6e-7,
    "metadata": {
      "notes": "Pricing listed as $1.20/1M tokens total. Assumed 50/50 split for input/output."
    },
    "output_cost_per_token": 6e-7,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/mistralai/mixtral-8x22b-instruct-v0.1",
    "model_name": "Mixtral 8x22B Instruct v0.1",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/Qwen/Qwen2.5-Coder-32B-Instruct": {
    "input_cost_per_token": 6e-8,
    "output_cost_per_token": 2e-7,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/Qwen/Qwen2.5-Coder-32B-Instruct",
    "model_name": "Qwen2.5 Coder 32B Instruct",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.06,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/Qwen/Qwen2.5-Coder-3B-Instruct": {
    "input_cost_per_token": 1e-8,
    "output_cost_per_token": 3e-8,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/Qwen/Qwen2.5-Coder-3B-Instruct",
    "model_name": "Qwen2.5 Coder 3B Instruct",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.01,
    "output_cost_per_million": 0.03,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/Qwen/Qwen2.5-Coder-7B-Instruct": {
    "input_cost_per_token": 1e-8,
    "output_cost_per_token": 3e-8,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/Qwen/Qwen2.5-Coder-7B-Instruct",
    "model_name": "Qwen2.5 Coder 7B Instruct",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.01,
    "output_cost_per_million": 0.03,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/Qwen/QwQ-32B": {
    "input_cost_per_token": 1.8e-7,
    "output_cost_per_token": 2e-7,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#chat-models",
    "model_id": "nscale/Qwen/QwQ-32B",
    "model_name": "QwQ 32B",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.18,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "nscale/stabilityai/stable-diffusion-xl-base-1.0": {
    "input_cost_per_pixel": 3e-9,
    "output_cost_per_pixel": 0,
    "source": "https://docs.nscale.com/docs/inference/serverless-models/current#image-models",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "nscale/stabilityai/stable-diffusion-xl-base-1.0",
    "model_name": "Stable Diffusion Xl Base 1.0",
    "provider_id": "nscale",
    "provider_name": "Nscale",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "oci/meta.llama-3.1-405b-instruct": {
    "input_cost_per_token": 0.00001068,
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00001068,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "model_id": "oci/meta.llama-3.1-405b-instruct",
    "model_name": "Meta.llama 3.1 405b Instruct",
    "provider_id": "oci",
    "provider_name": "Oci",
    "input_cost_per_million": 10.68,
    "output_cost_per_million": 10.68,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "oci/meta.llama-3.2-90b-vision-instruct": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000002,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "model_id": "oci/meta.llama-3.2-90b-vision-instruct",
    "model_name": "Meta.llama 3.2 90b Vision Instruct",
    "provider_id": "oci",
    "provider_name": "Oci",
    "input_cost_per_million": 2,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "oci/meta.llama-3.3-70b-instruct": {
    "input_cost_per_token": 7.2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 128000,
    "output_cost_per_token": 7.2e-7,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "model_id": "oci/meta.llama-3.3-70b-instruct",
    "model_name": "Meta.llama 3.3 70b Instruct",
    "provider_id": "oci",
    "provider_name": "Oci",
    "input_cost_per_million": 0.72,
    "output_cost_per_million": 0.72,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "oci/meta.llama-4-maverick-17b-128e-instruct-fp8": {
    "input_cost_per_token": 7.2e-7,
    "max_input_tokens": 512000,
    "max_output_tokens": 4000,
    "max_tokens": 512000,
    "output_cost_per_token": 7.2e-7,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "model_id": "oci/meta.llama-4-maverick-17b-128e-instruct-fp8",
    "model_name": "Meta.llama 4 Maverick 17b 128e Instruct Fp8",
    "provider_id": "oci",
    "provider_name": "Oci",
    "input_cost_per_million": 0.72,
    "output_cost_per_million": 0.72,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "oci/meta.llama-4-scout-17b-16e-instruct": {
    "input_cost_per_token": 7.2e-7,
    "max_input_tokens": 192000,
    "max_output_tokens": 4000,
    "max_tokens": 192000,
    "output_cost_per_token": 7.2e-7,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "model_id": "oci/meta.llama-4-scout-17b-16e-instruct",
    "model_name": "Meta.llama 4 Scout 17b 16e Instruct",
    "provider_id": "oci",
    "provider_name": "Oci",
    "input_cost_per_million": 0.72,
    "output_cost_per_million": 0.72,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "oci/xai.grok-3": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 1.5e-7,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "model_id": "oci/xai.grok-3",
    "model_name": "Xai.grok 3",
    "provider_id": "oci",
    "provider_name": "Oci",
    "input_cost_per_million": 3,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "oci/xai.grok-3-fast": {
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000025,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "model_id": "oci/xai.grok-3-fast",
    "model_name": "Xai.grok 3 Fast",
    "provider_id": "oci",
    "provider_name": "Oci",
    "input_cost_per_million": 5,
    "output_cost_per_million": 25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "oci/xai.grok-3-mini": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 5e-7,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "model_id": "oci/xai.grok-3-mini",
    "model_name": "Xai.grok 3 Mini",
    "provider_id": "oci",
    "provider_name": "Oci",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "oci/xai.grok-3-mini-fast": {
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000004,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "model_id": "oci/xai.grok-3-mini-fast",
    "model_name": "Xai.grok 3 Mini Fast",
    "provider_id": "oci",
    "provider_name": "Oci",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "oci/xai.grok-4": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 1.5e-7,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "model_id": "oci/xai.grok-4",
    "model_name": "Xai.grok 4",
    "provider_id": "oci",
    "provider_name": "Oci",
    "input_cost_per_million": 3,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "ollama/codegeex4": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "supports_function_calling": false,
    "model_id": "ollama/codegeex4",
    "model_name": "Codegeex4",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/codegemma": {
    "input_cost_per_token": 0,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "model_id": "ollama/codegemma",
    "model_name": "Codegemma",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/codellama": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "ollama/codellama",
    "model_name": "Codellama",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/deepseek-coder-v2-base": {
    "input_cost_per_token": 0,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "model_id": "ollama/deepseek-coder-v2-base",
    "model_name": "Deepseek Coder V2 Base",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/deepseek-coder-v2-instruct": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "model_id": "ollama/deepseek-coder-v2-instruct",
    "model_name": "Deepseek Coder V2 Instruct",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/deepseek-coder-v2-lite-base": {
    "input_cost_per_token": 0,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "model_id": "ollama/deepseek-coder-v2-lite-base",
    "model_name": "Deepseek Coder V2 Lite Base",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/deepseek-coder-v2-lite-instruct": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "model_id": "ollama/deepseek-coder-v2-lite-instruct",
    "model_name": "Deepseek Coder V2 Lite Instruct",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/internlm2_5-20b-chat": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "model_id": "ollama/internlm2_5-20b-chat",
    "model_name": "Internlm2_5 20b Chat",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/llama2": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "ollama/llama2",
    "model_name": "Llama2",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/llama2-uncensored": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "ollama/llama2-uncensored",
    "model_name": "Llama2 Uncensored",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/llama2:13b": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "ollama/llama2:13b",
    "model_name": "Llama2:13b",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/llama2:70b": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "ollama/llama2:70b",
    "model_name": "Llama2:70b",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/llama2:7b": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "ollama/llama2:7b",
    "model_name": "Llama2:7b",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/llama3": {
    "input_cost_per_token": 0,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "model_id": "ollama/llama3",
    "model_name": "Llama3",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/llama3:70b": {
    "input_cost_per_token": 0,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "model_id": "ollama/llama3:70b",
    "model_name": "Llama3:70b",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/llama3:8b": {
    "input_cost_per_token": 0,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "model_id": "ollama/llama3:8b",
    "model_name": "Llama3:8b",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/llama3.1": {
    "input_cost_per_token": 0,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "model_id": "ollama/llama3.1",
    "model_name": "Llama3.1",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/mistral": {
    "input_cost_per_token": 0,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "model_id": "ollama/mistral",
    "model_name": "Mistral",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/mistral-7B-Instruct-v0.1": {
    "input_cost_per_token": 0,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "model_id": "ollama/mistral-7B-Instruct-v0.1",
    "model_name": "Mistral 7B Instruct V0.1",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/mistral-7B-Instruct-v0.2": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "model_id": "ollama/mistral-7B-Instruct-v0.2",
    "model_name": "Mistral 7B Instruct V0.2",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/mistral-large-instruct-2407": {
    "input_cost_per_token": 0,
    "max_input_tokens": 65536,
    "max_output_tokens": 8192,
    "max_tokens": 65536,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "model_id": "ollama/mistral-large-instruct-2407",
    "model_name": "Mistral Large Instruct 2407",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/mixtral-8x22B-Instruct-v0.1": {
    "input_cost_per_token": 0,
    "max_input_tokens": 65536,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "model_id": "ollama/mixtral-8x22B-Instruct-v0.1",
    "model_name": "Mixtral 8x22B Instruct V0.1",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/mixtral-8x7B-Instruct-v0.1": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "model_id": "ollama/mixtral-8x7B-Instruct-v0.1",
    "model_name": "Mixtral 8x7B Instruct V0.1",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/orca-mini": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "ollama/orca-mini",
    "model_name": "Orca Mini",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ollama/vicuna": {
    "input_cost_per_token": 0,
    "max_input_tokens": 2048,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0,
    "model_id": "ollama/vicuna",
    "model_name": "Vicuna",
    "provider_id": "ollama",
    "provider_name": "Ollama",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "1024-x-1024/dall-e-2": {
    "input_cost_per_pixel": 1.9e-8,
    "output_cost_per_pixel": 0,
    "model_id": "1024-x-1024/dall-e-2",
    "model_name": "Dall E 2",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "256-x-256/dall-e-2": {
    "input_cost_per_pixel": 2.4414e-7,
    "output_cost_per_pixel": 0,
    "model_id": "256-x-256/dall-e-2",
    "model_name": "Dall E 2",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "512-x-512/dall-e-2": {
    "input_cost_per_pixel": 6.86e-8,
    "output_cost_per_pixel": 0,
    "model_id": "512-x-512/dall-e-2",
    "model_name": "Dall E 2",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "chatgpt-4o-latest": {
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "chatgpt-4o-latest",
    "model_name": "ChatGPT-4o",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 5,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "codex-mini-latest": {
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.000006,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "codex-mini-latest",
    "model_name": "Codex Mini Latest",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": 3.75e-7,
    "cache_read_cost_per_million": 0.375,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "ft:gpt-3.5-turbo": {
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_batches": 0.0000015,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000006,
    "output_cost_per_token_batches": 0.000003,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "ft:gpt-3.5-turbo",
    "model_name": "Ft:GPT 3.5 Turbo",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ft:gpt-3.5-turbo-0125": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000006,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "ft:gpt-3.5-turbo-0125",
    "model_name": "Ft:GPT 3.5 Turbo 0125",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ft:gpt-3.5-turbo-0613": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000006,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "ft:gpt-3.5-turbo-0613",
    "model_name": "Ft:GPT 3.5 Turbo 0613",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ft:gpt-3.5-turbo-1106": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000006,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "ft:gpt-3.5-turbo-1106",
    "model_name": "Ft:GPT 3.5 Turbo 1106",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ft:gpt-4-0613": {
    "input_cost_per_token": 0.00003,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00006,
    "source": "OpenAI needs to add pricing for this ft model, will be updated when added by OpenAI. Defaulting to base model pricing",
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "ft:gpt-4-0613",
    "model_name": "Ft:GPT 4 0613",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 30,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ft:gpt-4o-2024-08-06": {
    "input_cost_per_token": 0.00000375,
    "input_cost_per_token_batches": 0.000001875,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.000015,
    "output_cost_per_token_batches": 0.0000075,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "ft:gpt-4o-2024-08-06",
    "model_name": "Ft:GPT 4o 2024 08 06",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 3.75,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "ft:gpt-4o-2024-11-20": {
    "input_cost_per_token": 0.00000375,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "ft:gpt-4o-2024-11-20",
    "model_name": "Ft:GPT 4o 2024 11 20",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 3.75,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": 0.000001875,
    "cache_write_cost_per_million": 1.875,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "ft:gpt-4o-mini-2024-07-18": {
    "input_cost_per_token": 3e-7,
    "input_cost_per_token_batches": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.0000012,
    "output_cost_per_token_batches": 6e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "ft:gpt-4o-mini-2024-07-18",
    "model_name": "Ft:GPT 4o Mini 2024 07 18",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": 1.5e-7,
    "cache_read_cost_per_million": 0.15,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-3.5-turbo": {
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 4097,
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-3.5-turbo",
    "model_name": "GPT 3.5T",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-3.5-turbo-0125": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 16385,
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-3.5-turbo-0125",
    "model_name": "GPT 3.5T 0125",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-3.5-turbo-0301": {
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "max_tokens": 4097,
    "output_cost_per_token": 0.000002,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-3.5-turbo-0301",
    "model_name": "GPT 3.5 Turbo 0301",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-3.5-turbo-0613": {
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "max_tokens": 4097,
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-3.5-turbo-0613",
    "model_name": "GPT 3.5 Turbo 0613",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-3.5-turbo-1106": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 16385,
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-3.5-turbo-1106",
    "model_name": "GPT 3.5T 1106",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-3.5-turbo-16k": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 16385,
    "output_cost_per_token": 0.000004,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-3.5-turbo-16k",
    "model_name": "GPT 3.5T 16k",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-3.5-turbo-16k-0613": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 16385,
    "output_cost_per_token": 0.000004,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-3.5-turbo-16k-0613",
    "model_name": "GPT 3.5 Turbo 16k 0613",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-4": {
    "input_cost_per_token": 0.00003,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4",
    "model_name": "GPT-4",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 30,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-4-0125-preview": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4-0125-preview",
    "model_name": "GPT 4 0125 Preview",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4-0314": {
    "input_cost_per_token": 0.00003,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00006,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4-0314",
    "model_name": "GPT 4 0314",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 30,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-4-0613": {
    "deprecation_date": "2025-06-06",
    "input_cost_per_token": 0.00003,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4-0613",
    "model_name": "GPT 4 0613",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 30,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-4-1106-preview": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4-1106-preview",
    "model_name": "GPT 4 1106 Preview",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4-1106-vision-preview": {
    "deprecation_date": "2024-12-06",
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00003,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4-1106-vision-preview",
    "model_name": "GPT 4 1106 Vision Preview",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-4-32k": {
    "input_cost_per_token": 0.00006,
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00012,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4-32k",
    "model_name": "GPT 4 32k",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 60,
    "output_cost_per_million": 120,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-4-32k-0314": {
    "input_cost_per_token": 0.00006,
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00012,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4-32k-0314",
    "model_name": "GPT 4 32k 0314",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 60,
    "output_cost_per_million": 120,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-4-32k-0613": {
    "input_cost_per_token": 0.00006,
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00012,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4-32k-0613",
    "model_name": "GPT 4 32k 0613",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 60,
    "output_cost_per_million": 120,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-4-turbo": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4-turbo",
    "model_name": "GPT-4 Turbo",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "gpt-4-turbo-2024-04-09": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4-turbo-2024-04-09",
    "model_name": "GPT 4 Turbo 2024 04 09",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "gpt-4-turbo-preview": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4-turbo-preview",
    "model_name": "GPT-4 Turbo Preview",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4-vision-preview": {
    "deprecation_date": "2024-12-06",
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00003,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4-vision-preview",
    "model_name": "GPT 4 Vision-Preview",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-4.1": {
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_batches": 0.000004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4.1",
    "model_name": "GPT-4.1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4.1-2025-04-14": {
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_batches": 0.000004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4.1-2025-04-14",
    "model_name": "GPT-4.1 (Apr 2025)",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4.1-mini": {
    "input_cost_per_token": 4e-7,
    "input_cost_per_token_batches": 2e-7,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.0000016,
    "output_cost_per_token_batches": 8e-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4.1-mini",
    "model_name": "GPT-4.1 mini",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.5999999999999999,
    "cache_read_cost_per_token": 1e-7,
    "cache_read_cost_per_million": 0.09999999999999999,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4.1-mini-2025-04-14": {
    "input_cost_per_token": 4e-7,
    "input_cost_per_token_batches": 2e-7,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.0000016,
    "output_cost_per_token_batches": 8e-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4.1-mini-2025-04-14",
    "model_name": "GPT 4.1 Mini 2025 04 14",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.5999999999999999,
    "cache_read_cost_per_token": 1e-7,
    "cache_read_cost_per_million": 0.09999999999999999,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4.1-nano": {
    "input_cost_per_token": 1e-7,
    "input_cost_per_token_batches": 5e-8,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 4e-7,
    "output_cost_per_token_batches": 2e-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4.1-nano",
    "model_name": "GPT-4.1 nano",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4.1-nano-2025-04-14": {
    "input_cost_per_token": 1e-7,
    "input_cost_per_token_batches": 5e-8,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 4e-7,
    "output_cost_per_token_batches": 2e-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4.1-nano-2025-04-14",
    "model_name": "GPT 4.1 Nano 2025 04 14",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4.5-preview": {
    "input_cost_per_token": 0.000075,
    "input_cost_per_token_batches": 0.0000375,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00015,
    "output_cost_per_token_batches": 0.000075,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4.5-preview",
    "model_name": "GPT-4.5",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 75,
    "output_cost_per_million": 150,
    "cache_read_cost_per_token": 0.0000375,
    "cache_read_cost_per_million": 37.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4.5-preview-2025-02-27": {
    "deprecation_date": "2025-07-14",
    "input_cost_per_token": 0.000075,
    "input_cost_per_token_batches": 0.0000375,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00015,
    "output_cost_per_token_batches": 0.000075,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4.5-preview-2025-02-27",
    "model_name": "GPT 4.5 Preview 2025 02 27",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 75,
    "output_cost_per_million": 150,
    "cache_read_cost_per_token": 0.0000375,
    "cache_read_cost_per_million": 37.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4o": {
    "input_cost_per_token": 0.0000025,
    "input_cost_per_token_batches": 0.00000125,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_batches": 0.000005,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4o",
    "model_name": "GPT-4o",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4o-2024-05-13": {
    "input_cost_per_token": 0.000005,
    "input_cost_per_token_batches": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "output_cost_per_token_batches": 0.0000075,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4o-2024-05-13",
    "model_name": "GPT-4o (May 2024)",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 5,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "gpt-4o-2024-08-06": {
    "input_cost_per_token": 0.0000025,
    "input_cost_per_token_batches": 0.00000125,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_batches": 0.000005,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4o-2024-08-06",
    "model_name": "GPT-4o (Aug 2024)",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4o-2024-11-20": {
    "input_cost_per_token": 0.0000025,
    "input_cost_per_token_batches": 0.00000125,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_batches": 0.000005,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4o-2024-11-20",
    "model_name": "GPT-4o (Nov 2024)",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4o-audio-preview": {
    "input_cost_per_audio_token": 0.0001,
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_audio_token": 0.0002,
    "output_cost_per_token": 0.00001,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4o-audio-preview",
    "model_name": "GPT 4o Audio Preview",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4o-audio-preview-2024-10-01": {
    "input_cost_per_audio_token": 0.0001,
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_audio_token": 0.0002,
    "output_cost_per_token": 0.00001,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4o-audio-preview-2024-10-01",
    "model_name": "GPT 4o Audio Preview 2024 10 01",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4o-audio-preview-2024-12-17": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00001,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4o-audio-preview-2024-12-17",
    "model_name": "GPT 4o Audio Preview 2024 12 17",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4o-audio-preview-2025-06-03": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00001,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4o-audio-preview-2025-06-03",
    "model_name": "GPT 4o Audio Preview 2025 06 03",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4o-mini": {
    "input_cost_per_token": 1.5e-7,
    "input_cost_per_token_batches": 7.5e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 6e-7,
    "output_cost_per_token_batches": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4o-mini",
    "model_name": "GPT-4o mini",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4o-mini-2024-07-18": {
    "input_cost_per_token": 1.5e-7,
    "input_cost_per_token_batches": 7.5e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 6e-7,
    "output_cost_per_token_batches": 3e-7,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.03,
      "search_context_size_low": 0.025,
      "search_context_size_medium": 0.0275
    },
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4o-mini-2024-07-18",
    "model_name": "GPT-4o mini (Jul 2024)",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4o-mini-audio-preview": {
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 6e-7,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4o-mini-audio-preview",
    "model_name": "GPT 4o Mini Audio Preview",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4o-mini-audio-preview-2024-12-17": {
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 6e-7,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4o-mini-audio-preview-2024-12-17",
    "model_name": "GPT 4o Mini Audio Preview 2024 12 17",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4o-mini-realtime-preview": {
    "cache_creation_input_audio_token_cost": 3e-7,
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4o-mini-realtime-preview",
    "model_name": "GPT 4o Mini Realtime Preview",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 2.4,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4o-mini-realtime-preview-2024-12-17": {
    "cache_creation_input_audio_token_cost": 3e-7,
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4o-mini-realtime-preview-2024-12-17",
    "model_name": "GPT 4o Mini Realtime Preview 2024 12 17",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 2.4,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4o-mini-search-preview": {
    "input_cost_per_token": 1.5e-7,
    "input_cost_per_token_batches": 7.5e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 6e-7,
    "output_cost_per_token_batches": 3e-7,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.03,
      "search_context_size_low": 0.025,
      "search_context_size_medium": 0.0275
    },
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gpt-4o-mini-search-preview",
    "model_name": "GPT-4o mini Search Preview",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4o-mini-search-preview-2025-03-11": {
    "input_cost_per_token": 1.5e-7,
    "input_cost_per_token_batches": 7.5e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 6e-7,
    "output_cost_per_token_batches": 3e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4o-mini-search-preview-2025-03-11",
    "model_name": "GPT 4o Mini Search Preview 2025 03 11",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4o-mini-transcribe": {
    "input_cost_per_audio_token": 0.000003,
    "input_cost_per_token": 0.00000125,
    "max_input_tokens": 16000,
    "max_output_tokens": 2000,
    "output_cost_per_token": 0.000005,
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "gpt-4o-mini-transcribe",
    "model_name": "GPT 4o Mini Transcribe",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-4o-mini-tts": {
    "input_cost_per_token": 0.0000025,
    "output_cost_per_audio_token": 0.000012,
    "output_cost_per_second": 0.00025,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/audio/speech"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "audio"
    ],
    "model_id": "gpt-4o-mini-tts",
    "model_name": "GPT 4o Mini Tts",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-4o-realtime-preview": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00002,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4o-realtime-preview",
    "model_name": "GPT 4o Realtime Preview",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 5,
    "output_cost_per_million": 20,
    "cache_read_cost_per_token": 0.0000025,
    "cache_read_cost_per_million": 2.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4o-realtime-preview-2024-10-01": {
    "cache_creation_input_audio_token_cost": 0.00002,
    "input_cost_per_audio_token": 0.0001,
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.0002,
    "output_cost_per_token": 0.00002,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4o-realtime-preview-2024-10-01",
    "model_name": "GPT 4o Realtime Preview 2024 10 01",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 5,
    "output_cost_per_million": 20,
    "cache_read_cost_per_token": 0.0000025,
    "cache_read_cost_per_million": 2.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4o-realtime-preview-2024-12-17": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00002,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4o-realtime-preview-2024-12-17",
    "model_name": "GPT 4o Realtime Preview 2024 12 17",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 5,
    "output_cost_per_million": 20,
    "cache_read_cost_per_token": 0.0000025,
    "cache_read_cost_per_million": 2.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4o-realtime-preview-2025-06-03": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00002,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-4o-realtime-preview-2025-06-03",
    "model_name": "GPT 4o Realtime Preview 2025 06 03",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 5,
    "output_cost_per_million": 20,
    "cache_read_cost_per_token": 0.0000025,
    "cache_read_cost_per_million": 2.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-4o-search-preview": {
    "input_cost_per_token": 0.0000025,
    "input_cost_per_token_batches": 0.00000125,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_batches": 0.000005,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.05,
      "search_context_size_low": 0.03,
      "search_context_size_medium": 0.035
    },
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gpt-4o-search-preview",
    "model_name": "GPT-4o Search Preview",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4o-search-preview-2025-03-11": {
    "input_cost_per_token": 0.0000025,
    "input_cost_per_token_batches": 0.00000125,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_batches": 0.000005,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-4o-search-preview-2025-03-11",
    "model_name": "GPT 4o Search Preview 2025 03 11",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-4o-transcribe": {
    "input_cost_per_audio_token": 0.000006,
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 16000,
    "max_output_tokens": 2000,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "gpt-4o-transcribe",
    "model_name": "GPT 4o Transcribe",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-5": {
    "input_cost_per_token": 0.00000125,
    "max_input_tokens": 400000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-5",
    "model_name": "GPT 5",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 1.25e-7,
    "cache_read_cost_per_million": 0.125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-5-2025-08-07": {
    "input_cost_per_token": 0.00000125,
    "max_input_tokens": 400000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-5-2025-08-07",
    "model_name": "GPT 5 2025 08 07",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 1.25e-7,
    "cache_read_cost_per_million": 0.125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-5-chat": {
    "input_cost_per_token": 0.00000125,
    "max_input_tokens": 400000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true,
    "model_id": "gpt-5-chat",
    "model_name": "GPT 5 Chat",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 1.25e-7,
    "cache_read_cost_per_million": 0.125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "gpt-5-chat-latest": {
    "input_cost_per_token": 0.00000125,
    "max_input_tokens": 400000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true,
    "model_id": "gpt-5-chat-latest",
    "model_name": "GPT 5 Chat Latest",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 1.25e-7,
    "cache_read_cost_per_million": 0.125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "gpt-5-mini": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 400000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-5-mini",
    "model_name": "GPT 5 Mini",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-5-mini-2025-08-07": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 400000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-5-mini-2025-08-07",
    "model_name": "GPT 5 Mini 2025 08 07",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-5-nano": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 400000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 4e-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-5-nano",
    "model_name": "GPT 5 Nano",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 5e-9,
    "cache_read_cost_per_million": 0.005,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-5-nano-2025-08-07": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 400000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 4e-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gpt-5-nano-2025-08-07",
    "model_name": "GPT 5 Nano 2025 08 07",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 5e-9,
    "cache_read_cost_per_million": 0.005,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gpt-image-1": {
    "input_cost_per_pixel": 4.0054321e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-realtime": {
    "cache_creation_input_audio_token_cost": 4e-7,
    "input_cost_per_audio_token": 0.000032,
    "input_cost_per_image": 0.000005,
    "input_cost_per_token": 0.000004,
    "max_input_tokens": 32000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.000064,
    "output_cost_per_token": 0.000016,
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-realtime",
    "model_name": "GPT Realtime",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 4,
    "output_cost_per_million": 16,
    "cache_read_cost_per_token": 4e-7,
    "cache_read_cost_per_million": 0.39999999999999997,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gpt-realtime-2025-08-28": {
    "cache_creation_input_audio_token_cost": 4e-7,
    "input_cost_per_audio_token": 0.000032,
    "input_cost_per_image": 0.000005,
    "input_cost_per_token": 0.000004,
    "max_input_tokens": 32000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_audio_token": 0.000064,
    "output_cost_per_token": 0.000016,
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gpt-realtime-2025-08-28",
    "model_name": "GPT Realtime 2025 08 28",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 4,
    "output_cost_per_million": 16,
    "cache_read_cost_per_token": 4e-7,
    "cache_read_cost_per_million": 0.39999999999999997,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "hd/1024-x-1024/dall-e-3": {
    "input_cost_per_pixel": 7.629e-8,
    "output_cost_per_pixel": 0,
    "model_id": "hd/1024-x-1024/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "hd/1024-x-1792/dall-e-3": {
    "input_cost_per_pixel": 6.539e-8,
    "output_cost_per_pixel": 0,
    "model_id": "hd/1024-x-1792/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "hd/1792-x-1024/dall-e-3": {
    "input_cost_per_pixel": 6.539e-8,
    "output_cost_per_pixel": 0,
    "model_id": "hd/1792-x-1024/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "high/1024-x-1024/gpt-image-1": {
    "input_cost_per_pixel": 1.59263611e-7,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "high/1024-x-1024/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "high/1024-x-1536/gpt-image-1": {
    "input_cost_per_pixel": 1.58945719e-7,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "high/1024-x-1536/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "high/1536-x-1024/gpt-image-1": {
    "input_cost_per_pixel": 1.58945719e-7,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "high/1536-x-1024/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "low/1024-x-1024/gpt-image-1": {
    "input_cost_per_pixel": 1.0490417e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "low/1024-x-1024/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "low/1024-x-1536/gpt-image-1": {
    "input_cost_per_pixel": 1.0172526e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "low/1024-x-1536/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "low/1536-x-1024/gpt-image-1": {
    "input_cost_per_pixel": 1.0172526e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "low/1536-x-1024/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "medium/1024-x-1024/gpt-image-1": {
    "input_cost_per_pixel": 4.0054321e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "medium/1024-x-1024/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "medium/1024-x-1536/gpt-image-1": {
    "input_cost_per_pixel": 4.0054321e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "medium/1024-x-1536/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "medium/1536-x-1024/gpt-image-1": {
    "input_cost_per_pixel": 4.0054321e-8,
    "output_cost_per_pixel": 0,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "medium/1536-x-1024/gpt-image-1",
    "model_name": "GPT Image 1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "o1": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o1",
    "model_name": "o1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 15,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": 0.0000075,
    "cache_read_cost_per_million": 7.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "o1-2024-12-17": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o1-2024-12-17",
    "model_name": "O1 2024 12 17",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 15,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": 0.0000075,
    "cache_read_cost_per_million": 7.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "o1-mini": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0.0000044,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_vision": true,
    "model_id": "o1-mini",
    "model_name": "o1 mini",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": 5.5e-7,
    "cache_read_cost_per_million": 0.55,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "o1-mini-2024-09-12": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0.000012,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": true,
    "model_id": "o1-mini-2024-09-12",
    "model_name": "O1 Mini 2024 09 12",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 12,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "o1-preview": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.00006,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": true,
    "model_id": "o1-preview",
    "model_name": "o1 Preview",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 15,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": 0.0000075,
    "cache_read_cost_per_million": 7.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "o1-preview-2024-09-12": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.00006,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": true,
    "model_id": "o1-preview-2024-09-12",
    "model_name": "O1 Preview 2024 09 12",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 15,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": 0.0000075,
    "cache_read_cost_per_million": 7.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "o1-pro": {
    "input_cost_per_token": 0.00015,
    "input_cost_per_token_batches": 0.000075,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.0006,
    "output_cost_per_token_batches": 0.0003,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o1-pro",
    "model_name": "o1 Pro",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 150,
    "output_cost_per_million": 600,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "o1-pro-2025-03-19": {
    "input_cost_per_token": 0.00015,
    "input_cost_per_token_batches": 0.000075,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.0006,
    "output_cost_per_token_batches": 0.0003,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o1-pro-2025-03-19",
    "model_name": "O1 Pro 2025 03 19",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 150,
    "output_cost_per_million": 600,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "o3": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.000008,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o3",
    "model_name": "o3",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "o3-2025-04-16": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.000008,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o3-2025-04-16",
    "model_name": "O3 2025 04 16",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "o3-deep-research": {
    "input_cost_per_token": 0.00001,
    "input_cost_per_token_batches": 0.000005,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00004,
    "output_cost_per_token_batches": 0.00002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o3-deep-research",
    "model_name": "O3 Deep Research",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 10,
    "output_cost_per_million": 40,
    "cache_read_cost_per_token": 0.0000025,
    "cache_read_cost_per_million": 2.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "o3-deep-research-2025-06-26": {
    "input_cost_per_token": 0.00001,
    "input_cost_per_token_batches": 0.000005,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00004,
    "output_cost_per_token_batches": 0.00002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o3-deep-research-2025-06-26",
    "model_name": "O3 Deep Research 2025 06 26",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 10,
    "output_cost_per_million": 40,
    "cache_read_cost_per_token": 0.0000025,
    "cache_read_cost_per_million": 2.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "o3-mini": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "o3-mini",
    "model_name": "o3 mini",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": 5.5e-7,
    "cache_read_cost_per_million": 0.55,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "o3-mini-2025-01-31": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "o3-mini-2025-01-31",
    "model_name": "O3 Mini 2025 01 31",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": 5.5e-7,
    "cache_read_cost_per_million": 0.55,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "o3-pro": {
    "input_cost_per_token": 0.00002,
    "input_cost_per_token_batches": 0.00001,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00008,
    "output_cost_per_token_batches": 0.00004,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o3-pro",
    "model_name": "o3 Pro",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 20,
    "output_cost_per_million": 80,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "o3-pro-2025-06-10": {
    "input_cost_per_token": 0.00002,
    "input_cost_per_token_batches": 0.00001,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00008,
    "output_cost_per_token_batches": 0.00004,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o3-pro-2025-06-10",
    "model_name": "O3 Pro 2025 06 10",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 20,
    "output_cost_per_million": 80,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "o4-mini": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o4-mini",
    "model_name": "o4 mini",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": 2.75e-7,
    "cache_read_cost_per_million": 0.275,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "o4-mini-2025-04-16": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o4-mini-2025-04-16",
    "model_name": "O4 Mini 2025 04 16",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": 2.75e-7,
    "cache_read_cost_per_million": 0.275,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "o4-mini-deep-research": {
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_batches": 0.000004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o4-mini-deep-research",
    "model_name": "O4 Mini Deep Research",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "o4-mini-deep-research-2025-06-26": {
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_batches": 0.000004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "o4-mini-deep-research-2025-06-26",
    "model_name": "O4 Mini Deep Research 2025 06 26",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "responses",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "omni-moderation-2024-09-26": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32768,
    "max_output_tokens": null,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "model_id": "omni-moderation-2024-09-26",
    "model_name": "Omni Moderation 2024 09 26",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "moderation",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "omni-moderation-latest": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32768,
    "max_output_tokens": null,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "model_id": "omni-moderation-latest",
    "model_name": "Omni Moderation Latest",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "moderation",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "omni-moderation-latest-intents": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32768,
    "max_output_tokens": null,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "model_id": "omni-moderation-latest-intents",
    "model_name": "Omni Moderation Latest Intents",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "moderation",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "standard/1024-x-1024/dall-e-3": {
    "input_cost_per_pixel": 3.81469e-8,
    "output_cost_per_pixel": 0,
    "model_id": "standard/1024-x-1024/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "standard/1024-x-1792/dall-e-3": {
    "input_cost_per_pixel": 4.359e-8,
    "output_cost_per_pixel": 0,
    "model_id": "standard/1024-x-1792/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "standard/1792-x-1024/dall-e-3": {
    "input_cost_per_pixel": 4.359e-8,
    "output_cost_per_pixel": 0,
    "model_id": "standard/1792-x-1024/dall-e-3",
    "model_name": "Dall E 3",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-embedding-3-large": {
    "input_cost_per_token": 1.3e-7,
    "input_cost_per_token_batches": 6.5e-8,
    "max_input_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0,
    "output_cost_per_token_batches": 0,
    "output_vector_size": 3072,
    "model_id": "text-embedding-3-large",
    "model_name": "Text Embedding 3 Large",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.13,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-embedding-3-small": {
    "input_cost_per_token": 2e-8,
    "input_cost_per_token_batches": 1e-8,
    "max_input_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0,
    "output_cost_per_token_batches": 0,
    "output_vector_size": 1536,
    "model_id": "text-embedding-3-small",
    "model_name": "Text Embedding 3 Small",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.02,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-embedding-ada-002": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0,
    "output_vector_size": 1536,
    "model_id": "text-embedding-ada-002",
    "model_name": "Text Embedding Ada 002",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-embedding-ada-002-v2": {
    "input_cost_per_token": 1e-7,
    "input_cost_per_token_batches": 5e-8,
    "max_input_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0,
    "output_cost_per_token_batches": 0,
    "model_id": "text-embedding-ada-002-v2",
    "model_name": "Text Embedding Ada 002 V2",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-moderation-007": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32768,
    "max_output_tokens": null,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "model_id": "text-moderation-007",
    "model_name": "Text Moderation 007",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "moderation",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-moderation-latest": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32768,
    "max_output_tokens": null,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "model_id": "text-moderation-latest",
    "model_name": "Text Moderation Latest",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "moderation",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-moderation-stable": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32768,
    "max_output_tokens": null,
    "max_tokens": 32768,
    "output_cost_per_token": 0,
    "model_id": "text-moderation-stable",
    "model_name": "Text Moderation Stable",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "moderation",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "tts-1": {
    "input_cost_per_character": 0.000015,
    "supported_endpoints": [
      "/v1/audio/speech"
    ],
    "model_id": "tts-1",
    "model_name": "Tts 1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "tts-1-hd": {
    "input_cost_per_character": 0.00003,
    "supported_endpoints": [
      "/v1/audio/speech"
    ],
    "model_id": "tts-1-hd",
    "model_name": "Tts 1 Hd",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "whisper-1": {
    "input_cost_per_second": 0.0001,
    "output_cost_per_second": 0.0001,
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ],
    "model_id": "whisper-1",
    "model_name": "Whisper 1",
    "provider_id": "openai",
    "provider_name": "OpenAI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "audio",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-2": {
    "input_cost_per_token": 0.00001102,
    "max_output_tokens": 8191,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00003268,
    "supports_tool_choice": true,
    "model_id": "openrouter/anthropic/claude-2",
    "model_name": "Claude 2",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "input_cost_per_million": 11.02,
    "output_cost_per_million": 32.68,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-3-5-haiku": {
    "input_cost_per_token": 0.000001,
    "max_tokens": 200000,
    "output_cost_per_token": 0.000005,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "openrouter/anthropic/claude-3-5-haiku",
    "model_name": "Claude 3 5 Haiku",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 1,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-3-5-haiku-20241022": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000005,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "tool_use_system_prompt_tokens": 264,
    "model_id": "openrouter/anthropic/claude-3-5-haiku-20241022",
    "model_name": "Claude 3.5 Haiku (Oct 2024)",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 1,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-3-haiku": {
    "input_cost_per_image": 0.0004,
    "input_cost_per_token": 2.5e-7,
    "max_tokens": 200000,
    "output_cost_per_token": 0.00000125,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/anthropic/claude-3-haiku",
    "model_name": "Claude 3 Haiku",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-3-haiku-20240307": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00000125,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 264,
    "model_id": "openrouter/anthropic/claude-3-haiku-20240307",
    "model_name": "Claude 3 Haiku",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-3-opus": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000075,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 395,
    "model_id": "openrouter/anthropic/claude-3-opus",
    "model_name": "Claude 3 Opus",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-3-sonnet": {
    "input_cost_per_image": 0.0048,
    "input_cost_per_token": 0.000003,
    "max_tokens": 200000,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/anthropic/claude-3-sonnet",
    "model_name": "Claude 3 Sonnet",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-3.5-sonnet": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "openrouter/anthropic/claude-3.5-sonnet",
    "model_name": "Claude 3.5 Sonnet",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-3.5-sonnet:beta": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "openrouter/anthropic/claude-3.5-sonnet:beta",
    "model_name": "Claude 3.5 Sonnet:beta",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-3.7-sonnet": {
    "input_cost_per_image": 0.0048,
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "openrouter/anthropic/claude-3.7-sonnet",
    "model_name": "Claude 3.7 Sonnet",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-3.7-sonnet:beta": {
    "input_cost_per_image": 0.0048,
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000015,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "openrouter/anthropic/claude-3.7-sonnet:beta",
    "model_name": "Claude 3.7 Sonnet:beta",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-instant-v1": {
    "input_cost_per_token": 0.00000163,
    "max_output_tokens": 8191,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00000551,
    "supports_tool_choice": true,
    "model_id": "openrouter/anthropic/claude-instant-v1",
    "model_name": "Claude Instant V1",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "input_cost_per_million": 1.6300000000000001,
    "output_cost_per_million": 5.51,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-opus-4": {
    "input_cost_per_image": 0.0048,
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "openrouter/anthropic/claude-opus-4",
    "model_name": "Claude Opus 4",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-opus-4.1": {
    "input_cost_per_image": 0.0048,
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "openrouter/anthropic/claude-opus-4.1",
    "model_name": "Claude Opus 4.1",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/anthropic/claude-sonnet-4": {
    "input_cost_per_image": 0.0048,
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "openrouter/anthropic/claude-sonnet-4",
    "model_name": "Claude Sonnet 4",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/bytedance/ui-tars-1.5-7b": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 2e-7,
    "source": "https://openrouter.ai/api/v1/models/bytedance/ui-tars-1.5-7b",
    "supports_tool_choice": true,
    "model_id": "openrouter/bytedance/ui-tars-1.5-7b",
    "model_name": "Ui Tars 1.5 7b",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/cognitivecomputations/dolphin-mixtral-8x7b": {
    "input_cost_per_token": 5e-7,
    "max_tokens": 32769,
    "output_cost_per_token": 5e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/cognitivecomputations/dolphin-mixtral-8x7b",
    "model_name": "Dolphin Mixtral 8x7b",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/cohere/command-r-plus": {
    "input_cost_per_token": 0.000003,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000015,
    "supports_tool_choice": true,
    "model_id": "openrouter/cohere/command-r-plus",
    "model_name": "Command R Plus",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/databricks/dbrx-instruct": {
    "input_cost_per_token": 6e-7,
    "max_tokens": 32768,
    "output_cost_per_token": 6e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/databricks/dbrx-instruct",
    "model_name": "DBRX Instruct",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/deepseek/deepseek-chat": {
    "input_cost_per_token": 1.4e-7,
    "max_input_tokens": 65536,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 2.8e-7,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "model_id": "openrouter/deepseek/deepseek-chat",
    "model_name": "Deepseek Chat",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.14,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/deepseek/deepseek-chat-v3-0324": {
    "input_cost_per_token": 1.4e-7,
    "max_input_tokens": 65536,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 2.8e-7,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "model_id": "openrouter/deepseek/deepseek-chat-v3-0324",
    "model_name": "Deepseek Chat V3 0324",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.14,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/deepseek/deepseek-chat-v3.1": {
    "input_cost_per_token": 2e-7,
    "input_cost_per_token_cache_hit": 2e-8,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 8192,
    "output_cost_per_token": 8e-7,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "openrouter/deepseek/deepseek-chat-v3.1",
    "model_name": "Deepseek Chat V3.1",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.7999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/deepseek/deepseek-coder": {
    "input_cost_per_token": 1.4e-7,
    "max_input_tokens": 66000,
    "max_output_tokens": 4096,
    "max_tokens": 8192,
    "output_cost_per_token": 2.8e-7,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "model_id": "openrouter/deepseek/deepseek-coder",
    "model_name": "Deepseek Coder",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.14,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/deepseek/deepseek-r1": {
    "input_cost_per_token": 5.5e-7,
    "input_cost_per_token_cache_hit": 1.4e-7,
    "max_input_tokens": 65336,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000219,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "openrouter/deepseek/deepseek-r1",
    "model_name": "DeepSeek R1",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.55,
    "output_cost_per_million": 2.1900000000000004,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/deepseek/deepseek-r1-0528": {
    "input_cost_per_token": 5e-7,
    "input_cost_per_token_cache_hit": 1.4e-7,
    "max_input_tokens": 65336,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000215,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "openrouter/deepseek/deepseek-r1-0528",
    "model_name": "Deepseek R1 0528",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 2.1500000000000004,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/fireworks/firellava-13b": {
    "input_cost_per_token": 2e-7,
    "max_tokens": 4096,
    "output_cost_per_token": 2e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/fireworks/firellava-13b",
    "model_name": "Firellava 13b",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/google/gemini-2.0-flash-001": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 1e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 4e-7,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/google/gemini-2.0-flash-001",
    "model_name": "Gemini 2.0 Flash 001",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "openrouter/google/gemini-2.5-flash": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 3e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.0000025,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/google/gemini-2.5-flash",
    "model_name": "Gemini 2.5 Flash",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 2.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "openrouter/google/gemini-2.5-pro": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 0.00000125,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/google/gemini-2.5-pro",
    "model_name": "Gemini 2.5 Pro",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "openrouter/google/gemini-pro-1.5": {
    "input_cost_per_image": 0.00265,
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000075,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/google/gemini-pro-1.5",
    "model_name": "Gemini Pro 1.5",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 7.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/google/gemini-pro-vision": {
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 1.25e-7,
    "max_tokens": 45875,
    "output_cost_per_token": 3.75e-7,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/google/gemini-pro-vision",
    "model_name": "Gemini Pro Vision",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.375,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/google/palm-2-chat-bison": {
    "input_cost_per_token": 5e-7,
    "max_tokens": 25804,
    "output_cost_per_token": 5e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/google/palm-2-chat-bison",
    "model_name": "Palm 2 Chat Bison",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/google/palm-2-codechat-bison": {
    "input_cost_per_token": 5e-7,
    "max_tokens": 20070,
    "output_cost_per_token": 5e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/google/palm-2-codechat-bison",
    "model_name": "Palm 2 Codechat Bison",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/gryphe/mythomax-l2-13b": {
    "input_cost_per_token": 0.000001875,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000001875,
    "supports_tool_choice": true,
    "model_id": "openrouter/gryphe/mythomax-l2-13b",
    "model_name": "MythoMax L2 (13B)",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 1.875,
    "output_cost_per_million": 1.875,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/jondurbin/airoboros-l2-70b-2.1": {
    "input_cost_per_token": 0.000013875,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000013875,
    "supports_tool_choice": true,
    "model_id": "openrouter/jondurbin/airoboros-l2-70b-2.1",
    "model_name": "Airoboros L2 70b 2.1",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 13.875,
    "output_cost_per_million": 13.875,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/mancer/weaver": {
    "input_cost_per_token": 0.000005625,
    "max_tokens": 8000,
    "output_cost_per_token": 0.000005625,
    "supports_tool_choice": true,
    "model_id": "openrouter/mancer/weaver",
    "model_name": "Weaver",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 5.625,
    "output_cost_per_million": 5.625,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/meta-llama/codellama-34b-instruct": {
    "input_cost_per_token": 5e-7,
    "max_tokens": 8192,
    "output_cost_per_token": 5e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/meta-llama/codellama-34b-instruct",
    "model_name": "Codellama 34b Instruct",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/meta-llama/llama-2-13b-chat": {
    "input_cost_per_token": 2e-7,
    "max_tokens": 4096,
    "output_cost_per_token": 2e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/meta-llama/llama-2-13b-chat",
    "model_name": "Llama 2 13b Chat",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/meta-llama/llama-2-70b-chat": {
    "input_cost_per_token": 0.0000015,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0000015,
    "supports_tool_choice": true,
    "model_id": "openrouter/meta-llama/llama-2-70b-chat",
    "model_name": "LLaMA 2 70b Chat",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/meta-llama/llama-3-70b-instruct": {
    "input_cost_per_token": 5.9e-7,
    "max_tokens": 8192,
    "output_cost_per_token": 7.9e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/meta-llama/llama-3-70b-instruct",
    "model_name": "Llama 3 70b Instruct",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.59,
    "output_cost_per_million": 0.7899999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/meta-llama/llama-3-70b-instruct:nitro": {
    "input_cost_per_token": 9e-7,
    "max_tokens": 8192,
    "output_cost_per_token": 9e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/meta-llama/llama-3-70b-instruct:nitro",
    "model_name": "Llama 3 70b Instruct:nitro",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/meta-llama/llama-3-8b-instruct:extended": {
    "input_cost_per_token": 2.25e-7,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00000225,
    "supports_tool_choice": true,
    "model_id": "openrouter/meta-llama/llama-3-8b-instruct:extended",
    "model_name": "Llama 3 8b Instruct:extended",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.22499999999999998,
    "output_cost_per_million": 2.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/meta-llama/llama-3-8b-instruct:free": {
    "input_cost_per_token": 0,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "supports_tool_choice": true,
    "model_id": "openrouter/meta-llama/llama-3-8b-instruct:free",
    "model_name": "Llama 3 8b Instruct:free",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/microsoft/wizardlm-2-8x22b:nitro": {
    "input_cost_per_token": 0.000001,
    "max_tokens": 65536,
    "output_cost_per_token": 0.000001,
    "supports_tool_choice": true,
    "model_id": "openrouter/microsoft/wizardlm-2-8x22b:nitro",
    "model_name": "Wizardlm 2 8x22b:nitro",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 1,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/mistralai/mistral-7b-instruct": {
    "input_cost_per_token": 1.3e-7,
    "max_tokens": 8192,
    "output_cost_per_token": 1.3e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/mistralai/mistral-7b-instruct",
    "model_name": "Mistral 7b Instruct",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.13,
    "output_cost_per_million": 0.13,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/mistralai/mistral-7b-instruct:free": {
    "input_cost_per_token": 0,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "supports_tool_choice": true,
    "model_id": "openrouter/mistralai/mistral-7b-instruct:free",
    "model_name": "Mistral 7b Instruct:free",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/mistralai/mistral-large": {
    "input_cost_per_token": 0.000008,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true,
    "model_id": "openrouter/mistralai/mistral-large",
    "model_name": "Mistral Large",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 8,
    "output_cost_per_million": 24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/mistralai/mistral-small-3.1-24b-instruct": {
    "input_cost_per_token": 1e-7,
    "max_tokens": 32000,
    "output_cost_per_token": 3e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/mistralai/mistral-small-3.1-24b-instruct",
    "model_name": "Mistral Small 3.1 24b Instruct",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/mistralai/mistral-small-3.2-24b-instruct": {
    "input_cost_per_token": 1e-7,
    "max_tokens": 32000,
    "output_cost_per_token": 3e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/mistralai/mistral-small-3.2-24b-instruct",
    "model_name": "Mistral Small 3.2 24b Instruct",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/mistralai/mixtral-8x22b-instruct": {
    "input_cost_per_token": 6.5e-7,
    "max_tokens": 65536,
    "output_cost_per_token": 6.5e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/mistralai/mixtral-8x22b-instruct",
    "model_name": "Mixtral 8x22b Instruct",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.65,
    "output_cost_per_million": 0.65,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/nousresearch/nous-hermes-llama2-13b": {
    "input_cost_per_token": 2e-7,
    "max_tokens": 4096,
    "output_cost_per_token": 2e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/nousresearch/nous-hermes-llama2-13b",
    "model_name": "Nous: Hermes 13B",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/openai/gpt-3.5-turbo": {
    "input_cost_per_token": 0.0000015,
    "max_tokens": 4095,
    "output_cost_per_token": 0.000002,
    "supports_tool_choice": true,
    "model_id": "openrouter/openai/gpt-3.5-turbo",
    "model_name": "GPT 3.5T",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/openai/gpt-3.5-turbo-16k": {
    "input_cost_per_token": 0.000003,
    "max_tokens": 16383,
    "output_cost_per_token": 0.000004,
    "supports_tool_choice": true,
    "model_id": "openrouter/openai/gpt-3.5-turbo-16k",
    "model_name": "GPT 3.5T 16k",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 3,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/openai/gpt-4": {
    "input_cost_per_token": 0.00003,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00006,
    "supports_tool_choice": true,
    "model_id": "openrouter/openai/gpt-4",
    "model_name": "GPT 4",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 30,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/openai/gpt-4-vision-preview": {
    "input_cost_per_image": 0.01445,
    "input_cost_per_token": 0.00001,
    "max_tokens": 130000,
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/openai/gpt-4-vision-preview",
    "model_name": "GPT 4 Vision Preview",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/openai/gpt-4.1": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000008,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/openai/gpt-4.1",
    "model_name": "GPT 4.1",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "openrouter/openai/gpt-4.1-2025-04-14": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000008,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/openai/gpt-4.1-2025-04-14",
    "model_name": "GPT 4.1 (Apr 2025)",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "openrouter/openai/gpt-4.1-mini": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.0000016,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/openai/gpt-4.1-mini",
    "model_name": "GPT 4.1 mini",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.5999999999999999,
    "cache_read_cost_per_token": 1e-7,
    "cache_read_cost_per_million": 0.09999999999999999,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "openrouter/openai/gpt-4.1-mini-2025-04-14": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.0000016,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/openai/gpt-4.1-mini-2025-04-14",
    "model_name": "GPT 4.1 Mini 2025 04 14",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.5999999999999999,
    "cache_read_cost_per_token": 1e-7,
    "cache_read_cost_per_million": 0.09999999999999999,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "openrouter/openai/gpt-4.1-nano": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 4e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/openai/gpt-4.1-nano",
    "model_name": "GPT 4.1 nano",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "openrouter/openai/gpt-4.1-nano-2025-04-14": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 4e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/openai/gpt-4.1-nano-2025-04-14",
    "model_name": "GPT 4.1 Nano 2025 04 14",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "openrouter/openai/gpt-4o": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/openai/gpt-4o",
    "model_name": "GPT 4o",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "openrouter/openai/gpt-4o-2024-05-13": {
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/openai/gpt-4o-2024-05-13",
    "model_name": "GPT 4o (May 2024)",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 5,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "openrouter/openai/gpt-5-chat": {
    "input_cost_per_token": 0.00000125,
    "max_input_tokens": 400000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00001,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "openrouter/openai/gpt-5-chat",
    "model_name": "GPT 5 Chat",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 1.25e-7,
    "cache_read_cost_per_million": 0.125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/openai/gpt-5-mini": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 400000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000002,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "openrouter/openai/gpt-5-mini",
    "model_name": "GPT 5 Mini",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/openai/gpt-5-nano": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 400000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 4e-7,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "openrouter/openai/gpt-5-nano",
    "model_name": "GPT 5 Nano",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 5e-9,
    "cache_read_cost_per_million": 0.005,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/openai/gpt-oss-120b": {
    "input_cost_per_token": 1.8e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 8e-7,
    "source": "https://openrouter.ai/openai/gpt-oss-120b",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "openrouter/openai/gpt-oss-120b",
    "model_name": "GPT Oss 120b",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.18,
    "output_cost_per_million": 0.7999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "openrouter/openai/gpt-oss-20b": {
    "input_cost_per_token": 1.8e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 8e-7,
    "source": "https://openrouter.ai/openai/gpt-oss-20b",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "openrouter/openai/gpt-oss-20b",
    "model_name": "GPT Oss 20b",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.18,
    "output_cost_per_million": 0.7999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "openrouter/openai/o1": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "openrouter/openai/o1",
    "model_name": "O1",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 15,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": 0.0000075,
    "cache_read_cost_per_million": 7.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "openrouter/openai/o1-mini": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0.000012,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "openrouter/openai/o1-mini",
    "model_name": "O1 mini",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 3,
    "output_cost_per_million": 12,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "openrouter/openai/o1-mini-2024-09-12": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0.000012,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "openrouter/openai/o1-mini-2024-09-12",
    "model_name": "O1 Mini 2024 09 12",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 3,
    "output_cost_per_million": 12,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "openrouter/openai/o1-preview": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "openrouter/openai/o1-preview",
    "model_name": "O1 Preview",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 15,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "openrouter/openai/o1-preview-2024-09-12": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "openrouter/openai/o1-preview-2024-09-12",
    "model_name": "O1 Preview 2024 09 12",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 15,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "openrouter/openai/o3-mini": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "openrouter/openai/o3-mini",
    "model_name": "O3 mini",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "openrouter/openai/o3-mini-high": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "openrouter/openai/o3-mini-high",
    "model_name": "O3 Mini High",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "openrouter/pygmalionai/mythalion-13b": {
    "input_cost_per_token": 0.000001875,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000001875,
    "supports_tool_choice": true,
    "model_id": "openrouter/pygmalionai/mythalion-13b",
    "model_name": "Mythalion 13b",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 1.875,
    "output_cost_per_million": 1.875,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/qwen/qwen-2.5-coder-32b-instruct": {
    "input_cost_per_token": 1.8e-7,
    "max_input_tokens": 33792,
    "max_output_tokens": 33792,
    "max_tokens": 33792,
    "output_cost_per_token": 1.8e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/qwen/qwen-2.5-coder-32b-instruct",
    "model_name": "Qwen 2.5 Coder 32B Instruct",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.18,
    "output_cost_per_million": 0.18,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/qwen/qwen-vl-plus": {
    "input_cost_per_token": 2.1e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 2048,
    "max_tokens": 8192,
    "output_cost_per_token": 6.3e-7,
    "supports_tool_choice": true,
    "model_id": "openrouter/qwen/qwen-vl-plus",
    "model_name": "Qwen Vl Plus",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.21,
    "output_cost_per_million": 0.63,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/qwen/qwen3-coder": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "max_tokens": 1000000,
    "output_cost_per_token": 0.000005,
    "source": "https://openrouter.ai/qwen/qwen3-coder",
    "supports_tool_choice": true,
    "model_id": "openrouter/qwen/qwen3-coder",
    "model_name": "Qwen3 Coder",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 1,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/switchpoint/router": {
    "input_cost_per_token": 8.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.0000034,
    "source": "https://openrouter.ai/switchpoint/router",
    "supports_tool_choice": true,
    "model_id": "openrouter/switchpoint/router",
    "model_name": "Router",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 0.85,
    "output_cost_per_million": 3.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/undi95/remm-slerp-l2-13b": {
    "input_cost_per_token": 0.000001875,
    "max_tokens": 6144,
    "output_cost_per_token": 0.000001875,
    "supports_tool_choice": true,
    "model_id": "openrouter/undi95/remm-slerp-l2-13b",
    "model_name": "Remm Slerp L2 13b",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 1.875,
    "output_cost_per_million": 1.875,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openrouter/x-ai/grok-4": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.000015,
    "source": "https://openrouter.ai/x-ai/grok-4",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "openrouter/x-ai/grok-4",
    "model_name": "Grok 4",
    "provider_id": "openrouter",
    "provider_name": "OpenRouter",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ovhcloud/DeepSeek-R1-Distill-Llama-70B": {
    "input_cost_per_token": 6.7e-7,
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "output_cost_per_token": 6.7e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/deepseek-r1-distill-llama-70b",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "ovhcloud/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek R1 Distill Llama 70B",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.67,
    "output_cost_per_million": 0.67,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "ovhcloud/gpt-oss-120b": {
    "input_cost_per_token": 8e-8,
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "output_cost_per_token": 4e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/gpt-oss-120b",
    "supports_function_calling": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "ovhcloud/gpt-oss-120b",
    "model_name": "GPT Oss 120b",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.08,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "ovhcloud/gpt-oss-20b": {
    "input_cost_per_token": 4e-8,
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "output_cost_per_token": 1.5e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/gpt-oss-20b",
    "supports_function_calling": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "ovhcloud/gpt-oss-20b",
    "model_name": "GPT Oss 20b",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.04,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "ovhcloud/Llama-3.1-8B-Instruct": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "output_cost_per_token": 1e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/llama-3-1-8b-instruct",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "ovhcloud/Llama-3.1-8B-Instruct",
    "model_name": "Llama 3.1 8B Instruct",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "ovhcloud/llava-v1.6-mistral-7b-hf": {
    "input_cost_per_token": 2.9e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 2.9e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/llava-next-mistral-7b",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "supports_vision": true,
    "model_id": "ovhcloud/llava-v1.6-mistral-7b-hf",
    "model_name": "Llava V1.6 Mistral 7b Hf",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.29,
    "output_cost_per_million": 0.29,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "ovhcloud/mamba-codestral-7B-v0.1": {
    "input_cost_per_token": 1.9e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 1.9e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/mamba-codestral-7b-v0-1",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "ovhcloud/mamba-codestral-7B-v0.1",
    "model_name": "Mamba Codestral 7B V0.1",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.19,
    "output_cost_per_million": 0.19,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "ovhcloud/Meta-Llama-3_1-70B-Instruct": {
    "input_cost_per_token": 6.7e-7,
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "output_cost_per_token": 6.7e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/meta-llama-3-1-70b-instruct",
    "supports_function_calling": false,
    "supports_response_schema": false,
    "supports_tool_choice": false,
    "model_id": "ovhcloud/Meta-Llama-3_1-70B-Instruct",
    "model_name": "Meta Llama 3_1 70B Instruct",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.67,
    "output_cost_per_million": 0.67,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "ovhcloud/Meta-Llama-3_3-70B-Instruct": {
    "input_cost_per_token": 6.7e-7,
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "output_cost_per_token": 6.7e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/meta-llama-3-3-70b-instruct",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "ovhcloud/Meta-Llama-3_3-70B-Instruct",
    "model_name": "Meta Llama 3_3 70B Instruct",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.67,
    "output_cost_per_million": 0.67,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "ovhcloud/Mistral-7B-Instruct-v0.3": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 127000,
    "max_output_tokens": 127000,
    "max_tokens": 127000,
    "output_cost_per_token": 1e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/mistral-7b-instruct-v0-3",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "ovhcloud/Mistral-7B-Instruct-v0.3",
    "model_name": "Mistral 7B Instruct V0.3",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "ovhcloud/Mistral-Nemo-Instruct-2407": {
    "input_cost_per_token": 1.3e-7,
    "max_input_tokens": 118000,
    "max_output_tokens": 118000,
    "max_tokens": 118000,
    "output_cost_per_token": 1.3e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/mistral-nemo-instruct-2407",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "ovhcloud/Mistral-Nemo-Instruct-2407",
    "model_name": "Mistral Nemo Instruct 2407",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.13,
    "output_cost_per_million": 0.13,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "ovhcloud/Mistral-Small-3.2-24B-Instruct-2506": {
    "input_cost_per_token": 9e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 2.8e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/mistral-small-3-2-24b-instruct-2506",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "ovhcloud/Mistral-Small-3.2-24B-Instruct-2506",
    "model_name": "Mistral Small 3.2 24B Instruct 2506",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.09,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "ovhcloud/Mixtral-8x7B-Instruct-v0.1": {
    "input_cost_per_token": 6.3e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 6.3e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/mixtral-8x7b-instruct-v0-1",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "ovhcloud/Mixtral-8x7B-Instruct-v0.1",
    "model_name": "Mixtral 8x7B Instruct V0.1",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.63,
    "output_cost_per_million": 0.63,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "ovhcloud/Qwen2.5-Coder-32B-Instruct": {
    "input_cost_per_token": 8.7e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 8.7e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/qwen2-5-coder-32b-instruct",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "model_id": "ovhcloud/Qwen2.5-Coder-32B-Instruct",
    "model_name": "Qwen2.5 Coder 32B Instruct",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.87,
    "output_cost_per_million": 0.87,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "ovhcloud/Qwen2.5-VL-72B-Instruct": {
    "input_cost_per_token": 9.1e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 9.1e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/qwen2-5-vl-72b-instruct",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false,
    "supports_vision": true,
    "model_id": "ovhcloud/Qwen2.5-VL-72B-Instruct",
    "model_name": "Qwen2.5 VL 72B Instruct",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.9099999999999999,
    "output_cost_per_million": 0.9099999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "ovhcloud/Qwen3-32B": {
    "input_cost_per_token": 8e-8,
    "max_input_tokens": 32000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 2.3e-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/qwen3-32b",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "ovhcloud/Qwen3-32B",
    "model_name": "Qwen3 32B",
    "provider_id": "ovhcloud",
    "provider_name": "Ovhcloud",
    "input_cost_per_million": 0.08,
    "output_cost_per_million": 0.22999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "palm/chat-bison": {
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "palm/chat-bison",
    "model_name": "Chat Bison",
    "provider_id": "palm",
    "provider_name": "Palm AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "palm/chat-bison-001": {
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "palm/chat-bison-001",
    "model_name": "Chat Bison 001",
    "provider_id": "palm",
    "provider_name": "Palm AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "palm/text-bison": {
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "palm/text-bison",
    "model_name": "Text Bison",
    "provider_id": "palm",
    "provider_name": "Palm AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "palm/text-bison-001": {
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "palm/text-bison-001",
    "model_name": "Text Bison 001",
    "provider_id": "palm",
    "provider_name": "Palm AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "palm/text-bison-safety-off": {
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "palm/text-bison-safety-off",
    "model_name": "Text Bison Safety Off",
    "provider_id": "palm",
    "provider_name": "Palm AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "palm/text-bison-safety-recitation-off": {
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "palm/text-bison-safety-recitation-off",
    "model_name": "Text Bison Safety Recitation Off",
    "provider_id": "palm",
    "provider_name": "Palm AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codellama-34b-instruct": {
    "input_cost_per_token": 3.5e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.0000014,
    "model_id": "codellama-34b-instruct",
    "model_name": "Codellama 34b Instruct",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0.35,
    "output_cost_per_million": 1.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codellama-70b-instruct": {
    "input_cost_per_token": 7e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.0000028,
    "model_id": "codellama-70b-instruct",
    "model_name": "Codellama 70b Instruct",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0.7,
    "output_cost_per_million": 2.8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "llama-2-70b-chat": {
    "input_cost_per_token": 7e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0000028,
    "model_id": "llama-2-70b-chat",
    "model_name": "LLaMA 2 70b Chat",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0.7,
    "output_cost_per_million": 2.8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "llama-3.1-70b-instruct": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000001,
    "model_id": "llama-3.1-70b-instruct",
    "model_name": "Llama 3.1 70b Instruct",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "llama-3.1-8b-instruct": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 2e-7,
    "model_id": "llama-3.1-8b-instruct",
    "model_name": "Llama 3.1 8b Instruct",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "llama-3.1-sonar-huge-128k-online": {
    "deprecation_date": "2025-02-22",
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 127072,
    "max_output_tokens": 127072,
    "max_tokens": 127072,
    "output_cost_per_token": 0.000005,
    "model_id": "llama-3.1-sonar-huge-128k-online",
    "model_name": "Llama 3.1 Sonar Huge 128k Online",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 5,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "llama-3.1-sonar-large-128k-chat": {
    "deprecation_date": "2025-02-22",
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000001,
    "model_id": "llama-3.1-sonar-large-128k-chat",
    "model_name": "Llama 3.1 Sonar Large 128k Chat",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "llama-3.1-sonar-large-128k-online": {
    "deprecation_date": "2025-02-22",
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 127072,
    "max_output_tokens": 127072,
    "max_tokens": 127072,
    "output_cost_per_token": 0.000001,
    "model_id": "llama-3.1-sonar-large-128k-online",
    "model_name": "Llama 3.1 Sonar Large 128k Online",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "llama-3.1-sonar-small-128k-chat": {
    "deprecation_date": "2025-02-22",
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 2e-7,
    "model_id": "llama-3.1-sonar-small-128k-chat",
    "model_name": "Llama 3.1 Sonar Small 128k Chat",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "llama-3.1-sonar-small-128k-online": {
    "deprecation_date": "2025-02-22",
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 127072,
    "max_output_tokens": 127072,
    "max_tokens": 127072,
    "output_cost_per_token": 2e-7,
    "model_id": "llama-3.1-sonar-small-128k-online",
    "model_name": "Llama 3.1 Sonar Small 128k Online",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral-7b-instruct": {
    "input_cost_per_token": 7e-8,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 2.8e-7,
    "model_id": "mistral-7b-instruct",
    "model_name": "Mistral 7b Instruct",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0.07,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mixtral-8x7b-instruct": {
    "input_cost_per_token": 7e-8,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 2.8e-7,
    "model_id": "mixtral-8x7b-instruct",
    "model_name": "Mixtral 8x7b Instruct",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0.07,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "pplx-70b-chat": {
    "input_cost_per_token": 7e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0000028,
    "model_id": "pplx-70b-chat",
    "model_name": "Pplx 70b Chat",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0.7,
    "output_cost_per_million": 2.8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "pplx-70b-online": {
    "input_cost_per_request": 0.005,
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0000028,
    "model_id": "pplx-70b-online",
    "model_name": "Pplx 70b Online",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 2.8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "pplx-7b-chat": {
    "input_cost_per_token": 7e-8,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 2.8e-7,
    "model_id": "pplx-7b-chat",
    "model_name": "Pplx 7b Chat",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0.07,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "pplx-7b-online": {
    "input_cost_per_request": 0.005,
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 2.8e-7,
    "model_id": "pplx-7b-online",
    "model_name": "Pplx 7b Online",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sonar": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000001,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.012,
      "search_context_size_low": 0.005,
      "search_context_size_medium": 0.008
    },
    "supports_web_search": true,
    "model_id": "sonar",
    "model_name": "Sonar",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "max_output_tokens": null,
    "input_cost_per_million": 1,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sonar-deep-research": {
    "citation_cost_per_token": 0.000002,
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_reasoning_token": 0.000003,
    "output_cost_per_token": 0.000008,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.005,
      "search_context_size_low": 0.005,
      "search_context_size_medium": 0.005
    },
    "supports_reasoning": true,
    "supports_web_search": true,
    "model_id": "sonar-deep-research",
    "model_name": "Sonar Deep Research",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "max_output_tokens": null,
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sonar-medium-chat": {
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.0000018,
    "model_id": "sonar-medium-chat",
    "model_name": "Sonar Medium Chat",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 1.7999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sonar-medium-online": {
    "input_cost_per_request": 0.005,
    "input_cost_per_token": 0,
    "max_input_tokens": 12000,
    "max_output_tokens": 12000,
    "max_tokens": 12000,
    "output_cost_per_token": 0.0000018,
    "model_id": "sonar-medium-online",
    "model_name": "Sonar Medium Online",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 1.7999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sonar-pro": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.014,
      "search_context_size_low": 0.006,
      "search_context_size_medium": 0.01
    },
    "supports_web_search": true,
    "model_id": "sonar-pro",
    "model_name": "Sonar Pro",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sonar-reasoning": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000005,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.014,
      "search_context_size_low": 0.005,
      "search_context_size_medium": 0.008
    },
    "supports_reasoning": true,
    "supports_web_search": true,
    "model_id": "sonar-reasoning",
    "model_name": "Sonar Reasoning",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "max_output_tokens": null,
    "input_cost_per_million": 1,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sonar-reasoning-pro": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000008,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.014,
      "search_context_size_low": 0.006,
      "search_context_size_medium": 0.01
    },
    "supports_reasoning": true,
    "supports_web_search": true,
    "model_id": "sonar-reasoning-pro",
    "model_name": "Sonar Reasoning Pro",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "max_output_tokens": null,
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sonar-small-chat": {
    "input_cost_per_token": 7e-8,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 2.8e-7,
    "model_id": "sonar-small-chat",
    "model_name": "Sonar Small Chat",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0.07,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sonar-small-online": {
    "input_cost_per_request": 0.005,
    "input_cost_per_token": 0,
    "max_input_tokens": 12000,
    "max_output_tokens": 12000,
    "max_tokens": 12000,
    "output_cost_per_token": 2.8e-7,
    "model_id": "sonar-small-online",
    "model_name": "Sonar Small Online",
    "provider_id": "perplexity",
    "provider_name": "Perplexity AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "recraft/recraftv2": {
    "output_cost_per_image": 0.022,
    "source": "https://www.recraft.ai/docs#pricing",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "recraft/recraftv2",
    "model_name": "Recraftv2",
    "provider_id": "recraft",
    "provider_name": "Recraft",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "recraft/recraftv3": {
    "output_cost_per_image": 0.04,
    "source": "https://www.recraft.ai/docs#pricing",
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "model_id": "recraft/recraftv3",
    "model_name": "Recraftv3",
    "provider_id": "recraft",
    "provider_name": "Recraft",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-2-13b": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 5e-7,
    "supports_tool_choice": true,
    "model_id": "meta/llama-2-13b",
    "model_name": "Llama 2 13b",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-2-13b-chat": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 5e-7,
    "supports_tool_choice": true,
    "model_id": "meta/llama-2-13b-chat",
    "model_name": "Llama 2 13b Chat",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-2-70b": {
    "input_cost_per_token": 6.5e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00000275,
    "supports_tool_choice": true,
    "model_id": "meta/llama-2-70b",
    "model_name": "Llama 2 70b",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.65,
    "output_cost_per_million": 2.75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-2-70b-chat": {
    "input_cost_per_token": 6.5e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00000275,
    "supports_tool_choice": true,
    "model_id": "meta/llama-2-70b-chat",
    "model_name": "LLaMA 2 70b Chat",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.65,
    "output_cost_per_million": 2.75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-2-7b": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 2.5e-7,
    "supports_tool_choice": true,
    "model_id": "meta/llama-2-7b",
    "model_name": "Llama 2 7b",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-2-7b-chat": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 2.5e-7,
    "supports_tool_choice": true,
    "model_id": "meta/llama-2-7b-chat",
    "model_name": "Llama 2 7b Chat",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-3-70b": {
    "input_cost_per_token": 6.5e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000275,
    "supports_tool_choice": true,
    "model_id": "meta/llama-3-70b",
    "model_name": "Llama 3 70b",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.65,
    "output_cost_per_million": 2.75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-3-70b-instruct": {
    "input_cost_per_token": 6.5e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000275,
    "supports_tool_choice": true,
    "model_id": "meta/llama-3-70b-instruct",
    "model_name": "Llama 3 70b Instruct",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.65,
    "output_cost_per_million": 2.75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-3-8b": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 8086,
    "max_output_tokens": 8086,
    "max_tokens": 8086,
    "output_cost_per_token": 2.5e-7,
    "supports_tool_choice": true,
    "model_id": "meta/llama-3-8b",
    "model_name": "Llama 3 8b",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-3-8b-instruct": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 8086,
    "max_output_tokens": 8086,
    "max_tokens": 8086,
    "output_cost_per_token": 2.5e-7,
    "supports_tool_choice": true,
    "model_id": "meta/llama-3-8b-instruct",
    "model_name": "Llama 3 8b Instruct",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistralai/mistral-7b-instruct-v0.2": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 2.5e-7,
    "supports_tool_choice": true,
    "model_id": "mistralai/mistral-7b-instruct-v0.2",
    "model_name": "Mistral (7B) Instruct v0.2",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistralai/mistral-7b-v0.1": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 2.5e-7,
    "supports_tool_choice": true,
    "model_id": "mistralai/mistral-7b-v0.1",
    "model_name": "Mistral 7b V0.1",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistralai/mixtral-8x7b-instruct-v0.1": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000001,
    "supports_tool_choice": true,
    "model_id": "mistralai/mixtral-8x7b-instruct-v0.1",
    "model_name": "Mixtral 8x7B Instruct v0.1",
    "provider_id": "replicate",
    "provider_name": "Replicate",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sagemaker/meta-textgeneration-llama-2-13b": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "sagemaker/meta-textgeneration-llama-2-13b",
    "model_name": "Meta Textgeneration Llama 2 13b",
    "provider_id": "sagemaker",
    "provider_name": "AWS Sage Maker",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sagemaker/meta-textgeneration-llama-2-13b-f": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "sagemaker/meta-textgeneration-llama-2-13b-f",
    "model_name": "Meta Textgeneration Llama 2 13b F",
    "provider_id": "sagemaker",
    "provider_name": "AWS Sage Maker",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sagemaker/meta-textgeneration-llama-2-70b": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "sagemaker/meta-textgeneration-llama-2-70b",
    "model_name": "Meta Textgeneration Llama 2 70b",
    "provider_id": "sagemaker",
    "provider_name": "AWS Sage Maker",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sagemaker/meta-textgeneration-llama-2-70b-b-f": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "sagemaker/meta-textgeneration-llama-2-70b-b-f",
    "model_name": "Meta Textgeneration Llama 2 70b B F",
    "provider_id": "sagemaker",
    "provider_name": "AWS Sage Maker",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sagemaker/meta-textgeneration-llama-2-7b": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "sagemaker/meta-textgeneration-llama-2-7b",
    "model_name": "Meta Textgeneration Llama 2 7b",
    "provider_id": "sagemaker",
    "provider_name": "AWS Sage Maker",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sagemaker/meta-textgeneration-llama-2-7b-f": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "sagemaker/meta-textgeneration-llama-2-7b-f",
    "model_name": "Meta Textgeneration Llama 2 7b F",
    "provider_id": "sagemaker",
    "provider_name": "AWS Sage Maker",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sambanova/DeepSeek-R1": {
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000007,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "model_id": "sambanova/DeepSeek-R1",
    "model_name": "DeepSeek R1",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 5,
    "output_cost_per_million": 7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sambanova/DeepSeek-R1-Distill-Llama-70B": {
    "input_cost_per_token": 7e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.0000014,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "model_id": "sambanova/DeepSeek-R1-Distill-Llama-70B",
    "model_name": "DeepSeek R1 Distill Llama 70B",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 0.7,
    "output_cost_per_million": 1.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sambanova/DeepSeek-V3-0324": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.0000045,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "sambanova/DeepSeek-V3-0324",
    "model_name": "DeepSeek V3 0324",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 3,
    "output_cost_per_million": 4.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sambanova/Llama-4-Maverick-17B-128E-Instruct": {
    "input_cost_per_token": 6.3e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "metadata": {
      "notes": "For vision models, images are converted to 6432 input tokens and are billed at that amount"
    },
    "output_cost_per_token": 0.0000018,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "sambanova/Llama-4-Maverick-17B-128E-Instruct",
    "model_name": "Llama 4 Maverick 17B 128E Instruct",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 0.63,
    "output_cost_per_million": 1.7999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "sambanova/Llama-4-Scout-17B-16E-Instruct": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "metadata": {
      "notes": "For vision models, images are converted to 6432 input tokens and are billed at that amount"
    },
    "output_cost_per_token": 7e-7,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "sambanova/Llama-4-Scout-17B-16E-Instruct",
    "model_name": "Llama 4 Scout 17B 16E Instruct",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 0.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "sambanova/Meta-Llama-3.1-405B-Instruct": {
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.00001,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "sambanova/Meta-Llama-3.1-405B-Instruct",
    "model_name": "Meta Llama 3.1 405B Instruct",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "sambanova/Meta-Llama-3.1-8B-Instruct": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 2e-7,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "sambanova/Meta-Llama-3.1-8B-Instruct",
    "model_name": "Meta Llama 3.1 8B Instruct",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "sambanova/Meta-Llama-3.2-1B-Instruct": {
    "input_cost_per_token": 4e-8,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 8e-8,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "model_id": "sambanova/Meta-Llama-3.2-1B-Instruct",
    "model_name": "Meta Llama 3.2 1B Instruct",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 0.04,
    "output_cost_per_million": 0.08,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sambanova/Meta-Llama-3.2-3B-Instruct": {
    "input_cost_per_token": 8e-8,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 1.6e-7,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "model_id": "sambanova/Meta-Llama-3.2-3B-Instruct",
    "model_name": "Meta Llama 3.2 3B Instruct",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 0.08,
    "output_cost_per_million": 0.16,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sambanova/Meta-Llama-3.3-70B-Instruct": {
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.0000012,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "sambanova/Meta-Llama-3.3-70B-Instruct",
    "model_name": "Meta Llama 3.3 70B Instruct",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "sambanova/Meta-Llama-Guard-3-8B": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 3e-7,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "model_id": "sambanova/Meta-Llama-Guard-3-8B",
    "model_name": "Meta Llama Guard 3 8B",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sambanova/Qwen2-Audio-7B-Instruct": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.0001,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "supports_audio_input": true,
    "model_id": "sambanova/Qwen2-Audio-7B-Instruct",
    "model_name": "Qwen2 Audio 7B Instruct",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 100,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sambanova/Qwen3-32B": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 8e-7,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "sambanova/Qwen3-32B",
    "model_name": "Qwen3 32B",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 0.7999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "sambanova/QwQ-32B": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.000001,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "model_id": "sambanova/QwQ-32B",
    "model_name": "QwQ 32B",
    "provider_id": "sambanova",
    "provider_name": "Sambanova",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/claude-3-5-sonnet": {
    "max_input_tokens": 18000,
    "max_output_tokens": 8192,
    "max_tokens": 18000,
    "supports_computer_use": true,
    "model_id": "snowflake/claude-3-5-sonnet",
    "model_name": "Claude 3 5 Sonnet",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/deepseek-r1": {
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "max_tokens": 32768,
    "supports_reasoning": true,
    "model_id": "snowflake/deepseek-r1",
    "model_name": "DeepSeek R1",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/gemma-7b": {
    "max_input_tokens": 8000,
    "max_output_tokens": 8192,
    "max_tokens": 8000,
    "model_id": "snowflake/gemma-7b",
    "model_name": "Gemma 7b",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/jamba-1.5-large": {
    "max_input_tokens": 256000,
    "max_output_tokens": 8192,
    "max_tokens": 256000,
    "model_id": "snowflake/jamba-1.5-large",
    "model_name": "Jamba 1.5 Large",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/jamba-1.5-mini": {
    "max_input_tokens": 256000,
    "max_output_tokens": 8192,
    "max_tokens": 256000,
    "model_id": "snowflake/jamba-1.5-mini",
    "model_name": "Jamba 1.5 Mini",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/jamba-instruct": {
    "max_input_tokens": 256000,
    "max_output_tokens": 8192,
    "max_tokens": 256000,
    "model_id": "snowflake/jamba-instruct",
    "model_name": "Jamba Instruct",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/llama2-70b-chat": {
    "max_input_tokens": 4096,
    "max_output_tokens": 8192,
    "max_tokens": 4096,
    "model_id": "snowflake/llama2-70b-chat",
    "model_name": "Llama2 70b Chat",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/llama3-70b": {
    "max_input_tokens": 8000,
    "max_output_tokens": 8192,
    "max_tokens": 8000,
    "model_id": "snowflake/llama3-70b",
    "model_name": "Llama 3 70B",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/llama3-8b": {
    "max_input_tokens": 8000,
    "max_output_tokens": 8192,
    "max_tokens": 8000,
    "model_id": "snowflake/llama3-8b",
    "model_name": "Llama 3 8B",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/llama3.1-405b": {
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "model_id": "snowflake/llama3.1-405b",
    "model_name": "Llama3.1 405b",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/llama3.1-70b": {
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "model_id": "snowflake/llama3.1-70b",
    "model_name": "Llama 3.1 70B",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/llama3.1-8b": {
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "model_id": "snowflake/llama3.1-8b",
    "model_name": "Llama 3.1 8B",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/llama3.2-1b": {
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "model_id": "snowflake/llama3.2-1b",
    "model_name": "Llama 3.2 1B",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/llama3.2-3b": {
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "model_id": "snowflake/llama3.2-3b",
    "model_name": "Llama 3.2 3B",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/llama3.3-70b": {
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "model_id": "snowflake/llama3.3-70b",
    "model_name": "Llama 3.3 70B",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/mistral-7b": {
    "max_input_tokens": 32000,
    "max_output_tokens": 8192,
    "max_tokens": 32000,
    "model_id": "snowflake/mistral-7b",
    "model_name": "Mistral 7B",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/mistral-large": {
    "max_input_tokens": 32000,
    "max_output_tokens": 8192,
    "max_tokens": 32000,
    "model_id": "snowflake/mistral-large",
    "model_name": "Mistral Large",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/mistral-large2": {
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "model_id": "snowflake/mistral-large2",
    "model_name": "Mistral Large2",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/mixtral-8x7b": {
    "max_input_tokens": 32000,
    "max_output_tokens": 8192,
    "max_tokens": 32000,
    "model_id": "snowflake/mixtral-8x7b",
    "model_name": "Mixtral 8x7b",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/reka-core": {
    "max_input_tokens": 32000,
    "max_output_tokens": 8192,
    "max_tokens": 32000,
    "model_id": "snowflake/reka-core",
    "model_name": "Reka Core",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/reka-flash": {
    "max_input_tokens": 100000,
    "max_output_tokens": 8192,
    "max_tokens": 100000,
    "model_id": "snowflake/reka-flash",
    "model_name": "Reka Flash",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/snowflake-arctic": {
    "max_input_tokens": 4096,
    "max_output_tokens": 8192,
    "max_tokens": 4096,
    "model_id": "snowflake/snowflake-arctic",
    "model_name": "Snowflake Arctic",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/snowflake-llama-3.1-405b": {
    "max_input_tokens": 8000,
    "max_output_tokens": 8192,
    "max_tokens": 8000,
    "model_id": "snowflake/snowflake-llama-3.1-405b",
    "model_name": "Snowflake Llama 3.1 405b",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "snowflake/snowflake-llama-3.3-70b": {
    "max_input_tokens": 8000,
    "max_output_tokens": 8192,
    "max_tokens": 8000,
    "model_id": "snowflake/snowflake-llama-3.3-70b",
    "model_name": "Snowflake Llama 3.3 70b",
    "provider_id": "snowflake",
    "provider_name": "Snowflake",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "babbage-002": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 4096,
    "max_tokens": 16384,
    "output_cost_per_token": 4e-7,
    "model_id": "babbage-002",
    "model_name": "Babbage 002",
    "provider_id": "text-completion-openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "davinci-002": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 16384,
    "max_output_tokens": 4096,
    "max_tokens": 16384,
    "output_cost_per_token": 0.000002,
    "model_id": "davinci-002",
    "model_name": "Davinci 002",
    "provider_id": "text-completion-openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ft:babbage-002": {
    "input_cost_per_token": 4e-7,
    "input_cost_per_token_batches": 2e-7,
    "max_input_tokens": 16384,
    "max_output_tokens": 4096,
    "max_tokens": 16384,
    "output_cost_per_token": 4e-7,
    "output_cost_per_token_batches": 2e-7,
    "model_id": "ft:babbage-002",
    "model_name": "Ft:babbage 002",
    "provider_id": "text-completion-openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "ft:davinci-002": {
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "max_input_tokens": 16384,
    "max_output_tokens": 4096,
    "max_tokens": 16384,
    "output_cost_per_token": 0.000002,
    "output_cost_per_token_batches": 0.000001,
    "model_id": "ft:davinci-002",
    "model_name": "Ft:davinci 002",
    "provider_id": "text-completion-openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-3.5-turbo-instruct": {
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000002,
    "model_id": "gpt-3.5-turbo-instruct",
    "model_name": "GPT 3.5T Instruct",
    "provider_id": "text-completion-openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gpt-3.5-turbo-instruct-0914": {
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 8192,
    "max_output_tokens": 4097,
    "max_tokens": 4097,
    "output_cost_per_token": 0.000002,
    "model_id": "gpt-3.5-turbo-instruct-0914",
    "model_name": "GPT 3.5 Turbo Instruct 0914",
    "provider_id": "text-completion-openai",
    "provider_name": "OpenAI",
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek-ai/DeepSeek-R1": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 20480,
    "max_tokens": 20480,
    "output_cost_per_token": 0.000007,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "deepseek-ai/DeepSeek-R1",
    "model_name": "DeepSeek R1",
    "provider_id": "together",
    "provider_name": "Together AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "deepseek-ai/DeepSeek-R1-0528-tput": {
    "input_cost_per_token": 5.5e-7,
    "max_input_tokens": 128000,
    "output_cost_per_token": 0.00000219,
    "source": "https://www.together.ai/models/deepseek-r1-0528-throughput",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "deepseek-ai/DeepSeek-R1-0528-tput",
    "model_name": "DeepSeek R1 0528 Tput",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.55,
    "output_cost_per_million": 2.1900000000000004,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "deepseek-ai/DeepSeek-V3": {
    "input_cost_per_token": 0.00000125,
    "max_input_tokens": 65536,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.00000125,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "deepseek-ai/DeepSeek-V3",
    "model_name": "DeepSeek V3",
    "provider_id": "together",
    "provider_name": "Together AI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 1.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "deepseek-ai/DeepSeek-V3.1": {
    "input_cost_per_token": 6e-7,
    "max_tokens": 128000,
    "output_cost_per_token": 0.0000017,
    "source": "https://www.together.ai/models/deepseek-v3-1",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "deepseek-ai/DeepSeek-V3.1",
    "model_name": "DeepSeek V3.1",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 1.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Llama-3.2-3B-Instruct-Turbo",
    "model_name": "Llama 3.2 3B Instruct Turbo",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "meta-llama/Llama-3.3-70B-Instruct-Turbo": {
    "input_cost_per_token": 8.8e-7,
    "output_cost_per_token": 8.8e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
    "model_name": "Llama 3.3 70B Instruct Turbo",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.88,
    "output_cost_per_million": 0.88,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free": {
    "input_cost_per_token": 0,
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
    "model_name": "Llama 3.3 70B Instruct Turbo Free",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
    "input_cost_per_token": 2.7e-7,
    "output_cost_per_token": 8.5e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
    "model_name": "Llama 4 Maverick 17B 128E Instruct FP8",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.27,
    "output_cost_per_million": 0.85,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "meta-llama/Llama-4-Scout-17B-16E-Instruct": {
    "input_cost_per_token": 1.8e-7,
    "output_cost_per_token": 5.9e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
    "model_name": "Llama 4 Scout 17B 16E Instruct",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.18,
    "output_cost_per_million": 0.59,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
    "input_cost_per_token": 0.0000035,
    "output_cost_per_token": 0.0000035,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    "model_name": "Meta Llama 3.1 405B Instruct Turbo",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 3.5,
    "output_cost_per_million": 3.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
    "input_cost_per_token": 8.8e-7,
    "output_cost_per_token": 8.8e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
    "model_name": "Meta Llama 3.1 70B Instruct Turbo",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.88,
    "output_cost_per_million": 0.88,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
    "input_cost_per_token": 1.8e-7,
    "output_cost_per_token": 1.8e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
    "model_name": "Meta Llama 3.1 8B Instruct Turbo",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.18,
    "output_cost_per_million": 0.18,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "mistralai/Mistral-7B-Instruct-v0.1": {
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mistralai/Mistral-7B-Instruct-v0.1",
    "model_name": "Mistral 7B Instruct V0.1",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "mistralai/Mistral-Small-24B-Instruct-2501": {
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "mistralai/Mistral-Small-24B-Instruct-2501",
    "model_name": "Mistral Small 24B Instruct 2501",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "mistralai/Mixtral-8x7B-Instruct-v0.1": {
    "input_cost_per_token": 6e-7,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "model_name": "Mixtral 8x7B Instruct V0.1",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "moonshotai/Kimi-K2-Instruct": {
    "input_cost_per_token": 0.000001,
    "output_cost_per_token": 0.000003,
    "source": "https://www.together.ai/models/kimi-k2-instruct",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "moonshotai/Kimi-K2-Instruct",
    "model_name": "Kimi K2 Instruct",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "openai/gpt-oss-120b": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "output_cost_per_token": 6e-7,
    "source": "https://www.together.ai/models/gpt-oss-120b",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "openai/gpt-oss-120b",
    "model_name": "GPT Oss 120b",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "openai/gpt-oss-20b": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 128000,
    "output_cost_per_token": 2e-7,
    "source": "https://www.together.ai/models/gpt-oss-20b",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "openai/gpt-oss-20b",
    "model_name": "GPT Oss 20b",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "Qwen/Qwen2.5-72B-Instruct-Turbo": {
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen2.5-72B-Instruct-Turbo",
    "model_name": "Qwen2.5 72B Instruct Turbo",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "Qwen/Qwen2.5-7B-Instruct-Turbo": {
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen2.5-7B-Instruct-Turbo",
    "model_name": "Qwen2.5 7B Instruct Turbo",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "Qwen/Qwen3-235B-A22B-fp8-tput": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 40000,
    "output_cost_per_token": 6e-7,
    "source": "https://www.together.ai/models/qwen3-235b-a22b-fp8-tput",
    "supports_function_calling": false,
    "supports_parallel_function_calling": false,
    "supports_tool_choice": false,
    "model_id": "Qwen/Qwen3-235B-A22B-fp8-tput",
    "model_name": "Qwen3 235B A22B Fp8 Tput",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": false,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "Qwen/Qwen3-235B-A22B-Instruct-2507-tput": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 262000,
    "output_cost_per_token": 0.000006,
    "source": "https://www.together.ai/models/qwen3-235b-a22b-instruct-2507-fp8",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507-tput",
    "model_name": "Qwen3 235B A22B Instruct 2507 Tput",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "Qwen/Qwen3-235B-A22B-Thinking-2507": {
    "input_cost_per_token": 6.5e-7,
    "max_input_tokens": 256000,
    "output_cost_per_token": 0.000003,
    "source": "https://www.together.ai/models/qwen3-235b-a22b-thinking-2507",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
    "model_name": "Qwen3 235B A22B Thinking 2507",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.65,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 256000,
    "output_cost_per_token": 0.000002,
    "source": "https://www.together.ai/models/qwen3-coder-480b-a35b-instruct",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "model_name": "Qwen3 Coder 480B A35B Instruct FP8",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_output_tokens": null,
    "input_cost_per_million": 2,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "together-ai-21.1b-41b": {
    "input_cost_per_token": 8e-7,
    "output_cost_per_token": 8e-7,
    "model_id": "together-ai-21.1b-41b",
    "model_name": "Together Ai 21.1b 41b",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 0.7999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "together-ai-4.1b-8b": {
    "input_cost_per_token": 2e-7,
    "output_cost_per_token": 2e-7,
    "model_id": "together-ai-4.1b-8b",
    "model_name": "Together Ai 4.1b 8b",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "together-ai-41.1b-80b": {
    "input_cost_per_token": 9e-7,
    "output_cost_per_token": 9e-7,
    "model_id": "together-ai-41.1b-80b",
    "model_name": "Together Ai 41.1b 80b",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "together-ai-8.1b-21b": {
    "input_cost_per_token": 3e-7,
    "max_tokens": 1000,
    "output_cost_per_token": 3e-7,
    "model_id": "together-ai-8.1b-21b",
    "model_name": "Together Ai 8.1b 21b",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "together-ai-81.1b-110b": {
    "input_cost_per_token": 0.0000018,
    "output_cost_per_token": 0.0000018,
    "model_id": "together-ai-81.1b-110b",
    "model_name": "Together Ai 81.1b 110b",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 1.7999999999999998,
    "output_cost_per_million": 1.7999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "together-ai-embedding-151m-to-350m": {
    "input_cost_per_token": 1.6e-8,
    "output_cost_per_token": 0,
    "model_id": "together-ai-embedding-151m-to-350m",
    "model_name": "Together Ai Embedding 151m To 350m",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.016,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "together-ai-embedding-up-to-150m": {
    "input_cost_per_token": 8e-9,
    "output_cost_per_token": 0,
    "model_id": "together-ai-embedding-up-to-150m",
    "model_name": "Together Ai Embedding Up To 150m",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.008,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "together-ai-up-to-4b": {
    "input_cost_per_token": 1e-7,
    "output_cost_per_token": 1e-7,
    "model_id": "together-ai-up-to-4b",
    "model_name": "Together Ai Up To 4b",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "togethercomputer/CodeLlama-34b-Instruct": {
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "togethercomputer/CodeLlama-34b-Instruct",
    "model_name": "CodeLlama 34b Instruct",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "zai-org/GLM-4.5-Air-FP8": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 128000,
    "output_cost_per_token": 0.0000011,
    "source": "https://www.together.ai/models/glm-4-5-air",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "zai-org/GLM-4.5-Air-FP8",
    "model_name": "GLM 4.5 Air FP8",
    "provider_id": "together",
    "provider_name": "Together AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 1.1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "v0/v0-1.0-md": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "v0/v0-1.0-md",
    "model_name": "V0 1.0 Md",
    "provider_id": "v0",
    "provider_name": "V0",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "v0/v0-1.5-lg": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 512000,
    "max_output_tokens": 512000,
    "max_tokens": 512000,
    "output_cost_per_token": 0.000075,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "v0/v0-1.5-lg",
    "model_name": "V0 1.5 Lg",
    "provider_id": "v0",
    "provider_name": "V0",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "v0/v0-1.5-md": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "v0/v0-1.5-md",
    "model_name": "V0 1.5 Md",
    "provider_id": "v0",
    "provider_name": "V0",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "vercel_ai_gateway/alibaba/qwen-3-14b": {
    "input_cost_per_token": 8e-8,
    "max_input_tokens": 40960,
    "max_output_tokens": 16384,
    "max_tokens": 40960,
    "output_cost_per_token": 2.4e-7,
    "model_id": "vercel_ai_gateway/alibaba/qwen-3-14b",
    "model_name": "Qwen 3 14b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.08,
    "output_cost_per_million": 0.24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/alibaba/qwen-3-235b": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 40960,
    "max_output_tokens": 16384,
    "max_tokens": 40960,
    "output_cost_per_token": 6e-7,
    "model_id": "vercel_ai_gateway/alibaba/qwen-3-235b",
    "model_name": "Qwen 3 235b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/alibaba/qwen-3-30b": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 40960,
    "max_output_tokens": 16384,
    "max_tokens": 40960,
    "output_cost_per_token": 3e-7,
    "model_id": "vercel_ai_gateway/alibaba/qwen-3-30b",
    "model_name": "Qwen 3 30b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/alibaba/qwen-3-32b": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 40960,
    "max_output_tokens": 16384,
    "max_tokens": 40960,
    "output_cost_per_token": 3e-7,
    "model_id": "vercel_ai_gateway/alibaba/qwen-3-32b",
    "model_name": "Qwen 3 32b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/alibaba/qwen3-coder": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 262144,
    "max_output_tokens": 66536,
    "max_tokens": 262144,
    "output_cost_per_token": 0.0000016,
    "model_id": "vercel_ai_gateway/alibaba/qwen3-coder",
    "model_name": "Qwen3 Coder",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.5999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/amazon/nova-lite": {
    "input_cost_per_token": 6e-8,
    "max_input_tokens": 300000,
    "max_output_tokens": 8192,
    "max_tokens": 300000,
    "output_cost_per_token": 2.4e-7,
    "model_id": "vercel_ai_gateway/amazon/nova-lite",
    "model_name": "Nova Lite",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.06,
    "output_cost_per_million": 0.24,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/amazon/nova-micro": {
    "input_cost_per_token": 3.5e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "output_cost_per_token": 1.4e-7,
    "model_id": "vercel_ai_gateway/amazon/nova-micro",
    "model_name": "Nova Micro",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.035,
    "output_cost_per_million": 0.14,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/amazon/nova-pro": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 300000,
    "max_output_tokens": 8192,
    "max_tokens": 300000,
    "output_cost_per_token": 0.0000032,
    "model_id": "vercel_ai_gateway/amazon/nova-pro",
    "model_name": "Nova Pro",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 3.1999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/amazon/titan-embed-text-v2": {
    "input_cost_per_token": 2e-8,
    "max_input_tokens": null,
    "max_output_tokens": null,
    "max_tokens": 0,
    "output_cost_per_token": 0,
    "model_id": "vercel_ai_gateway/amazon/titan-embed-text-v2",
    "model_name": "Titan Embed Text V2",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.02,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/anthropic/claude-3-haiku": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 200000,
    "output_cost_per_token": 0.00000125,
    "model_id": "vercel_ai_gateway/anthropic/claude-3-haiku",
    "model_name": "Claude 3 Haiku",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1.25,
    "cache_read_cost_per_token": 3e-8,
    "cache_read_cost_per_million": 0.03,
    "cache_write_cost_per_token": 3e-7,
    "cache_write_cost_per_million": 0.3,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/anthropic/claude-3-opus": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 200000,
    "output_cost_per_token": 0.000075,
    "model_id": "vercel_ai_gateway/anthropic/claude-3-opus",
    "model_name": "Claude 3 Opus",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/anthropic/claude-3.5-haiku": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 200000,
    "output_cost_per_token": 0.000004,
    "model_id": "vercel_ai_gateway/anthropic/claude-3.5-haiku",
    "model_name": "Claude 3.5 Haiku",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": 8e-8,
    "cache_read_cost_per_million": 0.08,
    "cache_write_cost_per_token": 0.000001,
    "cache_write_cost_per_million": 1,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/anthropic/claude-3.5-sonnet": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 200000,
    "output_cost_per_token": 0.000015,
    "model_id": "vercel_ai_gateway/anthropic/claude-3.5-sonnet",
    "model_name": "Claude 3.5 Sonnet",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/anthropic/claude-3.7-sonnet": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 200000,
    "output_cost_per_token": 0.000015,
    "model_id": "vercel_ai_gateway/anthropic/claude-3.7-sonnet",
    "model_name": "Claude 3.7 Sonnet",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/anthropic/claude-4-opus": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 200000,
    "output_cost_per_token": 0.000075,
    "model_id": "vercel_ai_gateway/anthropic/claude-4-opus",
    "model_name": "Claude 4 Opus",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/anthropic/claude-4-sonnet": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 200000,
    "output_cost_per_token": 0.000015,
    "model_id": "vercel_ai_gateway/anthropic/claude-4-sonnet",
    "model_name": "Claude 4 Sonnet",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/cohere/command-a": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 256000,
    "max_output_tokens": 8000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.00001,
    "model_id": "vercel_ai_gateway/cohere/command-a",
    "model_name": "Command A",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/cohere/command-r": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 6e-7,
    "model_id": "vercel_ai_gateway/cohere/command-r",
    "model_name": "Command R",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/cohere/command-r-plus": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00001,
    "model_id": "vercel_ai_gateway/cohere/command-r-plus",
    "model_name": "Command R Plus",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/cohere/embed-v4.0": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": null,
    "max_output_tokens": null,
    "max_tokens": 0,
    "output_cost_per_token": 0,
    "model_id": "vercel_ai_gateway/cohere/embed-v4.0",
    "model_name": "Embed V4.0",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/deepseek/deepseek-r1": {
    "input_cost_per_token": 5.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00000219,
    "model_id": "vercel_ai_gateway/deepseek/deepseek-r1",
    "model_name": "DeepSeek R1",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.55,
    "output_cost_per_million": 2.1900000000000004,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/deepseek/deepseek-r1-distill-llama-70b": {
    "input_cost_per_token": 7.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 9.9e-7,
    "model_id": "vercel_ai_gateway/deepseek/deepseek-r1-distill-llama-70b",
    "model_name": "DeepSeek R1 Distill Llama 70B",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.75,
    "output_cost_per_million": 0.9900000000000001,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/deepseek/deepseek-v3": {
    "input_cost_per_token": 9e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "output_cost_per_token": 9e-7,
    "model_id": "vercel_ai_gateway/deepseek/deepseek-v3",
    "model_name": "DeepSeek V3",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/google/gemini-2.0-flash": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 1048576,
    "output_cost_per_token": 6e-7,
    "model_id": "vercel_ai_gateway/google/gemini-2.0-flash",
    "model_name": "Gemini 2.0 Flash Latest",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/google/gemini-2.0-flash-lite": {
    "input_cost_per_token": 7.5e-8,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 1048576,
    "output_cost_per_token": 3e-7,
    "model_id": "vercel_ai_gateway/google/gemini-2.0-flash-lite",
    "model_name": "Gemini 2.0 Flash Lite",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/google/gemini-2.5-flash": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 1000000,
    "max_output_tokens": 65536,
    "max_tokens": 1000000,
    "output_cost_per_token": 0.0000025,
    "model_id": "vercel_ai_gateway/google/gemini-2.5-flash",
    "model_name": "Gemini 2.5 Flash",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 2.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/google/gemini-2.5-pro": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_tokens": 1048576,
    "output_cost_per_token": 0.00001,
    "model_id": "vercel_ai_gateway/google/gemini-2.5-pro",
    "model_name": "Gemini 2.5 Pro",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/google/gemini-embedding-001": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": null,
    "max_output_tokens": null,
    "max_tokens": 0,
    "output_cost_per_token": 0,
    "model_id": "vercel_ai_gateway/google/gemini-embedding-001",
    "model_name": "Gemini Embedding 001",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/google/gemma-2-9b": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 2e-7,
    "model_id": "vercel_ai_gateway/google/gemma-2-9b",
    "model_name": "Gemma 2 9b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.19999999999999998,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/google/text-embedding-005": {
    "input_cost_per_token": 2.5e-8,
    "max_input_tokens": null,
    "max_output_tokens": null,
    "max_tokens": 0,
    "output_cost_per_token": 0,
    "model_id": "vercel_ai_gateway/google/text-embedding-005",
    "model_name": "Text Embedding 005",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.024999999999999998,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/google/text-multilingual-embedding-002": {
    "input_cost_per_token": 2.5e-8,
    "max_input_tokens": null,
    "max_output_tokens": null,
    "max_tokens": 0,
    "output_cost_per_token": 0,
    "model_id": "vercel_ai_gateway/google/text-multilingual-embedding-002",
    "model_name": "Text Multilingual Embedding 002",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.024999999999999998,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/inception/mercury-coder-small": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 16384,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000001,
    "model_id": "vercel_ai_gateway/inception/mercury-coder-small",
    "model_name": "Mercury Coder Small",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/meta/llama-3-70b": {
    "input_cost_per_token": 5.9e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 7.9e-7,
    "model_id": "vercel_ai_gateway/meta/llama-3-70b",
    "model_name": "Llama 3 70b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.59,
    "output_cost_per_million": 0.7899999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/meta/llama-3-8b": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 8e-8,
    "model_id": "vercel_ai_gateway/meta/llama-3-8b",
    "model_name": "Llama 3 8b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.08,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/meta/llama-3.1-70b": {
    "input_cost_per_token": 7.2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "output_cost_per_token": 7.2e-7,
    "model_id": "vercel_ai_gateway/meta/llama-3.1-70b",
    "model_name": "Llama 3.1 70b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.72,
    "output_cost_per_million": 0.72,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/meta/llama-3.1-8b": {
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 131000,
    "max_output_tokens": 131072,
    "max_tokens": 131000,
    "output_cost_per_token": 8e-8,
    "model_id": "vercel_ai_gateway/meta/llama-3.1-8b",
    "model_name": "Llama 3.1 8b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0.08,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/meta/llama-3.2-11b": {
    "input_cost_per_token": 1.6e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "output_cost_per_token": 1.6e-7,
    "model_id": "vercel_ai_gateway/meta/llama-3.2-11b",
    "model_name": "Llama 3.2 11b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.16,
    "output_cost_per_million": 0.16,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/meta/llama-3.2-1b": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "output_cost_per_token": 1e-7,
    "model_id": "vercel_ai_gateway/meta/llama-3.2-1b",
    "model_name": "Llama 3.2 1b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/meta/llama-3.2-3b": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "output_cost_per_token": 1.5e-7,
    "model_id": "vercel_ai_gateway/meta/llama-3.2-3b",
    "model_name": "Llama 3.2 3b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/meta/llama-3.2-90b": {
    "input_cost_per_token": 7.2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "output_cost_per_token": 7.2e-7,
    "model_id": "vercel_ai_gateway/meta/llama-3.2-90b",
    "model_name": "Llama 3.2 90b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.72,
    "output_cost_per_million": 0.72,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/meta/llama-3.3-70b": {
    "input_cost_per_token": 7.2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 128000,
    "output_cost_per_token": 7.2e-7,
    "model_id": "vercel_ai_gateway/meta/llama-3.3-70b",
    "model_name": "Llama 3.3 70b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.72,
    "output_cost_per_million": 0.72,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/meta/llama-4-maverick": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 131072,
    "output_cost_per_token": 6e-7,
    "model_id": "vercel_ai_gateway/meta/llama-4-maverick",
    "model_name": "Llama 4 Maverick",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/meta/llama-4-scout": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 131072,
    "output_cost_per_token": 3e-7,
    "model_id": "vercel_ai_gateway/meta/llama-4-scout",
    "model_name": "Llama 4 Scout",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/codestral": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 4000,
    "max_tokens": 256000,
    "output_cost_per_token": 9e-7,
    "model_id": "vercel_ai_gateway/mistral/codestral",
    "model_name": "Codestral",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.8999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/codestral-embed": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": null,
    "max_output_tokens": null,
    "max_tokens": 0,
    "output_cost_per_token": 0,
    "model_id": "vercel_ai_gateway/mistral/codestral-embed",
    "model_name": "Codestral Embed",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/devstral-small": {
    "input_cost_per_token": 7e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 2.8e-7,
    "model_id": "vercel_ai_gateway/mistral/devstral-small",
    "model_name": "Devstral Small",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.07,
    "output_cost_per_million": 0.28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/magistral-medium": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000005,
    "model_id": "vercel_ai_gateway/mistral/magistral-medium",
    "model_name": "Magistral Medium",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 2,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/magistral-small": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.0000015,
    "model_id": "vercel_ai_gateway/mistral/magistral-small",
    "model_name": "Magistral Small",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/ministral-3b": {
    "input_cost_per_token": 4e-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 128000,
    "output_cost_per_token": 4e-8,
    "model_id": "vercel_ai_gateway/mistral/ministral-3b",
    "model_name": "Ministral 3b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.04,
    "output_cost_per_million": 0.04,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/ministral-8b": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 128000,
    "output_cost_per_token": 1e-7,
    "model_id": "vercel_ai_gateway/mistral/ministral-8b",
    "model_name": "Ministral 8b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.09999999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/mistral-embed": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": null,
    "max_output_tokens": null,
    "max_tokens": 0,
    "output_cost_per_token": 0,
    "model_id": "vercel_ai_gateway/mistral/mistral-embed",
    "model_name": "Mistral Embed",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/mistral-large": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 32000,
    "max_output_tokens": 4000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000006,
    "model_id": "vercel_ai_gateway/mistral/mistral-large",
    "model_name": "Mistral Large",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/mistral-saba-24b": {
    "input_cost_per_token": 7.9e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 7.9e-7,
    "model_id": "vercel_ai_gateway/mistral/mistral-saba-24b",
    "model_name": "Mistral Saba 24b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.7899999999999999,
    "output_cost_per_million": 0.7899999999999999,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/mistral-small": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 4000,
    "max_tokens": 32000,
    "output_cost_per_token": 3e-7,
    "model_id": "vercel_ai_gateway/mistral/mistral-small",
    "model_name": "Mistral Small",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/mixtral-8x22b-instruct": {
    "input_cost_per_token": 0.0000012,
    "max_input_tokens": 65536,
    "max_output_tokens": 2048,
    "max_tokens": 65536,
    "output_cost_per_token": 0.0000012,
    "model_id": "vercel_ai_gateway/mistral/mixtral-8x22b-instruct",
    "model_name": "Mixtral 8x22b Instruct",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 1.2,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/pixtral-12b": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 128000,
    "output_cost_per_token": 1.5e-7,
    "model_id": "vercel_ai_gateway/mistral/pixtral-12b",
    "model_name": "Pixtral 12b",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/mistral/pixtral-large": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000006,
    "model_id": "vercel_ai_gateway/mistral/pixtral-large",
    "model_name": "Pixtral Large",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/moonshotai/kimi-k2": {
    "input_cost_per_token": 5.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 16384,
    "max_tokens": 131072,
    "output_cost_per_token": 0.0000022,
    "model_id": "vercel_ai_gateway/moonshotai/kimi-k2",
    "model_name": "Kimi K2",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.55,
    "output_cost_per_million": 2.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/morph/morph-v3-fast": {
    "input_cost_per_token": 8e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 16384,
    "max_tokens": 32768,
    "output_cost_per_token": 0.0000012,
    "model_id": "vercel_ai_gateway/morph/morph-v3-fast",
    "model_name": "Morph V3 Fast",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 1.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/morph/morph-v3-large": {
    "input_cost_per_token": 9e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 16384,
    "max_tokens": 32768,
    "output_cost_per_token": 0.0000019,
    "model_id": "vercel_ai_gateway/morph/morph-v3-large",
    "model_name": "Morph V3 Large",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.8999999999999999,
    "output_cost_per_million": 1.9,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/gpt-3.5-turbo": {
    "input_cost_per_token": 5e-7,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 16385,
    "output_cost_per_token": 0.0000015,
    "model_id": "vercel_ai_gateway/openai/gpt-3.5-turbo",
    "model_name": "GPT 3.5T",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/gpt-3.5-turbo-instruct": {
    "input_cost_per_token": 0.0000015,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000002,
    "model_id": "vercel_ai_gateway/openai/gpt-3.5-turbo-instruct",
    "model_name": "GPT 3.5T Instruct",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 1.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/gpt-4-turbo": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00003,
    "model_id": "vercel_ai_gateway/openai/gpt-4-turbo",
    "model_name": "GPT 4 Turbo",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 10,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/gpt-4.1": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 1047576,
    "output_cost_per_token": 0.000008,
    "model_id": "vercel_ai_gateway/openai/gpt-4.1",
    "model_name": "GPT 4.1",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/gpt-4.1-mini": {
    "input_cost_per_token": 4e-7,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 1047576,
    "output_cost_per_token": 0.0000016,
    "model_id": "vercel_ai_gateway/openai/gpt-4.1-mini",
    "model_name": "GPT 4.1 mini",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.39999999999999997,
    "output_cost_per_million": 1.5999999999999999,
    "cache_read_cost_per_token": 1e-7,
    "cache_read_cost_per_million": 0.09999999999999999,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/gpt-4.1-nano": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 1047576,
    "output_cost_per_token": 4e-7,
    "model_id": "vercel_ai_gateway/openai/gpt-4.1-nano",
    "model_name": "GPT 4.1 nano",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/gpt-4o": {
    "input_cost_per_token": 0.0000025,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 128000,
    "output_cost_per_token": 0.00001,
    "model_id": "vercel_ai_gateway/openai/gpt-4o",
    "model_name": "GPT 4o",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 2.5,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 0.00000125,
    "cache_read_cost_per_million": 1.25,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/gpt-4o-mini": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 128000,
    "output_cost_per_token": 6e-7,
    "model_id": "vercel_ai_gateway/openai/gpt-4o-mini",
    "model_name": "GPT 4o mini",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/o1": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 200000,
    "output_cost_per_token": 0.00006,
    "model_id": "vercel_ai_gateway/openai/o1",
    "model_name": "O1",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 15,
    "output_cost_per_million": 60,
    "cache_read_cost_per_token": 0.0000075,
    "cache_read_cost_per_million": 7.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/o3": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 200000,
    "output_cost_per_token": 0.000008,
    "model_id": "vercel_ai_gateway/openai/o3",
    "model_name": "O3",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": 5e-7,
    "cache_read_cost_per_million": 0.5,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/o3-mini": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 200000,
    "output_cost_per_token": 0.0000044,
    "model_id": "vercel_ai_gateway/openai/o3-mini",
    "model_name": "O3 mini",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": 5.5e-7,
    "cache_read_cost_per_million": 0.55,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/o4-mini": {
    "input_cost_per_token": 0.0000011,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 200000,
    "output_cost_per_token": 0.0000044,
    "model_id": "vercel_ai_gateway/openai/o4-mini",
    "model_name": "O4 mini",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 1.1,
    "output_cost_per_million": 4.4,
    "cache_read_cost_per_token": 2.75e-7,
    "cache_read_cost_per_million": 0.275,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/text-embedding-3-large": {
    "input_cost_per_token": 1.3e-7,
    "max_input_tokens": null,
    "max_output_tokens": null,
    "max_tokens": 0,
    "output_cost_per_token": 0,
    "model_id": "vercel_ai_gateway/openai/text-embedding-3-large",
    "model_name": "Text Embedding 3 Large",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.13,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/text-embedding-3-small": {
    "input_cost_per_token": 2e-8,
    "max_input_tokens": null,
    "max_output_tokens": null,
    "max_tokens": 0,
    "output_cost_per_token": 0,
    "model_id": "vercel_ai_gateway/openai/text-embedding-3-small",
    "model_name": "Text Embedding 3 Small",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.02,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/openai/text-embedding-ada-002": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": null,
    "max_output_tokens": null,
    "max_tokens": 0,
    "output_cost_per_token": 0,
    "model_id": "vercel_ai_gateway/openai/text-embedding-ada-002",
    "model_name": "Text Embedding Ada 002",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/perplexity/sonar": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 127000,
    "max_output_tokens": 8000,
    "max_tokens": 127000,
    "output_cost_per_token": 0.000001,
    "model_id": "vercel_ai_gateway/perplexity/sonar",
    "model_name": "Sonar",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 1,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/perplexity/sonar-pro": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8000,
    "max_tokens": 200000,
    "output_cost_per_token": 0.000015,
    "model_id": "vercel_ai_gateway/perplexity/sonar-pro",
    "model_name": "Sonar Pro",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/perplexity/sonar-reasoning": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 127000,
    "max_output_tokens": 8000,
    "max_tokens": 127000,
    "output_cost_per_token": 0.000005,
    "model_id": "vercel_ai_gateway/perplexity/sonar-reasoning",
    "model_name": "Sonar Reasoning",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 1,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/perplexity/sonar-reasoning-pro": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 127000,
    "max_output_tokens": 8000,
    "max_tokens": 127000,
    "output_cost_per_token": 0.000008,
    "model_id": "vercel_ai_gateway/perplexity/sonar-reasoning-pro",
    "model_name": "Sonar Reasoning Pro",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/vercel/v0-1.0-md": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 32000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000015,
    "model_id": "vercel_ai_gateway/vercel/v0-1.0-md",
    "model_name": "V0 1.0 Md",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/vercel/v0-1.5-md": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000015,
    "model_id": "vercel_ai_gateway/vercel/v0-1.5-md",
    "model_name": "V0 1.5 Md",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/xai/grok-2": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 131072,
    "max_output_tokens": 4000,
    "max_tokens": 131072,
    "output_cost_per_token": 0.00001,
    "model_id": "vercel_ai_gateway/xai/grok-2",
    "model_name": "Grok 2",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 2,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/xai/grok-2-vision": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.00001,
    "model_id": "vercel_ai_gateway/xai/grok-2-vision",
    "model_name": "Grok 2 Vision",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 2,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/xai/grok-3": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000015,
    "model_id": "vercel_ai_gateway/xai/grok-3",
    "model_name": "Grok 3",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/xai/grok-3-fast": {
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000025,
    "model_id": "vercel_ai_gateway/xai/grok-3-fast",
    "model_name": "Grok 3 Fast",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 5,
    "output_cost_per_million": 25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/xai/grok-3-mini": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 5e-7,
    "model_id": "vercel_ai_gateway/xai/grok-3-mini",
    "model_name": "Grok 3 Mini",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/xai/grok-3-mini-fast": {
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000004,
    "model_id": "vercel_ai_gateway/xai/grok-3-mini-fast",
    "model_name": "Grok 3 Mini Fast",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/xai/grok-4": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.000015,
    "model_id": "vercel_ai_gateway/xai/grok-4",
    "model_name": "Grok 4",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/zai/glm-4.5": {
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.0000022,
    "model_id": "vercel_ai_gateway/zai/glm-4.5",
    "model_name": "Glm 4.5",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 2.2,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "vercel_ai_gateway/zai/glm-4.5-air": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 96000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.0000011,
    "model_id": "vercel_ai_gateway/zai/glm-4.5-air",
    "model_name": "Glm 4.5 Air",
    "provider_id": "vercel",
    "provider_name": "Vercel",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 1.1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "chat-bison": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "chat-bison",
    "model_name": "Chat Bison",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "chat-bison-32k": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "chat-bison-32k",
    "model_name": "Chat Bison 32k",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "chat-bison-32k@002": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "chat-bison-32k@002",
    "model_name": "Chat Bison 32k@002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "chat-bison@001": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "chat-bison@001",
    "model_name": "Chat Bison@001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "chat-bison@002": {
    "deprecation_date": "2025-04-09",
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "chat-bison@002",
    "model_name": "Chat Bison@002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-5-haiku": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000005,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_tool_choice": true,
    "model_id": "claude-3-5-haiku",
    "model_name": "Claude 3 5 Haiku",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-5-haiku@20241022": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000005,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_tool_choice": true,
    "model_id": "claude-3-5-haiku@20241022",
    "model_name": "Claude 3 5 Haiku@20241022",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-5-sonnet": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "claude-3-5-sonnet",
    "model_name": "Claude 3 5 Sonnet",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-5-sonnet-v2": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "claude-3-5-sonnet-v2",
    "model_name": "Claude 3 5 Sonnet V2",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-5-sonnet-v2@20241022": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "claude-3-5-sonnet-v2@20241022",
    "model_name": "Claude 3 5 Sonnet V2@20241022",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-5-sonnet@20240620": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "claude-3-5-sonnet@20240620",
    "model_name": "Claude 3 5 Sonnet@20240620",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-7-sonnet@20250219": {
    "deprecation_date": "2025-06-01",
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-3-7-sonnet@20250219",
    "model_name": "Claude 3 7 Sonnet@20250219",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-3-haiku": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00000125,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "claude-3-haiku",
    "model_name": "Claude 3 Haiku",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-haiku@20240307": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.00000125,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "claude-3-haiku@20240307",
    "model_name": "Claude 3 Haiku@20240307",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1.25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-opus": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "claude-3-opus",
    "model_name": "Claude 3 Opus",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-opus@20240229": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "claude-3-opus@20240229",
    "model_name": "Claude 3 Opus@20240229",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-sonnet": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "claude-3-sonnet",
    "model_name": "Claude 3 Sonnet",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-3-sonnet@20240229": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "claude-3-sonnet@20240229",
    "model_name": "Claude 3 Sonnet@20240229",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-opus-4": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-opus-4",
    "model_name": "Claude Opus 4",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-opus-4-1": {
    "input_cost_per_token": 0.000015,
    "input_cost_per_token_batches": 0.0000075,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000075,
    "output_cost_per_token_batches": 0.0000375,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "claude-opus-4-1",
    "model_name": "Claude Opus 4 1",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-opus-4-1@20250805": {
    "input_cost_per_token": 0.000015,
    "input_cost_per_token_batches": 0.0000075,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0.000075,
    "output_cost_per_token_batches": 0.0000375,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "claude-opus-4-1@20250805",
    "model_name": "Claude Opus 4 1@20250805",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "claude-opus-4@20250514": {
    "input_cost_per_token": 0.000015,
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-opus-4@20250514",
    "model_name": "Claude Opus 4@20250514",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 15,
    "output_cost_per_million": 75,
    "cache_read_cost_per_token": 0.0000015,
    "cache_read_cost_per_million": 1.5,
    "cache_write_cost_per_token": 0.00001875,
    "cache_write_cost_per_million": 18.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-sonnet-4": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-sonnet-4",
    "model_name": "Claude Sonnet 4",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "claude-sonnet-4@20250514": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "model_id": "claude-sonnet-4@20250514",
    "model_name": "Claude Sonnet 4@20250514",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": 3e-7,
    "cache_read_cost_per_million": 0.3,
    "cache_write_cost_per_token": 0.00000375,
    "cache_write_cost_per_million": 3.75,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "code-bison": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 6144,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "code-bison",
    "model_name": "Code Bison",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "code-bison-32k@002": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 6144,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "code-bison-32k@002",
    "model_name": "Code Bison 32k@002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "code-bison@001": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 6144,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "code-bison@001",
    "model_name": "Code Bison@001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "code-bison@002": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 6144,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "code-bison@002",
    "model_name": "Code Bison@002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "code-bison32k": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 6144,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "code-bison32k",
    "model_name": "Code Bison32k",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "code-gecko": {
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 2048,
    "max_output_tokens": 64,
    "max_tokens": 64,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "code-gecko",
    "model_name": "Code Gecko",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "code-gecko-latest": {
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 2048,
    "max_output_tokens": 64,
    "max_tokens": 64,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "code-gecko-latest",
    "model_name": "Code Gecko Latest",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "code-gecko@001": {
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 2048,
    "max_output_tokens": 64,
    "max_tokens": 64,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "code-gecko@001",
    "model_name": "Code Gecko@001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "code-gecko@002": {
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 2048,
    "max_output_tokens": 64,
    "max_tokens": 64,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "code-gecko@002",
    "model_name": "Code Gecko@002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codechat-bison": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 6144,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "codechat-bison",
    "model_name": "Codechat Bison",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codechat-bison-32k": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "codechat-bison-32k",
    "model_name": "Codechat Bison 32k",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codechat-bison-32k@002": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 32000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "codechat-bison-32k@002",
    "model_name": "Codechat Bison 32k@002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codechat-bison@001": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 6144,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "codechat-bison@001",
    "model_name": "Codechat Bison@001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codechat-bison@002": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 6144,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "codechat-bison@002",
    "model_name": "Codechat Bison@002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codechat-bison@latest": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 6144,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "codechat-bison@latest",
    "model_name": "Codechat Bison@latest",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codestral-2501": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "codestral-2501",
    "model_name": "Codestral 2501",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codestral@2405": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "codestral@2405",
    "model_name": "Codestral@2405",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "codestral@latest": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 6e-7,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "codestral@latest",
    "model_name": "Codestral@latest",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "deepseek-ai/deepseek-r1-0528-maas": {
    "input_cost_per_token": 0.00000135,
    "max_input_tokens": 65336,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0000054,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "deepseek-ai/deepseek-r1-0528-maas",
    "model_name": "Deepseek R1 0528 Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1.35,
    "output_cost_per_million": 5.4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gemini-1.0-pro": {
    "input_cost_per_character": 1.25e-7,
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-7,
    "input_cost_per_video_per_second": 0.002,
    "max_input_tokens": 32760,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 3.75e-7,
    "output_cost_per_token": 0.0000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "gemini-1.0-pro",
    "model_name": "Gemini 1.0 Pro",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gemini-1.0-pro-001": {
    "deprecation_date": "2025-04-09",
    "input_cost_per_character": 1.25e-7,
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-7,
    "input_cost_per_video_per_second": 0.002,
    "max_input_tokens": 32760,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 3.75e-7,
    "output_cost_per_token": 0.0000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "gemini-1.0-pro-001",
    "model_name": "Gemini 1.0 Pro 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gemini-1.0-pro-002": {
    "deprecation_date": "2025-04-09",
    "input_cost_per_character": 1.25e-7,
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-7,
    "input_cost_per_video_per_second": 0.002,
    "max_input_tokens": 32760,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 3.75e-7,
    "output_cost_per_token": 0.0000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "gemini-1.0-pro-002",
    "model_name": "Gemini 1.0 Pro 002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gemini-1.0-pro-vision": {
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-7,
    "max_images_per_prompt": 16,
    "max_input_tokens": 16384,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "max_video_length": 2,
    "max_videos_per_prompt": 1,
    "output_cost_per_token": 0.0000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemini-1.0-pro-vision",
    "model_name": "Gemini 1.0 Pro Vision",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "gemini-1.0-pro-vision-001": {
    "deprecation_date": "2025-04-09",
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-7,
    "max_images_per_prompt": 16,
    "max_input_tokens": 16384,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "max_video_length": 2,
    "max_videos_per_prompt": 1,
    "output_cost_per_token": 0.0000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemini-1.0-pro-vision-001",
    "model_name": "Gemini 1.0 Pro Vision 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "gemini-1.0-ultra": {
    "input_cost_per_character": 1.25e-7,
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-7,
    "input_cost_per_video_per_second": 0.002,
    "max_input_tokens": 8192,
    "max_output_tokens": 2048,
    "max_tokens": 8192,
    "output_cost_per_character": 3.75e-7,
    "output_cost_per_token": 0.0000015,
    "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "gemini-1.0-ultra",
    "model_name": "Gemini 1.0 Ultra",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gemini-1.0-ultra-001": {
    "input_cost_per_character": 1.25e-7,
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-7,
    "input_cost_per_video_per_second": 0.002,
    "max_input_tokens": 8192,
    "max_output_tokens": 2048,
    "max_tokens": 8192,
    "output_cost_per_character": 3.75e-7,
    "output_cost_per_token": 0.0000015,
    "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "gemini-1.0-ultra-001",
    "model_name": "Gemini 1.0 Ultra 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gemini-1.5-flash": {
    "input_cost_per_audio_per_second": 0.000002,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
    "input_cost_per_character": 1.875e-8,
    "input_cost_per_character_above_128k_tokens": 2.5e-7,
    "input_cost_per_image": 0.00002,
    "input_cost_per_image_above_128k_tokens": 0.00004,
    "input_cost_per_token": 7.5e-8,
    "input_cost_per_token_above_128k_tokens": 0.000001,
    "input_cost_per_video_per_second": 0.00002,
    "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_character": 7.5e-8,
    "output_cost_per_character_above_128k_tokens": 1.5e-7,
    "output_cost_per_token": 3e-7,
    "output_cost_per_token_above_128k_tokens": 6e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemini-1.5-flash",
    "model_name": "Gemini 1.5 Flash",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-1.5-flash-001": {
    "deprecation_date": "2025-05-24",
    "input_cost_per_audio_per_second": 0.000002,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
    "input_cost_per_character": 1.875e-8,
    "input_cost_per_character_above_128k_tokens": 2.5e-7,
    "input_cost_per_image": 0.00002,
    "input_cost_per_image_above_128k_tokens": 0.00004,
    "input_cost_per_token": 7.5e-8,
    "input_cost_per_token_above_128k_tokens": 0.000001,
    "input_cost_per_video_per_second": 0.00002,
    "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_character": 7.5e-8,
    "output_cost_per_character_above_128k_tokens": 1.5e-7,
    "output_cost_per_token": 3e-7,
    "output_cost_per_token_above_128k_tokens": 6e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemini-1.5-flash-001",
    "model_name": "Gemini 1.5 Flash 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-1.5-flash-002": {
    "deprecation_date": "2025-09-24",
    "input_cost_per_audio_per_second": 0.000002,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
    "input_cost_per_character": 1.875e-8,
    "input_cost_per_character_above_128k_tokens": 2.5e-7,
    "input_cost_per_image": 0.00002,
    "input_cost_per_image_above_128k_tokens": 0.00004,
    "input_cost_per_token": 7.5e-8,
    "input_cost_per_token_above_128k_tokens": 0.000001,
    "input_cost_per_video_per_second": 0.00002,
    "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_character": 7.5e-8,
    "output_cost_per_character_above_128k_tokens": 1.5e-7,
    "output_cost_per_token": 3e-7,
    "output_cost_per_token_above_128k_tokens": 6e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemini-1.5-flash-002",
    "model_name": "Gemini 1.5 Flash 002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-1.5-flash-exp-0827": {
    "input_cost_per_audio_per_second": 0.000002,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
    "input_cost_per_character": 1.875e-8,
    "input_cost_per_character_above_128k_tokens": 2.5e-7,
    "input_cost_per_image": 0.00002,
    "input_cost_per_image_above_128k_tokens": 0.00004,
    "input_cost_per_token": 4.688e-9,
    "input_cost_per_token_above_128k_tokens": 0.000001,
    "input_cost_per_video_per_second": 0.00002,
    "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_character": 1.875e-8,
    "output_cost_per_character_above_128k_tokens": 3.75e-8,
    "output_cost_per_token": 4.6875e-9,
    "output_cost_per_token_above_128k_tokens": 9.375e-9,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemini-1.5-flash-exp-0827",
    "model_name": "Gemini 1.5 Flash Exp 0827",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.004688,
    "output_cost_per_million": 0.0046875,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-1.5-flash-preview-0514": {
    "input_cost_per_audio_per_second": 0.000002,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
    "input_cost_per_character": 1.875e-8,
    "input_cost_per_character_above_128k_tokens": 2.5e-7,
    "input_cost_per_image": 0.00002,
    "input_cost_per_image_above_128k_tokens": 0.00004,
    "input_cost_per_token": 7.5e-8,
    "input_cost_per_token_above_128k_tokens": 0.000001,
    "input_cost_per_video_per_second": 0.00002,
    "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_character": 1.875e-8,
    "output_cost_per_character_above_128k_tokens": 3.75e-8,
    "output_cost_per_token": 4.6875e-9,
    "output_cost_per_token_above_128k_tokens": 9.375e-9,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemini-1.5-flash-preview-0514",
    "model_name": "Gemini 1.5 Flash Preview 0514",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.0046875,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "gemini-1.5-pro": {
    "input_cost_per_audio_per_second": 0.00003125,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
    "input_cost_per_character": 3.125e-7,
    "input_cost_per_character_above_128k_tokens": 6.25e-7,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_128k_tokens": 0.0000025,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 0.00000125,
    "output_cost_per_character_above_128k_tokens": 0.0000025,
    "output_cost_per_token": 0.000005,
    "output_cost_per_token_above_128k_tokens": 0.00001,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemini-1.5-pro",
    "model_name": "Gemini 1.5 Pro",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-1.5-pro-001": {
    "deprecation_date": "2025-05-24",
    "input_cost_per_audio_per_second": 0.00003125,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
    "input_cost_per_character": 3.125e-7,
    "input_cost_per_character_above_128k_tokens": 6.25e-7,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_128k_tokens": 0.0000025,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 0.00000125,
    "output_cost_per_character_above_128k_tokens": 0.0000025,
    "output_cost_per_token": 0.000005,
    "output_cost_per_token_above_128k_tokens": 0.00001,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemini-1.5-pro-001",
    "model_name": "Gemini 1.5 Pro 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-1.5-pro-002": {
    "deprecation_date": "2025-09-24",
    "input_cost_per_audio_per_second": 0.00003125,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
    "input_cost_per_character": 3.125e-7,
    "input_cost_per_character_above_128k_tokens": 6.25e-7,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_128k_tokens": 0.0000025,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 0.00000125,
    "output_cost_per_character_above_128k_tokens": 0.0000025,
    "output_cost_per_token": 0.000005,
    "output_cost_per_token_above_128k_tokens": 0.00001,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemini-1.5-pro-002",
    "model_name": "Gemini 1.5 Pro 002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-1.5-pro-preview-0215": {
    "input_cost_per_audio_per_second": 0.00003125,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
    "input_cost_per_character": 3.125e-7,
    "input_cost_per_character_above_128k_tokens": 6.25e-7,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 7.8125e-8,
    "input_cost_per_token_above_128k_tokens": 1.5625e-7,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 0.00000125,
    "output_cost_per_character_above_128k_tokens": 0.0000025,
    "output_cost_per_token": 3.125e-7,
    "output_cost_per_token_above_128k_tokens": 6.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gemini-1.5-pro-preview-0215",
    "model_name": "Gemini 1.5 Pro Preview 0215",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.078125,
    "output_cost_per_million": 0.3125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "gemini-1.5-pro-preview-0409": {
    "input_cost_per_audio_per_second": 0.00003125,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
    "input_cost_per_character": 3.125e-7,
    "input_cost_per_character_above_128k_tokens": 6.25e-7,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 7.8125e-8,
    "input_cost_per_token_above_128k_tokens": 1.5625e-7,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 0.00000125,
    "output_cost_per_character_above_128k_tokens": 0.0000025,
    "output_cost_per_token": 3.125e-7,
    "output_cost_per_token_above_128k_tokens": 6.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "model_id": "gemini-1.5-pro-preview-0409",
    "model_name": "Gemini 1.5 Pro Preview 0409",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.078125,
    "output_cost_per_million": 0.3125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "gemini-1.5-pro-preview-0514": {
    "input_cost_per_audio_per_second": 0.00003125,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
    "input_cost_per_character": 3.125e-7,
    "input_cost_per_character_above_128k_tokens": 6.25e-7,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 7.8125e-8,
    "input_cost_per_token_above_128k_tokens": 1.5625e-7,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 0.00000125,
    "output_cost_per_character_above_128k_tokens": 0.0000025,
    "output_cost_per_token": 3.125e-7,
    "output_cost_per_token_above_128k_tokens": 6.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "model_id": "gemini-1.5-pro-preview-0514",
    "model_name": "Gemini 1.5 Pro Preview 0514",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.078125,
    "output_cost_per_million": 0.3125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true,
    "supports_vision": false
  },
  "gemini-2.0-flash": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 1e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 4e-7,
    "source": "https://ai.google.dev/pricing#2_0flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.0-flash",
    "model_name": "Gemini 2.0 Flash Latest",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.0-flash-001": {
    "deprecation_date": "2026-02-05",
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 1.5e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 6e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.0-flash-001",
    "model_name": "Gemini 2.0 Flash 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": 3.75e-8,
    "cache_read_cost_per_million": 0.0375,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.0-flash-exp": {
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 1.5e-7,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 6e-7,
    "output_cost_per_token_above_128k_tokens": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.0-flash-exp",
    "model_name": "Gemini 2.0 Flash Exp",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": 3.75e-8,
    "cache_read_cost_per_million": 0.0375,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.0-flash-lite": {
    "input_cost_per_audio_token": 7.5e-8,
    "input_cost_per_token": 7.5e-8,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 50,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 3e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.0-flash-lite",
    "model_name": "Gemini 2.0 Flash-Lite",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": 1.875e-8,
    "cache_read_cost_per_million": 0.01875,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.0-flash-lite-001": {
    "deprecation_date": "2026-02-25",
    "input_cost_per_audio_token": 7.5e-8,
    "input_cost_per_token": 7.5e-8,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 50,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 3e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.0-flash-lite-001",
    "model_name": "Gemini 2.0 Flash Lite 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": 1.875e-8,
    "cache_read_cost_per_million": 0.01875,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.0-flash-live-preview-04-09": {
    "input_cost_per_audio_token": 0.000003,
    "input_cost_per_image": 0.000003,
    "input_cost_per_token": 5e-7,
    "input_cost_per_video_per_second": 0.000003,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_audio_token": 0.000012,
    "output_cost_per_token": 0.000002,
    "rpm": 10,
    "source": "https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini#gemini-2-0-flash-live-preview-04-09",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000,
    "model_id": "gemini-2.0-flash-live-preview-04-09",
    "model_name": "Gemini 2.0 Flash Live Preview 04 09",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 2,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "gemini-2.0-flash-preview-image-generation": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 1e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 4e-7,
    "source": "https://ai.google.dev/pricing#2_0flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.0-flash-preview-image-generation",
    "model_name": "Gemini 2.0 Flash Preview Image Generation",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.0-flash-thinking-exp": {
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.0-flash-thinking-exp",
    "model_name": "Gemini 2.0 Flash Thinking Exp",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.0-flash-thinking-exp-01-21": {
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_pdf_size_mb": 30,
    "max_tokens": 65536,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": false,
    "supports_function_calling": false,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.0-flash-thinking-exp-01-21",
    "model_name": "Gemini 2.0 Flash Thinking Exp 01 21",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": true
  },
  "gemini-2.0-pro-exp-02-05": {
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.0-pro-exp-02-05",
    "model_name": "Gemini 2.0 Pro Exp 02 05",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 3.125e-7,
    "cache_read_cost_per_million": 0.3125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.5-flash": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.5-flash",
    "model_name": "Gemini 2.5 Flash",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 2.5,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.5-flash-image-preview": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_image": 0.039,
    "output_cost_per_reasoning_token": 0.00003,
    "output_cost_per_token": 0.00003,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 8000000,
    "model_id": "gemini-2.5-flash-image-preview",
    "model_name": "Gemini 2.5 Flash Image Preview",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 30,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.5-flash-lite": {
    "input_cost_per_audio_token": 5e-7,
    "input_cost_per_token": 1e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_reasoning_token": 4e-7,
    "output_cost_per_token": 4e-7,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.5-flash-lite",
    "model_name": "Gemini 2.5 Flash Lite",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.5-flash-lite-preview-06-17": {
    "input_cost_per_audio_token": 5e-7,
    "input_cost_per_token": 1e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_reasoning_token": 4e-7,
    "output_cost_per_token": 4e-7,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.5-flash-lite-preview-06-17",
    "model_name": "Gemini 2.5 Flash-Lite Preview",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": 2.5e-8,
    "cache_read_cost_per_million": 0.024999999999999998,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.5-flash-preview-04-17": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 1.5e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_reasoning_token": 0.0000035,
    "output_cost_per_token": 6e-7,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.5-flash-preview-04-17",
    "model_name": "Gemini 2.5 Flash Preview 04 17",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": 3.75e-8,
    "cache_read_cost_per_million": 0.0375,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.5-flash-preview-05-20": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3e-7,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.5-flash-preview-05-20",
    "model_name": "Gemini 2.5 Flash Preview 05 20",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 2.5,
    "cache_read_cost_per_token": 7.5e-8,
    "cache_read_cost_per_million": 0.075,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.5-pro": {
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.5-pro",
    "model_name": "Gemini 2.5 Pro",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 3.125e-7,
    "cache_read_cost_per_million": 0.3125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "gemini-2.5-pro-exp-03-25": {
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.5-pro-exp-03-25",
    "model_name": "Gemini 2.5 Pro Exp 03 25",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 3.125e-7,
    "cache_read_cost_per_million": 0.3125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.5-pro-preview-03-25": {
    "input_cost_per_audio_token": 0.00000125,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.5-pro-preview-03-25",
    "model_name": "Gemini 2.5 Pro Preview 03 25",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 3.125e-7,
    "cache_read_cost_per_million": 0.3125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.5-pro-preview-05-06": {
    "input_cost_per_audio_token": 0.00000125,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supported_regions": [
      "global"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.5-pro-preview-05-06",
    "model_name": "Gemini 2.5 Pro Preview 05 06",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 3.125e-7,
    "cache_read_cost_per_million": 0.3125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.5-pro-preview-06-05": {
    "input_cost_per_audio_token": 0.00000125,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.5-pro-preview-06-05",
    "model_name": "Gemini 2.5 Pro Preview 06 05",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 3.125e-7,
    "cache_read_cost_per_million": 0.3125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-2.5-pro-preview-tts": {
    "input_cost_per_audio_token": 7e-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "audio"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "gemini-2.5-pro-preview-tts",
    "model_name": "Gemini 2.5 Pro Preview Tts",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1.25,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": 3.125e-7,
    "cache_read_cost_per_million": 0.3125,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": true
  },
  "gemini-embedding-001": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0,
    "output_vector_size": 3072,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
    "model_id": "gemini-embedding-001",
    "model_name": "Gemini Embedding 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "gemini-flash-experimental": {
    "input_cost_per_character": 0,
    "input_cost_per_token": 0,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 0,
    "output_cost_per_token": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental",
    "supports_function_calling": false,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "gemini-flash-experimental",
    "model_name": "Gemini Flash Experimental",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gemini-pro": {
    "input_cost_per_character": 1.25e-7,
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-7,
    "input_cost_per_video_per_second": 0.002,
    "max_input_tokens": 32760,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 3.75e-7,
    "output_cost_per_token": 0.0000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "gemini-pro",
    "model_name": "Gemini Pro",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gemini-pro-experimental": {
    "input_cost_per_character": 0,
    "input_cost_per_token": 0,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 0,
    "output_cost_per_token": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental",
    "supports_function_calling": false,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "gemini-pro-experimental",
    "model_name": "Gemini Pro Experimental",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_vision": false,
    "supports_json_mode": false
  },
  "gemini-pro-vision": {
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-7,
    "max_images_per_prompt": 16,
    "max_input_tokens": 16384,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "max_video_length": 2,
    "max_videos_per_prompt": 1,
    "output_cost_per_token": 0.0000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "gemini-pro-vision",
    "model_name": "Gemini Pro Vision",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.5,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_parallel_functions": true,
    "supports_json_mode": false
  },
  "imagegeneration@006": {
    "output_cost_per_image": 0.02,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "model_id": "imagegeneration@006",
    "model_name": "Imagegeneration@006",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "imagen-3.0-fast-generate-001": {
    "output_cost_per_image": 0.02,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "model_id": "imagen-3.0-fast-generate-001",
    "model_name": "Imagen 3.0 Fast Generate 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "imagen-3.0-generate-001": {
    "output_cost_per_image": 0.04,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "model_id": "imagen-3.0-generate-001",
    "model_name": "Imagen 3.0 Generate 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "imagen-3.0-generate-002": {
    "output_cost_per_image": 0.04,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "model_id": "imagen-3.0-generate-002",
    "model_name": "Imagen 3.0 Generate 002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "imagen-4.0-fast-generate-001": {
    "output_cost_per_image": 0.02,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "model_id": "imagen-4.0-fast-generate-001",
    "model_name": "Imagen 4.0 Fast Generate 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "imagen-4.0-generate-001": {
    "output_cost_per_image": 0.04,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "model_id": "imagen-4.0-generate-001",
    "model_name": "Imagen 4.0 Generate 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "imagen-4.0-ultra-generate-001": {
    "output_cost_per_image": 0.06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "model_id": "imagen-4.0-ultra-generate-001",
    "model_name": "Imagen 4.0 Ultra Generate 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_input_tokens": null,
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "image",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "jamba-1.5": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 4e-7,
    "supports_tool_choice": true,
    "model_id": "jamba-1.5",
    "model_name": "Jamba 1.5",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "jamba-1.5-large": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.000008,
    "supports_tool_choice": true,
    "model_id": "jamba-1.5-large",
    "model_name": "Jamba 1.5 Large",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "jamba-1.5-large@001": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.000008,
    "supports_tool_choice": true,
    "model_id": "jamba-1.5-large@001",
    "model_name": "Jamba 1.5 Large@001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 8,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "jamba-1.5-mini": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 4e-7,
    "supports_tool_choice": true,
    "model_id": "jamba-1.5-mini",
    "model_name": "Jamba 1.5 Mini",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "jamba-1.5-mini@001": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 4e-7,
    "supports_tool_choice": true,
    "model_id": "jamba-1.5-mini@001",
    "model_name": "Jamba 1.5 Mini@001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 0.39999999999999997,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "medlm-large": {
    "input_cost_per_character": 0.000005,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 0.000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "medlm-large",
    "model_name": "Medlm Large",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "medlm-medium": {
    "input_cost_per_character": 5e-7,
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_character": 0.000001,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_tool_choice": true,
    "model_id": "medlm-medium",
    "model_name": "Medlm Medium",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-3.1-405b-instruct-maas": {
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000016,
    "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "meta/llama-3.1-405b-instruct-maas",
    "model_name": "Llama 3.1 405b Instruct Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 5,
    "output_cost_per_million": 16,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-3.1-70b-instruct-maas": {
    "input_cost_per_token": 0,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 128000,
    "output_cost_per_token": 0,
    "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "meta/llama-3.1-70b-instruct-maas",
    "model_name": "Llama 3.1 70b Instruct Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-3.1-8b-instruct-maas": {
    "input_cost_per_token": 0,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 128000,
    "metadata": {
      "notes": "VertexAI states that The Llama 3.1 API service for llama-3.1-70b-instruct-maas and llama-3.1-8b-instruct-maas are in public preview and at no cost."
    },
    "output_cost_per_token": 0,
    "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "meta/llama-3.1-8b-instruct-maas",
    "model_name": "Llama 3.1 8b Instruct Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-3.2-90b-vision-instruct-maas": {
    "input_cost_per_token": 0,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 128000,
    "metadata": {
      "notes": "VertexAI states that The Llama 3.2 API service is at no cost during public preview, and will be priced as per dollar-per-1M-tokens at GA."
    },
    "output_cost_per_token": 0,
    "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "meta/llama-3.2-90b-vision-instruct-maas",
    "model_name": "Llama 3.2 90b Vision Instruct Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-4-maverick-17b-128e-instruct-maas": {
    "input_cost_per_token": 3.5e-7,
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "max_tokens": 1000000,
    "output_cost_per_token": 0.00000115,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "meta/llama-4-maverick-17b-128e-instruct-maas",
    "model_name": "Llama 4 Maverick 17b 128e Instruct Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.35,
    "output_cost_per_million": 1.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-4-maverick-17b-16e-instruct-maas": {
    "input_cost_per_token": 3.5e-7,
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "max_tokens": 1000000,
    "output_cost_per_token": 0.00000115,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "meta/llama-4-maverick-17b-16e-instruct-maas",
    "model_name": "Llama 4 Maverick 17b 16e Instruct Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.35,
    "output_cost_per_million": 1.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-4-scout-17b-128e-instruct-maas": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 10000000,
    "max_output_tokens": 10000000,
    "max_tokens": 10000000,
    "output_cost_per_token": 7e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "meta/llama-4-scout-17b-128e-instruct-maas",
    "model_name": "Llama 4 Scout 17b 128e Instruct Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 0.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama-4-scout-17b-16e-instruct-maas": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 10000000,
    "max_output_tokens": 10000000,
    "max_tokens": 10000000,
    "output_cost_per_token": 7e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "meta/llama-4-scout-17b-16e-instruct-maas",
    "model_name": "Llama 4 Scout 17b 16e Instruct Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 0.7,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama3-405b-instruct-maas": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supports_tool_choice": true,
    "model_id": "meta/llama3-405b-instruct-maas",
    "model_name": "Llama3 405b Instruct Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama3-70b-instruct-maas": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supports_tool_choice": true,
    "model_id": "meta/llama3-70b-instruct-maas",
    "model_name": "Llama3 70b Instruct Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "meta/llama3-8b-instruct-maas": {
    "input_cost_per_token": 0,
    "max_input_tokens": 32000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supports_tool_choice": true,
    "model_id": "meta/llama3-8b-instruct-maas",
    "model_name": "Llama3 8b Instruct Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral-large-2411": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "mistral-large-2411",
    "model_name": "Mistral Large 2411",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral-large@2407": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "mistral-large@2407",
    "model_name": "Mistral Large@2407",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral-large@2411-001": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "mistral-large@2411-001",
    "model_name": "Mistral Large@2411 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral-large@latest": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "mistral-large@latest",
    "model_name": "Mistral Large@latest",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral-nemo@2407": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "mistral-nemo@2407",
    "model_name": "Mistral Nemo@2407",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral-nemo@latest": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 1.5e-7,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "mistral-nemo@latest",
    "model_name": "Mistral Nemo@latest",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral-small-2503": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "model_id": "mistral-small-2503",
    "model_name": "Mistral Small 2503",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "mistral-small-2503@001": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 32000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "mistral-small-2503@001",
    "model_name": "Mistral Small 2503@001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "multimodalembedding": {
    "input_cost_per_character": 2e-7,
    "input_cost_per_image": 0.0001,
    "input_cost_per_token": 8e-7,
    "input_cost_per_video_per_second": 0.0005,
    "input_cost_per_video_per_second_above_15s_interval": 0.002,
    "input_cost_per_video_per_second_above_8s_interval": 0.001,
    "max_input_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0,
    "output_vector_size": 768,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
    "supported_endpoints": [
      "/v1/embeddings"
    ],
    "supported_modalities": [
      "text",
      "image",
      "video"
    ],
    "model_id": "multimodalembedding",
    "model_name": "Multimodalembedding",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "multimodalembedding@001": {
    "input_cost_per_character": 2e-7,
    "input_cost_per_image": 0.0001,
    "input_cost_per_token": 8e-7,
    "input_cost_per_video_per_second": 0.0005,
    "input_cost_per_video_per_second_above_15s_interval": 0.002,
    "input_cost_per_video_per_second_above_8s_interval": 0.001,
    "max_input_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0,
    "output_vector_size": 768,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
    "supported_endpoints": [
      "/v1/embeddings"
    ],
    "supported_modalities": [
      "text",
      "image",
      "video"
    ],
    "model_id": "multimodalembedding@001",
    "model_name": "Multimodalembedding@001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.7999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openai/gpt-oss-120b-maas": {
    "input_cost_per_token": 1.5e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 6e-7,
    "source": "https://console.cloud.google.com/vertex-ai/publishers/openai/model-garden/gpt-oss-120b-maas",
    "supports_reasoning": true,
    "model_id": "openai/gpt-oss-120b-maas",
    "model_name": "GPT Oss 120b Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.15,
    "output_cost_per_million": 0.6,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "openai/gpt-oss-20b-maas": {
    "input_cost_per_token": 7.5e-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 3e-7,
    "source": "https://console.cloud.google.com/vertex-ai/publishers/openai/model-garden/gpt-oss-120b-maas",
    "supports_reasoning": true,
    "model_id": "openai/gpt-oss-20b-maas",
    "model_name": "GPT Oss 20b Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.075,
    "output_cost_per_million": 0.3,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "qwen/qwen3-235b-a22b-instruct-2507-maas": {
    "input_cost_per_token": 2.5e-7,
    "max_input_tokens": 262144,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "output_cost_per_token": 0.000001,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "qwen/qwen3-235b-a22b-instruct-2507-maas",
    "model_name": "Qwen3 235b A22b Instruct 2507 Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.25,
    "output_cost_per_million": 1,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "qwen/qwen3-coder-480b-a35b-instruct-maas": {
    "input_cost_per_token": 0.000001,
    "max_input_tokens": 262144,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.000004,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "model_id": "qwen/qwen3-coder-480b-a35b-instruct-maas",
    "model_name": "Qwen3 Coder 480b A35b Instruct Maas",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 1,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-bison": {
    "input_cost_per_character": 2.5e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_character": 5e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "text-bison",
    "model_name": "Text Bison",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-bison@001": {
    "input_cost_per_character": 2.5e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "text-bison@001",
    "model_name": "Text Bison@001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-bison@002": {
    "input_cost_per_character": 2.5e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "text-bison@002",
    "model_name": "Text Bison@002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-bison32k": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "text-bison32k",
    "model_name": "Text Bison32k",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-bison32k@002": {
    "input_cost_per_character": 2.5e-7,
    "input_cost_per_token": 1.25e-7,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_character": 5e-7,
    "output_cost_per_token": 1.25e-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "text-bison32k@002",
    "model_name": "Text Bison32k@002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 0.125,
    "output_cost_per_million": 0.125,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-embedding-004": {
    "input_cost_per_character": 2.5e-8,
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0,
    "output_vector_size": 768,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
    "model_id": "text-embedding-004",
    "model_name": "Text Embedding 004",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-embedding-005": {
    "input_cost_per_character": 2.5e-8,
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0,
    "output_vector_size": 768,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
    "model_id": "text-embedding-005",
    "model_name": "Text Embedding 005",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-embedding-large-exp-03-07": {
    "input_cost_per_character": 2.5e-8,
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0,
    "output_vector_size": 3072,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
    "model_id": "text-embedding-large-exp-03-07",
    "model_name": "Text Embedding Large Exp 03 07",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-embedding-preview-0409": {
    "input_cost_per_token": 6.25e-9,
    "input_cost_per_token_batch_requests": 5e-9,
    "max_input_tokens": 3072,
    "max_tokens": 3072,
    "output_cost_per_token": 0,
    "output_vector_size": 768,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "model_id": "text-embedding-preview-0409",
    "model_name": "Text Embedding Preview 0409",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.0062499999999999995,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-multilingual-embedding-002": {
    "input_cost_per_character": 2.5e-8,
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 2048,
    "max_tokens": 2048,
    "output_cost_per_token": 0,
    "output_vector_size": 768,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",
    "model_id": "text-multilingual-embedding-002",
    "model_name": "Text Multilingual Embedding 002",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-multilingual-embedding-preview-0409": {
    "input_cost_per_token": 6.25e-9,
    "max_input_tokens": 3072,
    "max_tokens": 3072,
    "output_cost_per_token": 0,
    "output_vector_size": 768,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "text-multilingual-embedding-preview-0409",
    "model_name": "Text Multilingual Embedding Preview 0409",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.0062499999999999995,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-unicorn": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_token": 0.000028,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "text-unicorn",
    "model_name": "Text Unicorn",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 10,
    "output_cost_per_million": 28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "text-unicorn@001": {
    "input_cost_per_token": 0.00001,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_token": 0.000028,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "text-unicorn@001",
    "model_name": "Text Unicorn@001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "input_cost_per_million": 10,
    "output_cost_per_million": 28,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "completion",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "textembedding-gecko": {
    "input_cost_per_character": 2.5e-8,
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 3072,
    "max_tokens": 3072,
    "output_cost_per_token": 0,
    "output_vector_size": 768,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "textembedding-gecko",
    "model_name": "Textembedding Gecko",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "textembedding-gecko-multilingual": {
    "input_cost_per_character": 2.5e-8,
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 3072,
    "max_tokens": 3072,
    "output_cost_per_token": 0,
    "output_vector_size": 768,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "textembedding-gecko-multilingual",
    "model_name": "Textembedding Gecko Multilingual",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "textembedding-gecko-multilingual@001": {
    "input_cost_per_character": 2.5e-8,
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 3072,
    "max_tokens": 3072,
    "output_cost_per_token": 0,
    "output_vector_size": 768,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "textembedding-gecko-multilingual@001",
    "model_name": "Textembedding Gecko Multilingual@001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "textembedding-gecko@001": {
    "input_cost_per_character": 2.5e-8,
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 3072,
    "max_tokens": 3072,
    "output_cost_per_token": 0,
    "output_vector_size": 768,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "textembedding-gecko@001",
    "model_name": "Textembedding Gecko@001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "textembedding-gecko@003": {
    "input_cost_per_character": 2.5e-8,
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 3072,
    "max_tokens": 3072,
    "output_cost_per_token": 0,
    "output_vector_size": 768,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "model_id": "textembedding-gecko@003",
    "model_name": "Textembedding Gecko@003",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "veo-2.0-generate-001": {
    "max_input_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_second": 0.35,
    "source": "https://ai.google.dev/gemini-api/docs/video",
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "video"
    ],
    "model_id": "veo-2.0-generate-001",
    "model_name": "Veo 2.0 Generate 001",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "video_generation",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "veo-3.0-fast-generate-preview": {
    "max_input_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_second": 0.4,
    "source": "https://ai.google.dev/gemini-api/docs/video",
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "video"
    ],
    "model_id": "veo-3.0-fast-generate-preview",
    "model_name": "Veo 3.0 Fast Generate Preview",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "video_generation",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "veo-3.0-generate-preview": {
    "max_input_tokens": 1024,
    "max_tokens": 1024,
    "output_cost_per_second": 0.75,
    "source": "https://ai.google.dev/gemini-api/docs/video",
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "video"
    ],
    "model_id": "veo-3.0-generate-preview",
    "model_name": "Veo 3.0 Generate Preview",
    "provider_id": "vertex",
    "provider_name": "Google Vertex AI",
    "max_output_tokens": null,
    "input_cost_per_token": 0,
    "input_cost_per_million": 0,
    "output_cost_per_token": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "video_generation",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "doubao-embedding": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_tokens": 4096,
    "metadata": {
      "notes": "Volcengine Doubao embedding model - standard version with 2560 dimensions"
    },
    "output_cost_per_token": 0,
    "output_vector_size": 2560,
    "model_id": "doubao-embedding",
    "model_name": "Doubao Embedding",
    "provider_id": "volcengine",
    "provider_name": "Volcengine",
    "max_output_tokens": null,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "doubao-embedding-large": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_tokens": 4096,
    "metadata": {
      "notes": "Volcengine Doubao embedding model - large version with 2048 dimensions"
    },
    "output_cost_per_token": 0,
    "output_vector_size": 2048,
    "model_id": "doubao-embedding-large",
    "model_name": "Doubao Embedding Large",
    "provider_id": "volcengine",
    "provider_name": "Volcengine",
    "max_output_tokens": null,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "doubao-embedding-large-text-240915": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_tokens": 4096,
    "metadata": {
      "notes": "Volcengine Doubao embedding model - text-240915 version with 4096 dimensions"
    },
    "output_cost_per_token": 0,
    "output_vector_size": 4096,
    "model_id": "doubao-embedding-large-text-240915",
    "model_name": "Doubao Embedding Large Text 240915",
    "provider_id": "volcengine",
    "provider_name": "Volcengine",
    "max_output_tokens": null,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "doubao-embedding-large-text-250515": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_tokens": 4096,
    "metadata": {
      "notes": "Volcengine Doubao embedding model - text-250515 version with 2048 dimensions"
    },
    "output_cost_per_token": 0,
    "output_vector_size": 2048,
    "model_id": "doubao-embedding-large-text-250515",
    "model_name": "Doubao Embedding Large Text 250515",
    "provider_id": "volcengine",
    "provider_name": "Volcengine",
    "max_output_tokens": null,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "doubao-embedding-text-240715": {
    "input_cost_per_token": 0,
    "max_input_tokens": 4096,
    "max_tokens": 4096,
    "metadata": {
      "notes": "Volcengine Doubao embedding model - text-240715 version with 2560 dimensions"
    },
    "output_cost_per_token": 0,
    "output_vector_size": 2560,
    "model_id": "doubao-embedding-text-240715",
    "model_name": "Doubao Embedding Text 240715",
    "provider_id": "volcengine",
    "provider_name": "Volcengine",
    "max_output_tokens": null,
    "input_cost_per_million": 0,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "rerank-2": {
    "input_cost_per_query": 5e-8,
    "input_cost_per_token": 5e-8,
    "max_input_tokens": 16000,
    "max_output_tokens": 16000,
    "max_query_tokens": 16000,
    "max_tokens": 16000,
    "output_cost_per_token": 0,
    "model_id": "rerank-2",
    "model_name": "Rerank 2",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "input_cost_per_million": 0.049999999999999996,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "rerank-2-lite": {
    "input_cost_per_query": 2e-8,
    "input_cost_per_token": 2e-8,
    "max_input_tokens": 8000,
    "max_output_tokens": 8000,
    "max_query_tokens": 8000,
    "max_tokens": 8000,
    "output_cost_per_token": 0,
    "model_id": "rerank-2-lite",
    "model_name": "Rerank 2 Lite",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "input_cost_per_million": 0.02,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "rerank",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-2": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 4000,
    "max_tokens": 4000,
    "output_cost_per_token": 0,
    "model_id": "voyage-2",
    "model_name": "Voyage 2",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-3": {
    "input_cost_per_token": 6e-8,
    "max_input_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0,
    "model_id": "voyage-3",
    "model_name": "Voyage 3",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.06,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-3-large": {
    "input_cost_per_token": 1.8e-7,
    "max_input_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0,
    "model_id": "voyage-3-large",
    "model_name": "Voyage 3 Large",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.18,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-3-lite": {
    "input_cost_per_token": 2e-8,
    "max_input_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0,
    "model_id": "voyage-3-lite",
    "model_name": "Voyage 3 Lite",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.02,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-code-2": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 16000,
    "max_tokens": 16000,
    "output_cost_per_token": 0,
    "model_id": "voyage-code-2",
    "model_name": "Voyage Code 2",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-code-3": {
    "input_cost_per_token": 1.8e-7,
    "max_input_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0,
    "model_id": "voyage-code-3",
    "model_name": "Voyage Code 3",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.18,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-context-3": {
    "input_cost_per_token": 1.8e-7,
    "max_input_tokens": 120000,
    "max_tokens": 120000,
    "output_cost_per_token": 0,
    "model_id": "voyage-context-3",
    "model_name": "Voyage Context 3",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.18,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-finance-2": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0,
    "model_id": "voyage-finance-2",
    "model_name": "Voyage Finance 2",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-large-2": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 16000,
    "max_tokens": 16000,
    "output_cost_per_token": 0,
    "model_id": "voyage-large-2",
    "model_name": "Voyage Large 2",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-law-2": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 16000,
    "max_tokens": 16000,
    "output_cost_per_token": 0,
    "model_id": "voyage-law-2",
    "model_name": "Voyage Law 2",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-lite-01": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 4096,
    "max_tokens": 4096,
    "output_cost_per_token": 0,
    "model_id": "voyage-lite-01",
    "model_name": "Voyage Lite 01",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-lite-02-instruct": {
    "input_cost_per_token": 1e-7,
    "max_input_tokens": 4000,
    "max_tokens": 4000,
    "output_cost_per_token": 0,
    "model_id": "voyage-lite-02-instruct",
    "model_name": "Voyage Lite 02 Instruct",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.09999999999999999,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "voyage-multimodal-3": {
    "input_cost_per_token": 1.2e-7,
    "max_input_tokens": 32000,
    "max_tokens": 32000,
    "output_cost_per_token": 0,
    "model_id": "voyage-multimodal-3",
    "model_name": "Voyage Multimodal 3",
    "provider_id": "voyage",
    "provider_name": "Voyage AI",
    "max_output_tokens": null,
    "input_cost_per_million": 0.12,
    "output_cost_per_million": 0,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "embedding",
    "deprecation_date": null,
    "supports_function_calling": false,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "watsonx/ibm/granite-3-8b-instruct": {
    "input_cost_per_token": 0.0002,
    "max_input_tokens": 8192,
    "max_output_tokens": 1024,
    "max_tokens": 8192,
    "output_cost_per_token": 0.0002,
    "supports_audio_input": false,
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "watsonx/ibm/granite-3-8b-instruct",
    "model_name": "Granite 3 8b Instruct",
    "provider_id": "watsonx",
    "provider_name": "IBM Watsonx",
    "input_cost_per_million": 200,
    "output_cost_per_million": 200,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "watsonx/mistralai/mistral-large": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 131072,
    "max_output_tokens": 16384,
    "max_tokens": 131072,
    "output_cost_per_token": 0.00001,
    "supports_audio_input": false,
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false,
    "model_id": "watsonx/mistralai/mistral-large",
    "model_name": "Mistral Large",
    "provider_id": "watsonx",
    "provider_name": "IBM Watsonx",
    "input_cost_per_million": 3,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": true,
    "supports_parallel_functions": false
  },
  "grok-2": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-2",
    "model_name": "Grok 2",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-2-1212": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-2-1212",
    "model_name": "Grok 2 1212",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-2-latest": {
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-2-latest",
    "model_name": "Grok 2 Latest",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-2-vision": {
    "input_cost_per_image": 0.000002,
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "grok-2-vision",
    "model_name": "Grok 2 Vision",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-2-vision-1212": {
    "input_cost_per_image": 0.000002,
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "grok-2-vision-1212",
    "model_name": "Grok 2 Vision 1212",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-2-vision-latest": {
    "input_cost_per_image": 0.000002,
    "input_cost_per_token": 0.000002,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "grok-2-vision-latest",
    "model_name": "Grok 2 Vision Latest",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 2,
    "output_cost_per_million": 10,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-3": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000015,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-3",
    "model_name": "Grok 3",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "grok-3-beta": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000015,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-3-beta",
    "model_name": "Grok 3 Beta",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "grok-3-fast-beta": {
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000025,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-3-fast-beta",
    "model_name": "Grok 3 Fast Beta",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 5,
    "output_cost_per_million": 25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "grok-3-fast-latest": {
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000025,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-3-fast-latest",
    "model_name": "Grok 3 Fast Latest",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 5,
    "output_cost_per_million": 25,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "grok-3-latest": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000015,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-3-latest",
    "model_name": "Grok 3 Latest",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "grok-3-mini": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 5e-7,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-3-mini",
    "model_name": "Grok 3 Mini",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "grok-3-mini-beta": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 5e-7,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-3-mini-beta",
    "model_name": "Grok 3 Mini Beta",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "grok-3-mini-fast": {
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000004,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-3-mini-fast",
    "model_name": "Grok 3 Mini Fast",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "grok-3-mini-fast-beta": {
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000004,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-3-mini-fast-beta",
    "model_name": "Grok 3 Mini Fast Beta",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "grok-3-mini-fast-latest": {
    "input_cost_per_token": 6e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000004,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-3-mini-fast-latest",
    "model_name": "Grok 3 Mini Fast Latest",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 0.6,
    "output_cost_per_million": 4,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "grok-3-mini-latest": {
    "input_cost_per_token": 3e-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 5e-7,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-3-mini-latest",
    "model_name": "Grok 3 Mini Latest",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 0.3,
    "output_cost_per_million": 0.5,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_vision": false,
    "supports_parallel_functions": false
  },
  "grok-4": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.000015,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-4",
    "model_name": "Grok 4",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-4-0709": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.000015,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-4-0709",
    "model_name": "Grok 4 0709",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-4-latest": {
    "input_cost_per_token": 0.000003,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.000015,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_web_search": true,
    "model_id": "grok-4-latest",
    "model_name": "Grok 4 Latest",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 3,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-beta": {
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "grok-beta",
    "model_name": "Grok Beta",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 5,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-code-fast": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.0000015,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "grok-code-fast",
    "model_name": "Grok Code Fast",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": 2e-8,
    "cache_read_cost_per_million": 0.02,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-code-fast-1": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.0000015,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "grok-code-fast-1",
    "model_name": "Grok Code Fast 1",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": 2e-8,
    "cache_read_cost_per_million": 0.02,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-code-fast-1-0825": {
    "input_cost_per_token": 2e-7,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "output_cost_per_token": 0.0000015,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "model_id": "grok-code-fast-1-0825",
    "model_name": "Grok Code Fast 1 0825",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 0.19999999999999998,
    "output_cost_per_million": 1.5,
    "cache_read_cost_per_token": 2e-8,
    "cache_read_cost_per_million": 0.02,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_vision": false,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  },
  "grok-vision-beta": {
    "input_cost_per_image": 0.000005,
    "input_cost_per_token": 0.000005,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "model_id": "grok-vision-beta",
    "model_name": "Grok Vision Beta",
    "provider_id": "xai",
    "provider_name": "xAI",
    "input_cost_per_million": 5,
    "output_cost_per_million": 15,
    "cache_read_cost_per_token": null,
    "cache_read_cost_per_million": null,
    "cache_write_cost_per_token": null,
    "cache_write_cost_per_million": null,
    "model_type": "chat",
    "deprecation_date": null,
    "supports_json_mode": false,
    "supports_parallel_functions": false
  }
} as const;
