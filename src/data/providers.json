{
  "ai21": [
    {
      "model_id": "j2-light",
      "model_slug": "j2-light",
      "model_name": "J2 Light",
      "provider_id": "ai21",
      "provider_name": "AI21 Labs",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "j2-mid",
      "model_slug": "j2-mid",
      "model_name": "J2 Mid",
      "provider_id": "ai21",
      "provider_name": "AI21 Labs",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "j2-ultra",
      "model_slug": "j2-ultra",
      "model_name": "J2 Ultra",
      "provider_id": "ai21",
      "provider_name": "AI21 Labs",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "jamba-1.5",
      "model_slug": "jamba-1.5",
      "model_name": "Jamba 1.5",
      "provider_id": "ai21",
      "provider_name": "AI21 Labs",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "jamba-1.5-large",
      "model_slug": "jamba-1.5-large",
      "model_name": "Jamba 1.5 Large",
      "provider_id": "ai21",
      "provider_name": "AI21 Labs",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "jamba-1.5-large@001",
      "model_slug": "jamba-1.5-large@001",
      "model_name": "Jamba 1.5 Large@001",
      "provider_id": "ai21",
      "provider_name": "AI21 Labs",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "jamba-1.5-mini",
      "model_slug": "jamba-1.5-mini",
      "model_name": "Jamba 1.5 Mini",
      "provider_id": "ai21",
      "provider_name": "AI21 Labs",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "jamba-1.5-mini@001",
      "model_slug": "jamba-1.5-mini@001",
      "model_name": "Jamba 1.5 Mini@001",
      "provider_id": "ai21",
      "provider_name": "AI21 Labs",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "jamba-large-1.6",
      "model_slug": "jamba-large-1.6",
      "model_name": "Jamba Large 1.6",
      "provider_id": "ai21",
      "provider_name": "AI21 Labs",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "jamba-large-1.7",
      "model_slug": "jamba-large-1.7",
      "model_name": "Jamba Large 1.7",
      "provider_id": "ai21",
      "provider_name": "AI21 Labs",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "jamba-mini-1.6",
      "model_slug": "jamba-mini-1.6",
      "model_name": "Jamba Mini 1.6",
      "provider_id": "ai21",
      "provider_name": "AI21 Labs",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "jamba-mini-1.7",
      "model_slug": "jamba-mini-1.7",
      "model_name": "Jamba Mini 1.7",
      "provider_id": "ai21",
      "provider_name": "AI21 Labs",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "aleph": [
    {
      "model_id": "luminous-base",
      "model_slug": "luminous-base",
      "model_name": "Luminous Base",
      "provider_id": "aleph",
      "provider_name": "Aleph",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.00003,
      "input_cost_per_million": 30,
      "output_cost_per_token": 0.000033,
      "output_cost_per_million": 33,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "luminous-base-control",
      "model_slug": "luminous-base-control",
      "model_name": "Luminous Base Control",
      "provider_id": "aleph",
      "provider_name": "Aleph",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.0000375,
      "input_cost_per_million": 37.5,
      "output_cost_per_token": 0.00004125,
      "output_cost_per_million": 41.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "luminous-extended",
      "model_slug": "luminous-extended",
      "model_name": "Luminous Extended",
      "provider_id": "aleph",
      "provider_name": "Aleph",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000045,
      "input_cost_per_million": 45,
      "output_cost_per_token": 0.0000495,
      "output_cost_per_million": 49.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "luminous-extended-control",
      "model_slug": "luminous-extended-control",
      "model_name": "Luminous Extended Control",
      "provider_id": "aleph",
      "provider_name": "Aleph",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.00005625,
      "input_cost_per_million": 56.25,
      "output_cost_per_token": 0.000061875,
      "output_cost_per_million": 61.875,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "luminous-supreme",
      "model_slug": "luminous-supreme",
      "model_name": "Luminous Supreme",
      "provider_id": "aleph",
      "provider_name": "Aleph",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000175,
      "input_cost_per_million": 175,
      "output_cost_per_token": 0.0001925,
      "output_cost_per_million": 192.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "luminous-supreme-control",
      "model_slug": "luminous-supreme-control",
      "model_name": "Luminous Supreme Control",
      "provider_id": "aleph",
      "provider_name": "Aleph",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.00021875,
      "input_cost_per_million": 218.75,
      "output_cost_per_token": 0.000240625,
      "output_cost_per_million": 240.625,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "anthropic": [
    {
      "model_id": "claude-2",
      "model_slug": "claude-2",
      "model_name": "Claude 2",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-2.1",
      "model_slug": "claude-2.1",
      "model_name": "Claude 2.1",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-3-5-haiku-20241022",
      "model_slug": "claude-3-5-haiku-20241022",
      "model_name": "Claude 3.5 Haiku (Oct 2024)",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 8e-7,
      "input_cost_per_million": 0.7999999999999999,
      "output_cost_per_token": 0.000004,
      "output_cost_per_million": 4,
      "cache_read_cost_per_token": 8e-8,
      "cache_read_cost_per_million": 0.08,
      "cache_write_cost_per_token": 0.000001,
      "cache_write_cost_per_million": 1,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-10-01"
    },
    {
      "model_id": "claude-3-5-haiku-latest",
      "model_slug": "claude-3-5-haiku-latest",
      "model_name": "Claude 3.5 Haiku",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": 1e-7,
      "cache_read_cost_per_million": 0.09999999999999999,
      "cache_write_cost_per_token": 0.00000125,
      "cache_write_cost_per_million": 1.25,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-10-01"
    },
    {
      "model_id": "claude-3-5-sonnet-20240620",
      "model_slug": "claude-3-5-sonnet-20240620",
      "model_name": "Claude 3.5 Sonnet (Jun 2024)",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-06-01"
    },
    {
      "model_id": "claude-3-5-sonnet-20241022",
      "model_slug": "claude-3-5-sonnet-20241022",
      "model_name": "Claude 3.5 Sonnet (Oct 2024)",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-10-01"
    },
    {
      "model_id": "claude-3-5-sonnet-latest",
      "model_slug": "claude-3-5-sonnet-latest",
      "model_name": "Claude 3.5 Sonnet",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-06-01"
    },
    {
      "model_id": "claude-3-7-sonnet-20250219",
      "model_slug": "claude-3-7-sonnet-20250219",
      "model_name": "Claude 3.7 Sonnet (Feb 2025)",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2026-02-01"
    },
    {
      "model_id": "claude-3-7-sonnet-latest",
      "model_slug": "claude-3-7-sonnet-latest",
      "model_name": "Claude 3.7 Sonnet",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-06-01"
    },
    {
      "model_id": "claude-3-haiku-20240307",
      "model_slug": "claude-3-haiku-20240307",
      "model_name": "Claude 3 Haiku",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 0.00000125,
      "output_cost_per_million": 1.25,
      "cache_read_cost_per_token": 3e-8,
      "cache_read_cost_per_million": 0.03,
      "cache_write_cost_per_token": 3e-7,
      "cache_write_cost_per_million": 0.3,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-03-01"
    },
    {
      "model_id": "claude-3-opus-20240229",
      "model_slug": "claude-3-opus-20240229",
      "model_name": "Claude 3 Opus (Feb 2024)",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": 0.0000015,
      "cache_read_cost_per_million": 1.5,
      "cache_write_cost_per_token": 0.00001875,
      "cache_write_cost_per_million": 18.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-03-01"
    },
    {
      "model_id": "claude-3-opus-latest",
      "model_slug": "claude-3-opus-latest",
      "model_name": "Claude 3 Opus",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": 0.0000015,
      "cache_read_cost_per_million": 1.5,
      "cache_write_cost_per_token": 0.00001875,
      "cache_write_cost_per_million": 18.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-03-01"
    },
    {
      "model_id": "claude-3-sonnet-20240229",
      "model_slug": "claude-3-sonnet-20240229",
      "model_name": "Claude 3 Sonnet",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-07-21"
    },
    {
      "model_id": "claude-4-opus-20250514",
      "model_slug": "claude-4-opus-20250514",
      "model_name": "Claude 4 Opus 20250514",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": 0.0000015,
      "cache_read_cost_per_million": 1.5,
      "cache_write_cost_per_token": 0.00001875,
      "cache_write_cost_per_million": 18.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-4-sonnet-20250514",
      "model_slug": "claude-4-sonnet-20250514",
      "model_name": "Claude 4 Sonnet 20250514",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-opus-4-20250514",
      "model_slug": "claude-opus-4-20250514",
      "model_name": "Claude 4 Opus",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": 0.0000015,
      "cache_read_cost_per_million": 1.5,
      "cache_write_cost_per_token": 0.00001875,
      "cache_write_cost_per_million": 18.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-sonnet-4-20250514",
      "model_slug": "claude-sonnet-4-20250514",
      "model_name": "Claude 4 Sonnet",
      "provider_id": "anthropic",
      "provider_name": "Anthropic",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "anyscale": [
    {
      "model_id": "codellama/CodeLlama-34b-Instruct-hf",
      "model_slug": "anyscale/codellama/CodeLlama-34b-Instruct-hf",
      "model_name": "CodeLlama 34b Instruct Hf | codellama",
      "provider_id": "anyscale",
      "provider_name": "Anyscale",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000001,
      "output_cost_per_million": 1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codellama/CodeLlama-70b-Instruct-hf",
      "model_slug": "anyscale/codellama/CodeLlama-70b-Instruct-hf",
      "model_name": "CodeLlama 70b Instruct Hf | codellama",
      "provider_id": "anyscale",
      "provider_name": "Anyscale",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000001,
      "output_cost_per_million": 1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "google/gemma-7b-it",
      "model_slug": "anyscale/google/gemma-7b-it",
      "model_name": "Gemma 7b IT | google",
      "provider_id": "anyscale",
      "provider_name": "Anyscale",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 1.5e-7,
      "output_cost_per_million": 0.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "HuggingFaceH4/zephyr-7b-beta",
      "model_slug": "anyscale/HuggingFaceH4/zephyr-7b-beta",
      "model_name": "Zephyr 7b Beta | HuggingFaceH4",
      "provider_id": "anyscale",
      "provider_name": "Anyscale",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 1.5e-7,
      "output_cost_per_million": 0.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Llama-2-13b-chat-hf",
      "model_slug": "anyscale/meta-llama/Llama-2-13b-chat-hf",
      "model_name": "Llama 2 13b Chat Hf | meta-llama",
      "provider_id": "anyscale",
      "provider_name": "Anyscale",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 2.5e-7,
      "output_cost_per_million": 0.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Llama-2-70b-chat-hf",
      "model_slug": "anyscale/meta-llama/Llama-2-70b-chat-hf",
      "model_name": "Llama 2 70b Chat Hf | meta-llama",
      "provider_id": "anyscale",
      "provider_name": "Anyscale",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000001,
      "output_cost_per_million": 1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Llama-2-7b-chat-hf",
      "model_slug": "anyscale/meta-llama/Llama-2-7b-chat-hf",
      "model_name": "Llama 2 7b Chat Hf | meta-llama",
      "provider_id": "anyscale",
      "provider_name": "Anyscale",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 1.5e-7,
      "output_cost_per_million": 0.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Meta-Llama-3-70B-Instruct",
      "model_slug": "anyscale/meta-llama/Meta-Llama-3-70B-Instruct",
      "model_name": "Meta Llama 3 70B Instruct | meta-llama",
      "provider_id": "anyscale",
      "provider_name": "Anyscale",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000001,
      "output_cost_per_million": 1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
      "model_slug": "anyscale/meta-llama/Meta-Llama-3-8B-Instruct",
      "model_name": "Meta Llama 3 8B Instruct | meta-llama",
      "provider_id": "anyscale",
      "provider_name": "Anyscale",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 1.5e-7,
      "output_cost_per_million": 0.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistralai/Mistral-7B-Instruct-v0.1",
      "model_slug": "anyscale/mistralai/Mistral-7B-Instruct-v0.1",
      "model_name": "Mistral 7B Instruct V0.1 | mistralai",
      "provider_id": "anyscale",
      "provider_name": "Anyscale",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 1.5e-7,
      "output_cost_per_million": 0.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistralai/Mixtral-8x22B-Instruct-v0.1",
      "model_slug": "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1",
      "model_name": "Mixtral 8x22B Instruct V0.1 | mistralai",
      "provider_id": "anyscale",
      "provider_name": "Anyscale",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_token": 9e-7,
      "input_cost_per_million": 0.8999999999999999,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "model_slug": "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1",
      "model_name": "Mixtral 8x7B Instruct V0.1 | mistralai",
      "provider_id": "anyscale",
      "provider_name": "Anyscale",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 1.5e-7,
      "output_cost_per_million": 0.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "assemblyai": [
    {
      "model_id": "assemblyai/best",
      "model_slug": "assemblyai/best",
      "model_name": "Best | assemblyai",
      "provider_id": "assemblyai",
      "provider_name": "AssemblyAI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "assemblyai/nano",
      "model_slug": "assemblyai/nano",
      "model_name": "Nano | assemblyai",
      "provider_id": "assemblyai",
      "provider_name": "AssemblyAI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    }
  ],
  "azure": [
    {
      "model_id": "ada",
      "model_slug": "azure/ada",
      "model_name": "Ada",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 8191,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Cohere-embed-v3-english",
      "model_slug": "azure_ai/Cohere-embed-v3-english",
      "model_name": "Cohere Embed V3 English | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 512,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Cohere-embed-v3-multilingual",
      "model_slug": "azure_ai/Cohere-embed-v3-multilingual",
      "model_name": "Cohere Embed V3 Multilingual | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 512,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/cohere-rerank-v3-english",
      "model_slug": "azure_ai/cohere-rerank-v3-english",
      "model_name": "Cohere Rerank V3 English | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/cohere-rerank-v3-multilingual",
      "model_slug": "azure_ai/cohere-rerank-v3-multilingual",
      "model_name": "Cohere Rerank V3 Multilingual | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/cohere-rerank-v3.5",
      "model_slug": "azure_ai/cohere-rerank-v3.5",
      "model_name": "Cohere Rerank V3.5 | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/deepseek-r1",
      "model_slug": "azure_ai/deepseek-r1",
      "model_name": "DeepSeek R1 | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000135,
      "input_cost_per_million": 1.35,
      "output_cost_per_token": 0.0000054,
      "output_cost_per_million": 5.4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/deepseek-v3",
      "model_slug": "azure_ai/deepseek-v3",
      "model_name": "DeepSeek V3 | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000114,
      "input_cost_per_million": 1.1400000000000001,
      "output_cost_per_token": 0.00000456,
      "output_cost_per_million": 4.5600000000000005,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/deepseek-v3-0324",
      "model_slug": "azure_ai/deepseek-v3-0324",
      "model_name": "Deepseek V3 0324 | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000114,
      "input_cost_per_million": 1.1400000000000001,
      "output_cost_per_token": 0.00000456,
      "output_cost_per_million": 4.5600000000000005,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/embed-v-4-0",
      "model_slug": "azure_ai/embed-v-4-0",
      "model_name": "Embed V 4 0 | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": null,
      "input_cost_per_token": 1.2e-7,
      "input_cost_per_million": 0.12,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/jamba-instruct",
      "model_slug": "azure_ai/jamba-instruct",
      "model_name": "Jamba Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 70000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 7e-7,
      "output_cost_per_million": 0.7,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Llama-3.2-11B-Vision-Instruct",
      "model_slug": "azure_ai/Llama-3.2-11B-Vision-Instruct",
      "model_name": "Llama 3.2 11B Vision Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 3.7e-7,
      "input_cost_per_million": 0.37,
      "output_cost_per_token": 3.7e-7,
      "output_cost_per_million": 0.37,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Llama-3.2-90B-Vision-Instruct",
      "model_slug": "azure_ai/Llama-3.2-90B-Vision-Instruct",
      "model_name": "Llama 3.2 90B Vision Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.00000204,
      "input_cost_per_million": 2.04,
      "output_cost_per_token": 0.00000204,
      "output_cost_per_million": 2.04,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Llama-3.3-70B-Instruct",
      "model_slug": "azure_ai/Llama-3.3-70B-Instruct",
      "model_name": "Llama 3.3 70B Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 7.1e-7,
      "input_cost_per_million": 0.71,
      "output_cost_per_token": 7.1e-7,
      "output_cost_per_million": 0.71,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "model_slug": "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "model_name": "Llama 4 Maverick 17B 128E Instruct FP8 | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000141,
      "input_cost_per_million": 1.4100000000000001,
      "output_cost_per_token": 3.5e-7,
      "output_cost_per_million": 0.35,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Llama-4-Scout-17B-16E-Instruct",
      "model_slug": "azure_ai/Llama-4-Scout-17B-16E-Instruct",
      "model_name": "Llama 4 Scout 17B 16E Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 10000000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 7.8e-7,
      "output_cost_per_million": 0.78,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Meta-Llama-3-70B-Instruct",
      "model_slug": "azure_ai/Meta-Llama-3-70B-Instruct",
      "model_name": "Meta Llama 3 70B Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.0000011,
      "input_cost_per_million": 1.1,
      "output_cost_per_token": 3.7e-7,
      "output_cost_per_million": 0.37,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Meta-Llama-3.1-405B-Instruct",
      "model_slug": "azure_ai/Meta-Llama-3.1-405B-Instruct",
      "model_name": "Meta Llama 3.1 405B Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.00000533,
      "input_cost_per_million": 5.33,
      "output_cost_per_token": 0.000016,
      "output_cost_per_million": 16,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Meta-Llama-3.1-70B-Instruct",
      "model_slug": "azure_ai/Meta-Llama-3.1-70B-Instruct",
      "model_name": "Meta Llama 3.1 70B Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.00000268,
      "input_cost_per_million": 2.68,
      "output_cost_per_token": 0.00000354,
      "output_cost_per_million": 3.54,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Meta-Llama-3.1-8B-Instruct",
      "model_slug": "azure_ai/Meta-Llama-3.1-8B-Instruct",
      "model_name": "Meta Llama 3.1 8B Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 6.1e-7,
      "output_cost_per_million": 0.61,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/ministral-3b",
      "model_slug": "azure_ai/ministral-3b",
      "model_name": "Ministral 3b | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 4e-8,
      "input_cost_per_million": 0.04,
      "output_cost_per_token": 4e-8,
      "output_cost_per_million": 0.04,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/mistral-large",
      "model_slug": "azure_ai/mistral-large",
      "model_name": "Mistral Large | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000004,
      "input_cost_per_million": 4,
      "output_cost_per_token": 0.000012,
      "output_cost_per_million": 12,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/mistral-large-2407",
      "model_slug": "azure_ai/mistral-large-2407",
      "model_name": "Mistral Large 2407 | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/mistral-large-latest",
      "model_slug": "azure_ai/mistral-large-latest",
      "model_name": "Mistral Large | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/mistral-medium-2505",
      "model_slug": "azure_ai/mistral-medium-2505",
      "model_name": "Mistral Medium 2505 | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 131072,
      "max_output_tokens": 8191,
      "input_cost_per_token": 4e-7,
      "input_cost_per_million": 0.39999999999999997,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/mistral-nemo",
      "model_slug": "azure_ai/mistral-nemo",
      "model_name": "Mistral Nemo | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 1.5e-7,
      "output_cost_per_million": 0.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/mistral-small",
      "model_slug": "azure_ai/mistral-small",
      "model_name": "Mistral Small | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/mistral-small-2503",
      "model_slug": "azure_ai/mistral-small-2503",
      "model_name": "Mistral Small 2503 | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Phi-3-medium-128k-instruct",
      "model_slug": "azure_ai/Phi-3-medium-128k-instruct",
      "model_name": "Phi 3 Medium 128k Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.7e-7,
      "input_cost_per_million": 0.16999999999999998,
      "output_cost_per_token": 6.8e-7,
      "output_cost_per_million": 0.6799999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Phi-3-medium-4k-instruct",
      "model_slug": "azure_ai/Phi-3-medium-4k-instruct",
      "model_name": "Phi 3 Medium 4k Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.7e-7,
      "input_cost_per_million": 0.16999999999999998,
      "output_cost_per_token": 6.8e-7,
      "output_cost_per_million": 0.6799999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Phi-3-mini-128k-instruct",
      "model_slug": "azure_ai/Phi-3-mini-128k-instruct",
      "model_name": "Phi 3 Mini 128k Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.3e-7,
      "input_cost_per_million": 0.13,
      "output_cost_per_token": 5.2e-7,
      "output_cost_per_million": 0.52,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Phi-3-mini-4k-instruct",
      "model_slug": "azure_ai/Phi-3-mini-4k-instruct",
      "model_name": "Phi 3 Mini 4k Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.3e-7,
      "input_cost_per_million": 0.13,
      "output_cost_per_token": 5.2e-7,
      "output_cost_per_million": 0.52,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Phi-3-small-128k-instruct",
      "model_slug": "azure_ai/Phi-3-small-128k-instruct",
      "model_name": "Phi 3 Small 128k Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Phi-3-small-8k-instruct",
      "model_slug": "azure_ai/Phi-3-small-8k-instruct",
      "model_name": "Phi 3 Small 8k Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Phi-3.5-mini-instruct",
      "model_slug": "azure_ai/Phi-3.5-mini-instruct",
      "model_name": "Phi 3.5 Mini Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.3e-7,
      "input_cost_per_million": 0.13,
      "output_cost_per_token": 5.2e-7,
      "output_cost_per_million": 0.52,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Phi-3.5-MoE-instruct",
      "model_slug": "azure_ai/Phi-3.5-MoE-instruct",
      "model_name": "Phi 3.5 MoE Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.6e-7,
      "input_cost_per_million": 0.16,
      "output_cost_per_token": 6.4e-7,
      "output_cost_per_million": 0.64,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Phi-3.5-vision-instruct",
      "model_slug": "azure_ai/Phi-3.5-vision-instruct",
      "model_name": "Phi 3.5 Vision Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.3e-7,
      "input_cost_per_million": 0.13,
      "output_cost_per_token": 5.2e-7,
      "output_cost_per_million": 0.52,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Phi-4",
      "model_slug": "azure_ai/Phi-4",
      "model_name": "Phi 4 | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Phi-4-mini-instruct",
      "model_slug": "azure_ai/Phi-4-mini-instruct",
      "model_name": "Phi 4 Mini Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "azure_ai/Phi-4-multimodal-instruct",
      "model_slug": "azure_ai/Phi-4-multimodal-instruct",
      "model_name": "Phi 4 Multimodal Instruct | azure_ai",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "input_cost_per_token": 8e-8,
      "input_cost_per_million": 0.08,
      "output_cost_per_token": 3.2e-7,
      "output_cost_per_million": 0.32,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codex-mini",
      "model_slug": "azure/codex-mini",
      "model_name": "Codex Mini",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000015,
      "input_cost_per_million": 1.5,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": 3.75e-7,
      "cache_read_cost_per_million": 0.375,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "computer-use-preview",
      "model_slug": "azure/computer-use-preview",
      "model_name": "Computer Use Preview",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000012,
      "output_cost_per_million": 12,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu/gpt-4o-2024-08-06",
      "model_slug": "azure/eu/gpt-4o-2024-08-06",
      "model_name": "GPT 4o (Aug 2024) | eu",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000275,
      "input_cost_per_million": 2.75,
      "output_cost_per_token": 0.000011,
      "output_cost_per_million": 11,
      "cache_read_cost_per_token": 0.000001375,
      "cache_read_cost_per_million": 1.375,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu/gpt-4o-2024-11-20",
      "model_slug": "azure/eu/gpt-4o-2024-11-20",
      "model_name": "GPT 4o (Nov 2024) | eu",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000275,
      "input_cost_per_million": 2.75,
      "output_cost_per_token": 0.000011,
      "output_cost_per_million": 11,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": 0.00000138,
      "cache_write_cost_per_million": 1.38,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu/gpt-4o-mini-2024-07-18",
      "model_slug": "azure/eu/gpt-4o-mini-2024-07-18",
      "model_name": "GPT 4o mini (Jul 2024) | eu",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.65e-7,
      "input_cost_per_million": 0.165,
      "output_cost_per_token": 6.6e-7,
      "output_cost_per_million": 0.66,
      "cache_read_cost_per_token": 8.3e-8,
      "cache_read_cost_per_million": 0.083,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu/gpt-4o-mini-realtime-preview-2024-12-17",
      "model_slug": "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17",
      "model_name": "Gpt 4o Mini Realtime Preview 2024 12 17 | eu",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6.6e-7,
      "input_cost_per_million": 0.66,
      "output_cost_per_token": 0.00000264,
      "output_cost_per_million": 2.64,
      "cache_read_cost_per_token": 3.3e-7,
      "cache_read_cost_per_million": 0.33,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu/gpt-4o-realtime-preview-2024-10-01",
      "model_slug": "azure/eu/gpt-4o-realtime-preview-2024-10-01",
      "model_name": "Gpt 4o Realtime Preview 2024 10 01 | eu",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000055,
      "input_cost_per_million": 5.5,
      "output_cost_per_token": 0.000022,
      "output_cost_per_million": 22,
      "cache_read_cost_per_token": 0.00000275,
      "cache_read_cost_per_million": 2.75,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu/gpt-4o-realtime-preview-2024-12-17",
      "model_slug": "azure/eu/gpt-4o-realtime-preview-2024-12-17",
      "model_name": "Gpt 4o Realtime Preview 2024 12 17 | eu",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000055,
      "input_cost_per_million": 5.5,
      "output_cost_per_token": 0.000022,
      "output_cost_per_million": 22,
      "cache_read_cost_per_token": 0.00000275,
      "cache_read_cost_per_million": 2.75,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu/o1-2024-12-17",
      "model_slug": "azure/eu/o1-2024-12-17",
      "model_name": "O1 2024 12 17 | eu",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000165,
      "input_cost_per_million": 16.5,
      "output_cost_per_token": 0.000066,
      "output_cost_per_million": 66,
      "cache_read_cost_per_token": 0.00000825,
      "cache_read_cost_per_million": 8.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu/o1-mini-2024-09-12",
      "model_slug": "azure/eu/o1-mini-2024-09-12",
      "model_name": "O1 Mini 2024 09 12 | eu",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_million": 1.21,
      "output_cost_per_token": 0.00000484,
      "output_cost_per_million": 4.84,
      "cache_read_cost_per_token": 6.05e-7,
      "cache_read_cost_per_million": 0.605,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu/o1-preview-2024-09-12",
      "model_slug": "azure/eu/o1-preview-2024-09-12",
      "model_name": "O1 Preview 2024 09 12 | eu",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.0000165,
      "input_cost_per_million": 16.5,
      "output_cost_per_token": 0.000066,
      "output_cost_per_million": 66,
      "cache_read_cost_per_token": 0.00000825,
      "cache_read_cost_per_million": 8.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu/o3-mini-2025-01-31",
      "model_slug": "azure/eu/o3-mini-2025-01-31",
      "model_name": "O3 Mini 2025 01 31 | eu",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_million": 1.21,
      "output_cost_per_token": 0.00000484,
      "output_cost_per_million": 4.84,
      "cache_read_cost_per_token": 6.05e-7,
      "cache_read_cost_per_million": 0.605,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "global-standard/gpt-4o-2024-08-06",
      "model_slug": "azure/global-standard/gpt-4o-2024-08-06",
      "model_name": "GPT 4o (Aug 2024) | global-standard",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 0.00000125,
      "cache_read_cost_per_million": 1.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-08-20"
    },
    {
      "model_id": "global-standard/gpt-4o-2024-11-20",
      "model_slug": "azure/global-standard/gpt-4o-2024-11-20",
      "model_name": "GPT 4o (Nov 2024) | global-standard",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 0.00000125,
      "cache_read_cost_per_million": 1.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-12-20"
    },
    {
      "model_id": "global-standard/gpt-4o-mini",
      "model_slug": "azure/global-standard/gpt-4o-mini",
      "model_name": "GPT 4o mini | global-standard",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "global/gpt-4o-2024-08-06",
      "model_slug": "azure/global/gpt-4o-2024-08-06",
      "model_name": "GPT 4o (Aug 2024) | global",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 0.00000125,
      "cache_read_cost_per_million": 1.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "global/gpt-4o-2024-11-20",
      "model_slug": "azure/global/gpt-4o-2024-11-20",
      "model_name": "GPT 4o (Nov 2024) | global",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 0.00000125,
      "cache_read_cost_per_million": 1.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-3.5-turbo",
      "model_slug": "azure/gpt-3.5-turbo",
      "model_name": "GPT 3.5T",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-3.5-turbo-0125",
      "model_slug": "azure/gpt-3.5-turbo-0125",
      "model_name": "GPT 3.5T 0125",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-03-31"
    },
    {
      "model_id": "gpt-35-turbo",
      "model_slug": "azure/gpt-35-turbo",
      "model_name": "GPT 35 Turbo",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-35-turbo-0125",
      "model_slug": "azure/gpt-35-turbo-0125",
      "model_name": "GPT 35 Turbo 0125",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-05-31"
    },
    {
      "model_id": "gpt-35-turbo-0301",
      "model_slug": "azure/gpt-35-turbo-0301",
      "model_name": "GPT 35 Turbo 0301",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-02-13"
    },
    {
      "model_id": "gpt-35-turbo-0613",
      "model_slug": "azure/gpt-35-turbo-0613",
      "model_name": "GPT 35 Turbo 0613",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "input_cost_per_million": 1.5,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-02-13"
    },
    {
      "model_id": "gpt-35-turbo-1106",
      "model_slug": "azure/gpt-35-turbo-1106",
      "model_name": "GPT 35 Turbo 1106",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-03-31"
    },
    {
      "model_id": "gpt-35-turbo-16k",
      "model_slug": "azure/gpt-35-turbo-16k",
      "model_name": "GPT 35 Turbo 16k",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000004,
      "output_cost_per_million": 4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-35-turbo-16k-0613",
      "model_slug": "azure/gpt-35-turbo-16k-0613",
      "model_name": "GPT 35 Turbo 16k 0613",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000004,
      "output_cost_per_million": 4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-35-turbo-instruct",
      "model_slug": "azure/gpt-35-turbo-instruct",
      "model_name": "GPT 35 Turbo Instruct",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 4097,
      "max_output_tokens": null,
      "input_cost_per_token": 0.0000015,
      "input_cost_per_million": 1.5,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-35-turbo-instruct-0914",
      "model_slug": "azure/gpt-35-turbo-instruct-0914",
      "model_name": "GPT 35 Turbo Instruct 0914",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 4097,
      "max_output_tokens": null,
      "input_cost_per_token": 0.0000015,
      "input_cost_per_million": 1.5,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4",
      "model_slug": "azure/gpt-4",
      "model_name": "GPT-4",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "input_cost_per_million": 30,
      "output_cost_per_token": 0.00006,
      "output_cost_per_million": 60,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4-0125-preview",
      "model_slug": "azure/gpt-4-0125-preview",
      "model_name": "GPT 4 0125 Preview",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00003,
      "output_cost_per_million": 30,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4-0613",
      "model_slug": "azure/gpt-4-0613",
      "model_name": "GPT 4 0613",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "input_cost_per_million": 30,
      "output_cost_per_token": 0.00006,
      "output_cost_per_million": 60,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4-1106-preview",
      "model_slug": "azure/gpt-4-1106-preview",
      "model_name": "GPT 4 1106 Preview",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00003,
      "output_cost_per_million": 30,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4-32k",
      "model_slug": "azure/gpt-4-32k",
      "model_name": "GPT 4 32k",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "input_cost_per_million": 60,
      "output_cost_per_token": 0.00012,
      "output_cost_per_million": 120,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4-32k-0613",
      "model_slug": "azure/gpt-4-32k-0613",
      "model_name": "GPT 4 32k 0613",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "input_cost_per_million": 60,
      "output_cost_per_token": 0.00012,
      "output_cost_per_million": 120,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4-turbo",
      "model_slug": "azure/gpt-4-turbo",
      "model_name": "GPT-4 Turbo",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00003,
      "output_cost_per_million": 30,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4-turbo-2024-04-09",
      "model_slug": "azure/gpt-4-turbo-2024-04-09",
      "model_name": "GPT 4 Turbo 2024 04 09",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00003,
      "output_cost_per_million": 30,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4-turbo-vision-preview",
      "model_slug": "azure/gpt-4-turbo-vision-preview",
      "model_name": "GPT 4 Turbo Vision Preview",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00003,
      "output_cost_per_million": 30,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4.1",
      "model_slug": "azure/gpt-4.1",
      "model_name": "GPT-4.1",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": 5e-7,
      "cache_read_cost_per_million": 0.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4.1-2025-04-14",
      "model_slug": "azure/gpt-4.1-2025-04-14",
      "model_name": "GPT-4.1 (Apr 2025)",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": 5e-7,
      "cache_read_cost_per_million": 0.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4.1-mini",
      "model_slug": "azure/gpt-4.1-mini",
      "model_name": "GPT-4.1 mini",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 4e-7,
      "input_cost_per_million": 0.39999999999999997,
      "output_cost_per_token": 0.0000016,
      "output_cost_per_million": 1.5999999999999999,
      "cache_read_cost_per_token": 1e-7,
      "cache_read_cost_per_million": 0.09999999999999999,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4.1-mini-2025-04-14",
      "model_slug": "azure/gpt-4.1-mini-2025-04-14",
      "model_name": "GPT 4.1 Mini 2025 04 14",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 4e-7,
      "input_cost_per_million": 0.39999999999999997,
      "output_cost_per_token": 0.0000016,
      "output_cost_per_million": 1.5999999999999999,
      "cache_read_cost_per_token": 1e-7,
      "cache_read_cost_per_million": 0.09999999999999999,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4.1-nano",
      "model_slug": "azure/gpt-4.1-nano",
      "model_name": "GPT-4.1 nano",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": 2.5e-8,
      "cache_read_cost_per_million": 0.024999999999999998,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4.1-nano-2025-04-14",
      "model_slug": "azure/gpt-4.1-nano-2025-04-14",
      "model_name": "GPT 4.1 Nano 2025 04 14",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": 2.5e-8,
      "cache_read_cost_per_million": 0.024999999999999998,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4.5-preview",
      "model_slug": "azure/gpt-4.5-preview",
      "model_name": "GPT-4.5",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000075,
      "input_cost_per_million": 75,
      "output_cost_per_token": 0.00015,
      "output_cost_per_million": 150,
      "cache_read_cost_per_token": 0.0000375,
      "cache_read_cost_per_million": 37.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o",
      "model_slug": "azure/gpt-4o",
      "model_name": "GPT-4o",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 0.00000125,
      "cache_read_cost_per_million": 1.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-2024-05-13",
      "model_slug": "azure/gpt-4o-2024-05-13",
      "model_name": "GPT-4o (May 2024)",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-2024-08-06",
      "model_slug": "azure/gpt-4o-2024-08-06",
      "model_name": "GPT-4o (Aug 2024)",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 0.00000125,
      "cache_read_cost_per_million": 1.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-2024-11-20",
      "model_slug": "azure/gpt-4o-2024-11-20",
      "model_name": "GPT-4o (Nov 2024)",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000275,
      "input_cost_per_million": 2.75,
      "output_cost_per_token": 0.000011,
      "output_cost_per_million": 11,
      "cache_read_cost_per_token": 0.00000125,
      "cache_read_cost_per_million": 1.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-audio-preview-2024-12-17",
      "model_slug": "azure/gpt-4o-audio-preview-2024-12-17",
      "model_name": "GPT 4o Audio Preview 2024 12 17",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-mini",
      "model_slug": "azure/gpt-4o-mini",
      "model_name": "GPT-4o mini",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.65e-7,
      "input_cost_per_million": 0.165,
      "output_cost_per_token": 6.6e-7,
      "output_cost_per_million": 0.66,
      "cache_read_cost_per_token": 7.5e-8,
      "cache_read_cost_per_million": 0.075,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-mini-2024-07-18",
      "model_slug": "azure/gpt-4o-mini-2024-07-18",
      "model_name": "GPT-4o mini (Jul 2024)",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.65e-7,
      "input_cost_per_million": 0.165,
      "output_cost_per_token": 6.6e-7,
      "output_cost_per_million": 0.66,
      "cache_read_cost_per_token": 7.5e-8,
      "cache_read_cost_per_million": 0.075,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-mini-audio-preview-2024-12-17",
      "model_slug": "azure/gpt-4o-mini-audio-preview-2024-12-17",
      "model_name": "GPT 4o Mini Audio Preview 2024 12 17",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-mini-realtime-preview-2024-12-17",
      "model_slug": "azure/gpt-4o-mini-realtime-preview-2024-12-17",
      "model_name": "GPT 4o Mini Realtime Preview 2024 12 17",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 0.0000024,
      "output_cost_per_million": 2.4,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-mini-transcribe",
      "model_slug": "azure/gpt-4o-mini-transcribe",
      "model_name": "GPT 4o Mini Transcribe",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-mini-tts",
      "model_slug": "azure/gpt-4o-mini-tts",
      "model_name": "GPT 4o Mini Tts",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-realtime-preview-2024-10-01",
      "model_slug": "azure/gpt-4o-realtime-preview-2024-10-01",
      "model_name": "GPT 4o Realtime Preview 2024 10 01",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.00002,
      "output_cost_per_million": 20,
      "cache_read_cost_per_token": 0.0000025,
      "cache_read_cost_per_million": 2.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-realtime-preview-2024-12-17",
      "model_slug": "azure/gpt-4o-realtime-preview-2024-12-17",
      "model_name": "GPT 4o Realtime Preview 2024 12 17",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.00002,
      "output_cost_per_million": 20,
      "cache_read_cost_per_token": 0.0000025,
      "cache_read_cost_per_million": 2.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-transcribe",
      "model_slug": "azure/gpt-4o-transcribe",
      "model_name": "GPT 4o Transcribe",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 16000,
      "max_output_tokens": 2000,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-image-1",
      "model_slug": "azure/gpt-image-1",
      "model_name": "GPT Image 1",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "hd/1024-x-1024/dall-e-3",
      "model_slug": "azure/hd/1024-x-1024/dall-e-3",
      "model_name": "Dall E 3 | 1024-x-1024 | hd",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "hd/1024-x-1792/dall-e-3",
      "model_slug": "azure/hd/1024-x-1792/dall-e-3",
      "model_name": "Dall E 3 | 1024-x-1792 | hd",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "hd/1792-x-1024/dall-e-3",
      "model_slug": "azure/hd/1792-x-1024/dall-e-3",
      "model_name": "Dall E 3 | 1792-x-1024 | hd",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "high/1024-x-1024/gpt-image-1",
      "model_slug": "azure/high/1024-x-1024/gpt-image-1",
      "model_name": "Gpt Image 1 | 1024-x-1024 | high",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "high/1024-x-1536/gpt-image-1",
      "model_slug": "azure/high/1024-x-1536/gpt-image-1",
      "model_name": "Gpt Image 1 | 1024-x-1536 | high",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "high/1536-x-1024/gpt-image-1",
      "model_slug": "azure/high/1536-x-1024/gpt-image-1",
      "model_name": "Gpt Image 1 | 1536-x-1024 | high",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "low/1024-x-1024/gpt-image-1",
      "model_slug": "azure/low/1024-x-1024/gpt-image-1",
      "model_name": "Gpt Image 1 | 1024-x-1024 | low",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "low/1024-x-1536/gpt-image-1",
      "model_slug": "azure/low/1024-x-1536/gpt-image-1",
      "model_name": "Gpt Image 1 | 1024-x-1536 | low",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "low/1536-x-1024/gpt-image-1",
      "model_slug": "azure/low/1536-x-1024/gpt-image-1",
      "model_name": "Gpt Image 1 | 1536-x-1024 | low",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "medium/1024-x-1024/gpt-image-1",
      "model_slug": "azure/medium/1024-x-1024/gpt-image-1",
      "model_name": "Gpt Image 1 | 1024-x-1024 | medium",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "medium/1024-x-1536/gpt-image-1",
      "model_slug": "azure/medium/1024-x-1536/gpt-image-1",
      "model_name": "Gpt Image 1 | 1024-x-1536 | medium",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "medium/1536-x-1024/gpt-image-1",
      "model_slug": "azure/medium/1536-x-1024/gpt-image-1",
      "model_name": "Gpt Image 1 | 1536-x-1024 | medium",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "o1",
      "model_slug": "azure/o1",
      "model_name": "o1",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.00006,
      "output_cost_per_million": 60,
      "cache_read_cost_per_token": 0.0000075,
      "cache_read_cost_per_million": 7.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o1-2024-12-17",
      "model_slug": "azure/o1-2024-12-17",
      "model_name": "O1 2024 12 17",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.00006,
      "output_cost_per_million": 60,
      "cache_read_cost_per_token": 0.0000075,
      "cache_read_cost_per_million": 7.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o1-mini",
      "model_slug": "azure/o1-mini",
      "model_name": "o1 mini",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_million": 1.21,
      "output_cost_per_token": 0.00000484,
      "output_cost_per_million": 4.84,
      "cache_read_cost_per_token": 6.05e-7,
      "cache_read_cost_per_million": 0.605,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o1-mini-2024-09-12",
      "model_slug": "azure/o1-mini-2024-09-12",
      "model_name": "O1 Mini 2024 09 12",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.0000011,
      "input_cost_per_million": 1.1,
      "output_cost_per_token": 0.0000044,
      "output_cost_per_million": 4.4,
      "cache_read_cost_per_token": 5.5e-7,
      "cache_read_cost_per_million": 0.55,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o1-preview",
      "model_slug": "azure/o1-preview",
      "model_name": "o1 Preview",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.00006,
      "output_cost_per_million": 60,
      "cache_read_cost_per_token": 0.0000075,
      "cache_read_cost_per_million": 7.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o1-preview-2024-09-12",
      "model_slug": "azure/o1-preview-2024-09-12",
      "model_name": "O1 Preview 2024 09 12",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.00006,
      "output_cost_per_million": 60,
      "cache_read_cost_per_token": 0.0000075,
      "cache_read_cost_per_million": 7.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o3",
      "model_slug": "azure/o3",
      "model_name": "o3",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": 5e-7,
      "cache_read_cost_per_million": 0.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o3-2025-04-16",
      "model_slug": "azure/o3-2025-04-16",
      "model_name": "O3 2025 04 16",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00004,
      "output_cost_per_million": 40,
      "cache_read_cost_per_token": 0.0000025,
      "cache_read_cost_per_million": 2.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o3-deep-research",
      "model_slug": "azure/o3-deep-research",
      "model_name": "O3 Deep Research",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00004,
      "output_cost_per_million": 40,
      "cache_read_cost_per_token": 0.0000025,
      "cache_read_cost_per_million": 2.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o3-mini",
      "model_slug": "azure/o3-mini",
      "model_name": "o3 mini",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000011,
      "input_cost_per_million": 1.1,
      "output_cost_per_token": 0.0000044,
      "output_cost_per_million": 4.4,
      "cache_read_cost_per_token": 5.5e-7,
      "cache_read_cost_per_million": 0.55,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o3-mini-2025-01-31",
      "model_slug": "azure/o3-mini-2025-01-31",
      "model_name": "O3 Mini 2025 01 31",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000011,
      "input_cost_per_million": 1.1,
      "output_cost_per_token": 0.0000044,
      "output_cost_per_million": 4.4,
      "cache_read_cost_per_token": 5.5e-7,
      "cache_read_cost_per_million": 0.55,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o3-pro",
      "model_slug": "azure/o3-pro",
      "model_name": "o3 Pro",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.00002,
      "input_cost_per_million": 20,
      "output_cost_per_token": 0.00008,
      "output_cost_per_million": 80,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o3-pro-2025-06-10",
      "model_slug": "azure/o3-pro-2025-06-10",
      "model_name": "O3 Pro 2025 06 10",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.00002,
      "input_cost_per_million": 20,
      "output_cost_per_token": 0.00008,
      "output_cost_per_million": 80,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o4-mini",
      "model_slug": "azure/o4-mini",
      "model_name": "o4 mini",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000011,
      "input_cost_per_million": 1.1,
      "output_cost_per_token": 0.0000044,
      "output_cost_per_million": 4.4,
      "cache_read_cost_per_token": 2.75e-7,
      "cache_read_cost_per_million": 0.275,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o4-mini-2025-04-16",
      "model_slug": "azure/o4-mini-2025-04-16",
      "model_name": "O4 Mini 2025 04 16",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000011,
      "input_cost_per_million": 1.1,
      "output_cost_per_token": 0.0000044,
      "output_cost_per_million": 4.4,
      "cache_read_cost_per_token": 2.75e-7,
      "cache_read_cost_per_million": 0.275,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "standard/1024-x-1024/dall-e-2",
      "model_slug": "azure/standard/1024-x-1024/dall-e-2",
      "model_name": "Dall E 2 | 1024-x-1024 | standard",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "standard/1024-x-1024/dall-e-3",
      "model_slug": "azure/standard/1024-x-1024/dall-e-3",
      "model_name": "Dall E 3 | 1024-x-1024 | standard",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "standard/1024-x-1792/dall-e-3",
      "model_slug": "azure/standard/1024-x-1792/dall-e-3",
      "model_name": "Dall E 3 | 1024-x-1792 | standard",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "standard/1792-x-1024/dall-e-3",
      "model_slug": "azure/standard/1792-x-1024/dall-e-3",
      "model_name": "Dall E 3 | 1792-x-1024 | standard",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "text-embedding-3-large",
      "model_slug": "azure/text-embedding-3-large",
      "model_name": "Text Embedding 3 Large",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 8191,
      "max_output_tokens": null,
      "input_cost_per_token": 1.3e-7,
      "input_cost_per_million": 0.13,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "text-embedding-3-small",
      "model_slug": "azure/text-embedding-3-small",
      "model_name": "Text Embedding 3 Small",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 8191,
      "max_output_tokens": null,
      "input_cost_per_token": 2e-8,
      "input_cost_per_million": 0.02,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "text-embedding-ada-002",
      "model_slug": "azure/text-embedding-ada-002",
      "model_name": "Text Embedding Ada 002",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 8191,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "tts-1",
      "model_slug": "azure/tts-1",
      "model_name": "Tts 1",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "tts-1-hd",
      "model_slug": "azure/tts-1-hd",
      "model_name": "Tts 1 Hd",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "us/gpt-4o-2024-08-06",
      "model_slug": "azure/us/gpt-4o-2024-08-06",
      "model_name": "GPT 4o (Aug 2024) | us",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000275,
      "input_cost_per_million": 2.75,
      "output_cost_per_token": 0.000011,
      "output_cost_per_million": 11,
      "cache_read_cost_per_token": 0.000001375,
      "cache_read_cost_per_million": 1.375,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us/gpt-4o-2024-11-20",
      "model_slug": "azure/us/gpt-4o-2024-11-20",
      "model_name": "GPT 4o (Nov 2024) | us",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000275,
      "input_cost_per_million": 2.75,
      "output_cost_per_token": 0.000011,
      "output_cost_per_million": 11,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": 0.00000138,
      "cache_write_cost_per_million": 1.38,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us/gpt-4o-mini-2024-07-18",
      "model_slug": "azure/us/gpt-4o-mini-2024-07-18",
      "model_name": "GPT 4o mini (Jul 2024) | us",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.65e-7,
      "input_cost_per_million": 0.165,
      "output_cost_per_token": 6.6e-7,
      "output_cost_per_million": 0.66,
      "cache_read_cost_per_token": 8.3e-8,
      "cache_read_cost_per_million": 0.083,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us/gpt-4o-mini-realtime-preview-2024-12-17",
      "model_slug": "azure/us/gpt-4o-mini-realtime-preview-2024-12-17",
      "model_name": "Gpt 4o Mini Realtime Preview 2024 12 17 | us",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6.6e-7,
      "input_cost_per_million": 0.66,
      "output_cost_per_token": 0.00000264,
      "output_cost_per_million": 2.64,
      "cache_read_cost_per_token": 3.3e-7,
      "cache_read_cost_per_million": 0.33,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us/gpt-4o-realtime-preview-2024-10-01",
      "model_slug": "azure/us/gpt-4o-realtime-preview-2024-10-01",
      "model_name": "Gpt 4o Realtime Preview 2024 10 01 | us",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000055,
      "input_cost_per_million": 5.5,
      "output_cost_per_token": 0.000022,
      "output_cost_per_million": 22,
      "cache_read_cost_per_token": 0.00000275,
      "cache_read_cost_per_million": 2.75,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us/gpt-4o-realtime-preview-2024-12-17",
      "model_slug": "azure/us/gpt-4o-realtime-preview-2024-12-17",
      "model_name": "Gpt 4o Realtime Preview 2024 12 17 | us",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000055,
      "input_cost_per_million": 5.5,
      "output_cost_per_token": 0.000022,
      "output_cost_per_million": 22,
      "cache_read_cost_per_token": 0.00000275,
      "cache_read_cost_per_million": 2.75,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us/o1-2024-12-17",
      "model_slug": "azure/us/o1-2024-12-17",
      "model_name": "O1 2024 12 17 | us",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000165,
      "input_cost_per_million": 16.5,
      "output_cost_per_token": 0.000066,
      "output_cost_per_million": 66,
      "cache_read_cost_per_token": 0.00000825,
      "cache_read_cost_per_million": 8.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us/o1-mini-2024-09-12",
      "model_slug": "azure/us/o1-mini-2024-09-12",
      "model_name": "O1 Mini 2024 09 12 | us",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_million": 1.21,
      "output_cost_per_token": 0.00000484,
      "output_cost_per_million": 4.84,
      "cache_read_cost_per_token": 6.05e-7,
      "cache_read_cost_per_million": 0.605,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us/o1-preview-2024-09-12",
      "model_slug": "azure/us/o1-preview-2024-09-12",
      "model_name": "O1 Preview 2024 09 12 | us",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.0000165,
      "input_cost_per_million": 16.5,
      "output_cost_per_token": 0.000066,
      "output_cost_per_million": 66,
      "cache_read_cost_per_token": 0.00000825,
      "cache_read_cost_per_million": 8.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us/o3-mini-2025-01-31",
      "model_slug": "azure/us/o3-mini-2025-01-31",
      "model_name": "O3 Mini 2025 01 31 | us",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.00000121,
      "input_cost_per_million": 1.21,
      "output_cost_per_token": 0.00000484,
      "output_cost_per_million": 4.84,
      "cache_read_cost_per_token": 6.05e-7,
      "cache_read_cost_per_million": 0.605,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "whisper-1",
      "model_slug": "azure/whisper-1",
      "model_name": "Whisper 1",
      "provider_id": "azure",
      "provider_name": "Microsoft Azure",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    }
  ],
  "bedrock": [
    {
      "model_id": "*/1-month-commitment/cohere.command-light-text-v14",
      "model_slug": "bedrock/*/1-month-commitment/cohere.command-light-text-v14",
      "model_name": "Cohere.command Light Text V14 | 1-month-commitment | *",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "*/1-month-commitment/cohere.command-text-v14",
      "model_slug": "bedrock/*/1-month-commitment/cohere.command-text-v14",
      "model_name": "Cohere.command Text V14 | 1-month-commitment | *",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "*/6-month-commitment/cohere.command-light-text-v14",
      "model_slug": "bedrock/*/6-month-commitment/cohere.command-light-text-v14",
      "model_name": "Cohere.command Light Text V14 | 6-month-commitment | *",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "*/6-month-commitment/cohere.command-text-v14",
      "model_slug": "bedrock/*/6-month-commitment/cohere.command-text-v14",
      "model_name": "Cohere.command Text V14 | 6-month-commitment | *",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0",
      "model_slug": "1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0",
      "model_name": "Amazon.nova Canvas V1:0 | bedrock | 50-steps | 1024-x-1024",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 2600,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1",
      "model_slug": "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1",
      "model_name": "Stability.stable Diffusion Xl V1 | 50-steps | 1024-x-1024",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 77,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1",
      "model_slug": "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1",
      "model_name": "Stability.stable Diffusion Xl V1 | max-steps | 1024-x-1024",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 77,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "512-x-512/50-steps/stability.stable-diffusion-xl-v0",
      "model_slug": "512-x-512/50-steps/stability.stable-diffusion-xl-v0",
      "model_name": "Stability.stable Diffusion Xl V0 | 50-steps | 512-x-512",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 77,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "512-x-512/max-steps/stability.stable-diffusion-xl-v0",
      "model_slug": "512-x-512/max-steps/stability.stable-diffusion-xl-v0",
      "model_name": "Stability.stable Diffusion Xl V0 | max-steps | 512-x-512",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 77,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "ai21.j2-mid-v1",
      "model_slug": "ai21.j2-mid-v1",
      "model_name": "Ai21.j2 Mid V1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8191,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000125,
      "input_cost_per_million": 12.5,
      "output_cost_per_token": 0.0000125,
      "output_cost_per_million": 12.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ai21.j2-ultra-v1",
      "model_slug": "ai21.j2-ultra-v1",
      "model_name": "Ai21.j2 Ultra V1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8191,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000188,
      "input_cost_per_million": 18.8,
      "output_cost_per_token": 0.0000188,
      "output_cost_per_million": 18.8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ai21.jamba-1-5-large-v1:0",
      "model_slug": "ai21.jamba-1-5-large-v1:0",
      "model_name": "Ai21.jamba 1 5 Large V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ai21.jamba-1-5-mini-v1:0",
      "model_slug": "ai21.jamba-1-5-mini-v1:0",
      "model_name": "Ai21.jamba 1 5 Mini V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ai21.jamba-instruct-v1:0",
      "model_slug": "ai21.jamba-instruct-v1:0",
      "model_name": "Ai21.jamba Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 70000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 7e-7,
      "output_cost_per_million": 0.7,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "amazon.nova-lite-v1:0",
      "model_slug": "amazon.nova-lite-v1:0",
      "model_name": "Amazon.nova Lite V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 6e-8,
      "input_cost_per_million": 0.06,
      "output_cost_per_token": 2.4e-7,
      "output_cost_per_million": 0.24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "amazon.nova-micro-v1:0",
      "model_slug": "amazon.nova-micro-v1:0",
      "model_name": "Amazon.nova Micro V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 3.5e-8,
      "input_cost_per_million": 0.035,
      "output_cost_per_token": 1.4e-7,
      "output_cost_per_million": 0.14,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "amazon.nova-pro-v1:0",
      "model_slug": "amazon.nova-pro-v1:0",
      "model_name": "Amazon.nova Pro V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 8e-7,
      "input_cost_per_million": 0.7999999999999999,
      "output_cost_per_token": 0.0000032,
      "output_cost_per_million": 3.1999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "amazon.rerank-v1:0",
      "model_slug": "amazon.rerank-v1:0",
      "model_name": "Amazon.rerank V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    },
    {
      "model_id": "amazon.titan-embed-image-v1",
      "model_slug": "amazon.titan-embed-image-v1",
      "model_name": "Amazon.titan Embed Image V1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128,
      "max_output_tokens": null,
      "input_cost_per_token": 8e-7,
      "input_cost_per_million": 0.7999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "amazon.titan-embed-text-v1",
      "model_slug": "amazon.titan-embed-text-v1",
      "model_name": "Amazon.titan Embed Text V1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "amazon.titan-embed-text-v2:0",
      "model_slug": "amazon.titan-embed-text-v2:0",
      "model_name": "Amazon.titan Embed Text V2:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": null,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "amazon.titan-text-express-v1",
      "model_slug": "amazon.titan-text-express-v1",
      "model_name": "Amazon.titan Text Express V1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 42000,
      "max_output_tokens": 8000,
      "input_cost_per_token": 0.0000013,
      "input_cost_per_million": 1.3,
      "output_cost_per_token": 0.0000017,
      "output_cost_per_million": 1.7,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "amazon.titan-text-lite-v1",
      "model_slug": "amazon.titan-text-lite-v1",
      "model_name": "Amazon.titan Text Lite V1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 42000,
      "max_output_tokens": 4000,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "amazon.titan-text-premier-v1:0",
      "model_slug": "amazon.titan-text-premier-v1:0",
      "model_name": "Amazon.titan Text Premier V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 42000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-3-5-haiku-20241022-v1:0",
      "model_slug": "anthropic.claude-3-5-haiku-20241022-v1:0",
      "model_name": "Anthropic.claude 3 5 Haiku 20241022 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 8e-7,
      "input_cost_per_million": 0.7999999999999999,
      "output_cost_per_token": 0.000004,
      "output_cost_per_million": 4,
      "cache_read_cost_per_token": 8e-8,
      "cache_read_cost_per_million": 0.08,
      "cache_write_cost_per_token": 0.000001,
      "cache_write_cost_per_million": 1,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-3-5-sonnet-20240620-v1:0",
      "model_slug": "anthropic.claude-3-5-sonnet-20240620-v1:0",
      "model_name": "Anthropic.claude 3 5 Sonnet 20240620 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-3-5-sonnet-20241022-v2:0",
      "model_slug": "anthropic.claude-3-5-sonnet-20241022-v2:0",
      "model_name": "Anthropic.claude 3 5 Sonnet 20241022 V2:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-3-7-sonnet-20250219-v1:0",
      "model_slug": "anthropic.claude-3-7-sonnet-20250219-v1:0",
      "model_name": "Anthropic.claude 3 7 Sonnet 20250219 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-3-haiku-20240307-v1:0",
      "model_slug": "anthropic.claude-3-haiku-20240307-v1:0",
      "model_name": "Anthropic.claude 3 Haiku 20240307 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 0.00000125,
      "output_cost_per_million": 1.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-3-opus-20240229-v1:0",
      "model_slug": "anthropic.claude-3-opus-20240229-v1:0",
      "model_name": "Anthropic.claude 3 Opus 20240229 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-3-sonnet-20240229-v1:0",
      "model_slug": "anthropic.claude-3-sonnet-20240229-v1:0",
      "model_name": "Anthropic.claude 3 Sonnet 20240229 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-instant-v1",
      "model_slug": "anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 8e-7,
      "input_cost_per_million": 0.7999999999999999,
      "output_cost_per_token": 0.0000024,
      "output_cost_per_million": 2.4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-opus-4-20250514-v1:0",
      "model_slug": "anthropic.claude-opus-4-20250514-v1:0",
      "model_name": "Anthropic.claude Opus 4 20250514 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": 0.0000015,
      "cache_read_cost_per_million": 1.5,
      "cache_write_cost_per_token": 0.00001875,
      "cache_write_cost_per_million": 18.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-sonnet-4-20250514-v1:0",
      "model_slug": "anthropic.claude-sonnet-4-20250514-v1:0",
      "model_name": "Anthropic.claude Sonnet 4 20250514 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-v1",
      "model_slug": "anthropic.claude-v1",
      "model_name": "Anthropic.claude V1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-v2",
      "model_slug": "anthropic.claude-v2",
      "model_name": "Anthropic.claude V2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "anthropic.claude-v2:1",
      "model_slug": "anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1",
      "model_slug": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1 | 1-month-commitment | ap-northeast-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-northeast-1/1-month-commitment/anthropic.claude-v1",
      "model_slug": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1",
      "model_name": "Anthropic.claude V1 | 1-month-commitment | ap-northeast-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-northeast-1/1-month-commitment/anthropic.claude-v2",
      "model_slug": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2",
      "model_name": "Anthropic.claude V2 | 1-month-commitment | ap-northeast-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-northeast-1/1-month-commitment/anthropic.claude-v2:1",
      "model_slug": "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1 | 1-month-commitment | ap-northeast-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1",
      "model_slug": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1 | 6-month-commitment | ap-northeast-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-northeast-1/6-month-commitment/anthropic.claude-v1",
      "model_slug": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1",
      "model_name": "Anthropic.claude V1 | 6-month-commitment | ap-northeast-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-northeast-1/6-month-commitment/anthropic.claude-v2",
      "model_slug": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2",
      "model_name": "Anthropic.claude V2 | 6-month-commitment | ap-northeast-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-northeast-1/6-month-commitment/anthropic.claude-v2:1",
      "model_slug": "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1 | 6-month-commitment | ap-northeast-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-northeast-1/anthropic.claude-instant-v1",
      "model_slug": "bedrock/ap-northeast-1/anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1 | ap-northeast-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000223,
      "input_cost_per_million": 2.23,
      "output_cost_per_token": 0.00000755,
      "output_cost_per_million": 7.55,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-northeast-1/anthropic.claude-v1",
      "model_slug": "bedrock/ap-northeast-1/anthropic.claude-v1",
      "model_name": "Anthropic.claude V1 | ap-northeast-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-northeast-1/anthropic.claude-v2",
      "model_slug": "bedrock/ap-northeast-1/anthropic.claude-v2",
      "model_name": "Anthropic.claude V2 | ap-northeast-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-northeast-1/anthropic.claude-v2:1",
      "model_slug": "bedrock/ap-northeast-1/anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1 | ap-northeast-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-south-1/meta.llama3-70b-instruct-v1:0",
      "model_slug": "bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0",
      "model_name": "Meta.llama3 70b Instruct V1:0 | ap-south-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000318,
      "input_cost_per_million": 3.18,
      "output_cost_per_token": 0.0000042,
      "output_cost_per_million": 4.199999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ap-south-1/meta.llama3-8b-instruct-v1:0",
      "model_slug": "bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0",
      "model_name": "Meta.llama3 8b Instruct V1:0 | ap-south-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.6e-7,
      "input_cost_per_million": 0.36,
      "output_cost_per_token": 7.2e-7,
      "output_cost_per_million": 0.72,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "apac.amazon.nova-lite-v1:0",
      "model_slug": "apac.amazon.nova-lite-v1:0",
      "model_name": "Apac.amazon.nova Lite V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 6.3e-8,
      "input_cost_per_million": 0.063,
      "output_cost_per_token": 2.52e-7,
      "output_cost_per_million": 0.252,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "apac.amazon.nova-micro-v1:0",
      "model_slug": "apac.amazon.nova-micro-v1:0",
      "model_name": "Apac.amazon.nova Micro V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 3.7e-8,
      "input_cost_per_million": 0.037,
      "output_cost_per_token": 1.48e-7,
      "output_cost_per_million": 0.148,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "apac.amazon.nova-pro-v1:0",
      "model_slug": "apac.amazon.nova-pro-v1:0",
      "model_name": "Apac.amazon.nova Pro V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 8.4e-7,
      "input_cost_per_million": 0.84,
      "output_cost_per_token": 0.00000336,
      "output_cost_per_million": 3.36,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "apac.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "model_slug": "apac.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "model_name": "Apac.anthropic.claude 3 5 Sonnet 20240620 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "apac.anthropic.claude-3-5-sonnet-20241022-v2:0",
      "model_slug": "apac.anthropic.claude-3-5-sonnet-20241022-v2:0",
      "model_name": "Apac.anthropic.claude 3 5 Sonnet 20241022 V2:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "apac.anthropic.claude-3-haiku-20240307-v1:0",
      "model_slug": "apac.anthropic.claude-3-haiku-20240307-v1:0",
      "model_name": "Apac.anthropic.claude 3 Haiku 20240307 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 0.00000125,
      "output_cost_per_million": 1.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "apac.anthropic.claude-3-sonnet-20240229-v1:0",
      "model_slug": "apac.anthropic.claude-3-sonnet-20240229-v1:0",
      "model_name": "Apac.anthropic.claude 3 Sonnet 20240229 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "apac.anthropic.claude-sonnet-4-20250514-v1:0",
      "model_slug": "apac.anthropic.claude-sonnet-4-20250514-v1:0",
      "model_name": "Apac.anthropic.claude Sonnet 4 20250514 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ca-central-1/meta.llama3-70b-instruct-v1:0",
      "model_slug": "bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0",
      "model_name": "Meta.llama3 70b Instruct V1:0 | ca-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000305,
      "input_cost_per_million": 3.05,
      "output_cost_per_token": 0.00000403,
      "output_cost_per_million": 4.03,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ca-central-1/meta.llama3-8b-instruct-v1:0",
      "model_slug": "bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0",
      "model_name": "Meta.llama3 8b Instruct V1:0 | ca-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_million": 0.35,
      "output_cost_per_token": 6.9e-7,
      "output_cost_per_million": 0.69,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "cohere.command-light-text-v14",
      "model_slug": "cohere.command-light-text-v14",
      "model_name": "Cohere.command Light Text V14",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "cohere.command-r-plus-v1:0",
      "model_slug": "cohere.command-r-plus-v1:0",
      "model_name": "Cohere.command R Plus V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "cohere.command-r-v1:0",
      "model_slug": "cohere.command-r-v1:0",
      "model_name": "Cohere.command R V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "cohere.command-text-v14",
      "model_slug": "cohere.command-text-v14",
      "model_name": "Cohere.command Text V14",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "input_cost_per_million": 1.5,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "cohere.embed-english-v3",
      "model_slug": "cohere.embed-english-v3",
      "model_name": "Cohere.embed English V3",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 512,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "cohere.embed-multilingual-v3",
      "model_slug": "cohere.embed-multilingual-v3",
      "model_name": "Cohere.embed Multilingual V3",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 512,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "cohere.rerank-v3-5:0",
      "model_slug": "cohere.rerank-v3-5:0",
      "model_name": "Cohere.rerank V3 5:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    },
    {
      "model_id": "eu-central-1/1-month-commitment/anthropic.claude-instant-v1",
      "model_slug": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1 | 1-month-commitment | eu-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-central-1/1-month-commitment/anthropic.claude-v1",
      "model_slug": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1",
      "model_name": "Anthropic.claude V1 | 1-month-commitment | eu-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-central-1/1-month-commitment/anthropic.claude-v2",
      "model_slug": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2",
      "model_name": "Anthropic.claude V2 | 1-month-commitment | eu-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-central-1/1-month-commitment/anthropic.claude-v2:1",
      "model_slug": "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1 | 1-month-commitment | eu-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-central-1/6-month-commitment/anthropic.claude-instant-v1",
      "model_slug": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1 | 6-month-commitment | eu-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-central-1/6-month-commitment/anthropic.claude-v1",
      "model_slug": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1",
      "model_name": "Anthropic.claude V1 | 6-month-commitment | eu-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-central-1/6-month-commitment/anthropic.claude-v2",
      "model_slug": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2",
      "model_name": "Anthropic.claude V2 | 6-month-commitment | eu-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-central-1/6-month-commitment/anthropic.claude-v2:1",
      "model_slug": "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1 | 6-month-commitment | eu-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-central-1/anthropic.claude-instant-v1",
      "model_slug": "bedrock/eu-central-1/anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1 | eu-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000248,
      "input_cost_per_million": 2.48,
      "output_cost_per_token": 0.00000838,
      "output_cost_per_million": 8.379999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-central-1/anthropic.claude-v1",
      "model_slug": "bedrock/eu-central-1/anthropic.claude-v1",
      "model_name": "Anthropic.claude V1 | eu-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-central-1/anthropic.claude-v2",
      "model_slug": "bedrock/eu-central-1/anthropic.claude-v2",
      "model_name": "Anthropic.claude V2 | eu-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-central-1/anthropic.claude-v2:1",
      "model_slug": "bedrock/eu-central-1/anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1 | eu-central-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-west-1/meta.llama3-70b-instruct-v1:0",
      "model_slug": "bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0",
      "model_name": "Meta.llama3 70b Instruct V1:0 | eu-west-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000286,
      "input_cost_per_million": 2.8600000000000003,
      "output_cost_per_token": 0.00000378,
      "output_cost_per_million": 3.78,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-west-1/meta.llama3-8b-instruct-v1:0",
      "model_slug": "bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0",
      "model_name": "Meta.llama3 8b Instruct V1:0 | eu-west-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.2e-7,
      "input_cost_per_million": 0.32,
      "output_cost_per_token": 6.5e-7,
      "output_cost_per_million": 0.65,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-west-2/meta.llama3-70b-instruct-v1:0",
      "model_slug": "bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0",
      "model_name": "Meta.llama3 70b Instruct V1:0 | eu-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000345,
      "input_cost_per_million": 3.45,
      "output_cost_per_token": 0.00000455,
      "output_cost_per_million": 4.55,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-west-2/meta.llama3-8b-instruct-v1:0",
      "model_slug": "bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0",
      "model_name": "Meta.llama3 8b Instruct V1:0 | eu-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.9e-7,
      "input_cost_per_million": 0.39,
      "output_cost_per_token": 7.8e-7,
      "output_cost_per_million": 0.78,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-west-3/mistral.mistral-7b-instruct-v0:2",
      "model_slug": "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2",
      "model_name": "Mistral.mistral 7b Instruct V0:2 | eu-west-3",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2.6e-7,
      "output_cost_per_million": 0.26,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-west-3/mistral.mistral-large-2402-v1:0",
      "model_slug": "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0",
      "model_name": "Mistral.mistral Large 2402 V1:0 | eu-west-3",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000104,
      "input_cost_per_million": 10.4,
      "output_cost_per_token": 0.0000312,
      "output_cost_per_million": 31.2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu-west-3/mistral.mixtral-8x7b-instruct-v0:1",
      "model_slug": "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1",
      "model_name": "Mistral.mixtral 8x7b Instruct V0:1 | eu-west-3",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 5.9e-7,
      "input_cost_per_million": 0.59,
      "output_cost_per_token": 9.1e-7,
      "output_cost_per_million": 0.9099999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.amazon.nova-lite-v1:0",
      "model_slug": "eu.amazon.nova-lite-v1:0",
      "model_name": "Eu.amazon.nova Lite V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 7.8e-8,
      "input_cost_per_million": 0.078,
      "output_cost_per_token": 3.12e-7,
      "output_cost_per_million": 0.312,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.amazon.nova-micro-v1:0",
      "model_slug": "eu.amazon.nova-micro-v1:0",
      "model_name": "Eu.amazon.nova Micro V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 4.6e-8,
      "input_cost_per_million": 0.046,
      "output_cost_per_token": 1.84e-7,
      "output_cost_per_million": 0.184,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.amazon.nova-pro-v1:0",
      "model_slug": "eu.amazon.nova-pro-v1:0",
      "model_name": "Eu.amazon.nova Pro V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 0.00000105,
      "input_cost_per_million": 1.0499999999999998,
      "output_cost_per_token": 0.0000042,
      "output_cost_per_million": 4.199999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.anthropic.claude-3-5-haiku-20241022-v1:0",
      "model_slug": "eu.anthropic.claude-3-5-haiku-20241022-v1:0",
      "model_name": "Eu.anthropic.claude 3 5 Haiku 20241022 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 0.00000125,
      "output_cost_per_million": 1.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "model_slug": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "model_name": "Eu.anthropic.claude 3 5 Sonnet 20240620 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.anthropic.claude-3-5-sonnet-20241022-v2:0",
      "model_slug": "eu.anthropic.claude-3-5-sonnet-20241022-v2:0",
      "model_name": "Eu.anthropic.claude 3 5 Sonnet 20241022 V2:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.anthropic.claude-3-7-sonnet-20250219-v1:0",
      "model_slug": "eu.anthropic.claude-3-7-sonnet-20250219-v1:0",
      "model_name": "Eu.anthropic.claude 3 7 Sonnet 20250219 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.anthropic.claude-3-haiku-20240307-v1:0",
      "model_slug": "eu.anthropic.claude-3-haiku-20240307-v1:0",
      "model_name": "Eu.anthropic.claude 3 Haiku 20240307 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 0.00000125,
      "output_cost_per_million": 1.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.anthropic.claude-3-opus-20240229-v1:0",
      "model_slug": "eu.anthropic.claude-3-opus-20240229-v1:0",
      "model_name": "Eu.anthropic.claude 3 Opus 20240229 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.anthropic.claude-3-sonnet-20240229-v1:0",
      "model_slug": "eu.anthropic.claude-3-sonnet-20240229-v1:0",
      "model_name": "Eu.anthropic.claude 3 Sonnet 20240229 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.anthropic.claude-opus-4-20250514-v1:0",
      "model_slug": "eu.anthropic.claude-opus-4-20250514-v1:0",
      "model_name": "Eu.anthropic.claude Opus 4 20250514 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": 0.0000015,
      "cache_read_cost_per_million": 1.5,
      "cache_write_cost_per_token": 0.00001875,
      "cache_write_cost_per_million": 18.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.anthropic.claude-sonnet-4-20250514-v1:0",
      "model_slug": "eu.anthropic.claude-sonnet-4-20250514-v1:0",
      "model_name": "Eu.anthropic.claude Sonnet 4 20250514 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.meta.llama3-2-1b-instruct-v1:0",
      "model_slug": "eu.meta.llama3-2-1b-instruct-v1:0",
      "model_name": "Eu.meta.llama3 2 1b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.3e-7,
      "input_cost_per_million": 0.13,
      "output_cost_per_token": 1.3e-7,
      "output_cost_per_million": 0.13,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.meta.llama3-2-3b-instruct-v1:0",
      "model_slug": "eu.meta.llama3-2-3b-instruct-v1:0",
      "model_name": "Eu.meta.llama3 2 3b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.9e-7,
      "input_cost_per_million": 0.19,
      "output_cost_per_token": 1.9e-7,
      "output_cost_per_million": 0.19,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "eu.mistral.pixtral-large-2502-v1:0",
      "model_slug": "eu.mistral.pixtral-large-2502-v1:0",
      "model_name": "Eu.mistral.pixtral Large 2502 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "invoke/anthropic.claude-3-5-sonnet-20240620-v1:0",
      "model_slug": "bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0",
      "model_name": "Anthropic.claude 3 5 Sonnet 20240620 V1:0 | invoke",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "max-x-max/50-steps/stability.stable-diffusion-xl-v0",
      "model_slug": "max-x-max/50-steps/stability.stable-diffusion-xl-v0",
      "model_name": "Stability.stable Diffusion Xl V0 | 50-steps | max-x-max",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 77,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "max-x-max/max-steps/stability.stable-diffusion-xl-v0",
      "model_slug": "max-x-max/max-steps/stability.stable-diffusion-xl-v0",
      "model_name": "Stability.stable Diffusion Xl V0 | max-steps | max-x-max",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 77,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama2-13b-chat-v1",
      "model_slug": "meta.llama2-13b-chat-v1",
      "model_name": "Meta.llama2 13b Chat V1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7.5e-7,
      "input_cost_per_million": 0.75,
      "output_cost_per_token": 0.000001,
      "output_cost_per_million": 1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama2-70b-chat-v1",
      "model_slug": "meta.llama2-70b-chat-v1",
      "model_name": "Meta.llama2 70b Chat V1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000195,
      "input_cost_per_million": 1.95,
      "output_cost_per_token": 0.00000256,
      "output_cost_per_million": 2.56,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama3-1-405b-instruct-v1:0",
      "model_slug": "meta.llama3-1-405b-instruct-v1:0",
      "model_name": "Meta.llama3 1 405b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000532,
      "input_cost_per_million": 5.32,
      "output_cost_per_token": 0.000016,
      "output_cost_per_million": 16,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama3-1-70b-instruct-v1:0",
      "model_slug": "meta.llama3-1-70b-instruct-v1:0",
      "model_name": "Meta.llama3 1 70b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 9.9e-7,
      "input_cost_per_million": 0.9900000000000001,
      "output_cost_per_token": 9.9e-7,
      "output_cost_per_million": 0.9900000000000001,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama3-1-8b-instruct-v1:0",
      "model_slug": "meta.llama3-1-8b-instruct-v1:0",
      "model_name": "Meta.llama3 1 8b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 2.2e-7,
      "input_cost_per_million": 0.22,
      "output_cost_per_token": 2.2e-7,
      "output_cost_per_million": 0.22,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama3-2-11b-instruct-v1:0",
      "model_slug": "meta.llama3-2-11b-instruct-v1:0",
      "model_name": "Meta.llama3 2 11b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_million": 0.35,
      "output_cost_per_token": 3.5e-7,
      "output_cost_per_million": 0.35,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama3-2-1b-instruct-v1:0",
      "model_slug": "meta.llama3-2-1b-instruct-v1:0",
      "model_name": "Meta.llama3 2 1b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 1e-7,
      "output_cost_per_million": 0.09999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama3-2-3b-instruct-v1:0",
      "model_slug": "meta.llama3-2-3b-instruct-v1:0",
      "model_name": "Meta.llama3 2 3b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 1.5e-7,
      "output_cost_per_million": 0.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama3-2-90b-instruct-v1:0",
      "model_slug": "meta.llama3-2-90b-instruct-v1:0",
      "model_name": "Meta.llama3 2 90b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama3-3-70b-instruct-v1:0",
      "model_slug": "meta.llama3-3-70b-instruct-v1:0",
      "model_name": "Meta.llama3 3 70b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7.2e-7,
      "input_cost_per_million": 0.72,
      "output_cost_per_token": 7.2e-7,
      "output_cost_per_million": 0.72,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama3-70b-instruct-v1:0",
      "model_slug": "meta.llama3-70b-instruct-v1:0",
      "model_name": "Meta.llama3 70b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000265,
      "input_cost_per_million": 2.65,
      "output_cost_per_token": 0.0000035,
      "output_cost_per_million": 3.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama3-8b-instruct-v1:0",
      "model_slug": "meta.llama3-8b-instruct-v1:0",
      "model_name": "Meta.llama3 8b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama4-maverick-17b-instruct-v1:0",
      "model_slug": "meta.llama4-maverick-17b-instruct-v1:0",
      "model_name": "Meta.llama4 Maverick 17b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.4e-7,
      "input_cost_per_million": 0.24,
      "output_cost_per_token": 9.7e-7,
      "output_cost_per_million": 0.9700000000000001,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta.llama4-scout-17b-instruct-v1:0",
      "model_slug": "meta.llama4-scout-17b-instruct-v1:0",
      "model_name": "Meta.llama4 Scout 17b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.7e-7,
      "input_cost_per_million": 0.16999999999999998,
      "output_cost_per_token": 6.6e-7,
      "output_cost_per_million": 0.66,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral.mistral-7b-instruct-v0:2",
      "model_slug": "mistral.mistral-7b-instruct-v0:2",
      "model_name": "Mistral.mistral 7b Instruct V0:2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral.mistral-large-2402-v1:0",
      "model_slug": "mistral.mistral-large-2402-v1:0",
      "model_name": "Mistral.mistral Large 2402 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral.mistral-large-2407-v1:0",
      "model_slug": "mistral.mistral-large-2407-v1:0",
      "model_name": "Mistral.mistral Large 2407 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000009,
      "output_cost_per_million": 9,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral.mistral-small-2402-v1:0",
      "model_slug": "mistral.mistral-small-2402-v1:0",
      "model_name": "Mistral.mistral Small 2402 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral.mixtral-8x7b-instruct-v0:1",
      "model_slug": "mistral.mixtral-8x7b-instruct-v0:1",
      "model_name": "Mistral.mixtral 8x7b Instruct V0:1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 4.5e-7,
      "input_cost_per_million": 0.44999999999999996,
      "output_cost_per_token": 7e-7,
      "output_cost_per_million": 0.7,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sa-east-1/meta.llama3-70b-instruct-v1:0",
      "model_slug": "bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0",
      "model_name": "Meta.llama3 70b Instruct V1:0 | sa-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000445,
      "input_cost_per_million": 4.45,
      "output_cost_per_token": 0.00000588,
      "output_cost_per_million": 5.88,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sa-east-1/meta.llama3-8b-instruct-v1:0",
      "model_slug": "bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0",
      "model_name": "Meta.llama3 8b Instruct V1:0 | sa-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.00000101,
      "output_cost_per_million": 1.01,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "stability.sd3-5-large-v1:0",
      "model_slug": "stability.sd3-5-large-v1:0",
      "model_name": "Stability.sd3 5 Large V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 77,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "stability.sd3-large-v1:0",
      "model_slug": "stability.sd3-large-v1:0",
      "model_name": "Stability.sd3 Large V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 77,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "stability.stable-image-core-v1:0",
      "model_slug": "stability.stable-image-core-v1:0",
      "model_name": "Stability.stable Image Core V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 77,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "stability.stable-image-core-v1:1",
      "model_slug": "stability.stable-image-core-v1:1",
      "model_name": "Stability.stable Image Core V1:1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 77,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "stability.stable-image-ultra-v1:0",
      "model_slug": "stability.stable-image-ultra-v1:0",
      "model_name": "Stability.stable Image Ultra V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 77,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "stability.stable-image-ultra-v1:1",
      "model_slug": "stability.stable-image-ultra-v1:1",
      "model_name": "Stability.stable Image Ultra V1:1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 77,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/1-month-commitment/anthropic.claude-instant-v1",
      "model_slug": "bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1 | 1-month-commitment | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/1-month-commitment/anthropic.claude-v1",
      "model_slug": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v1",
      "model_name": "Anthropic.claude V1 | 1-month-commitment | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/1-month-commitment/anthropic.claude-v2",
      "model_slug": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2",
      "model_name": "Anthropic.claude V2 | 1-month-commitment | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/1-month-commitment/anthropic.claude-v2:1",
      "model_slug": "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1 | 1-month-commitment | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/6-month-commitment/anthropic.claude-instant-v1",
      "model_slug": "bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1 | 6-month-commitment | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/6-month-commitment/anthropic.claude-v1",
      "model_slug": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v1",
      "model_name": "Anthropic.claude V1 | 6-month-commitment | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/6-month-commitment/anthropic.claude-v2",
      "model_slug": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2",
      "model_name": "Anthropic.claude V2 | 6-month-commitment | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/6-month-commitment/anthropic.claude-v2:1",
      "model_slug": "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1 | 6-month-commitment | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/anthropic.claude-instant-v1",
      "model_slug": "bedrock/us-east-1/anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1 | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 8e-7,
      "input_cost_per_million": 0.7999999999999999,
      "output_cost_per_token": 0.0000024,
      "output_cost_per_million": 2.4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/anthropic.claude-v1",
      "model_slug": "bedrock/us-east-1/anthropic.claude-v1",
      "model_name": "Anthropic.claude V1 | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/anthropic.claude-v2",
      "model_slug": "bedrock/us-east-1/anthropic.claude-v2",
      "model_name": "Anthropic.claude V2 | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/anthropic.claude-v2:1",
      "model_slug": "bedrock/us-east-1/anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1 | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/meta.llama3-70b-instruct-v1:0",
      "model_slug": "bedrock/us-east-1/meta.llama3-70b-instruct-v1:0",
      "model_name": "Meta.llama3 70b Instruct V1:0 | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000265,
      "input_cost_per_million": 2.65,
      "output_cost_per_token": 0.0000035,
      "output_cost_per_million": 3.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/meta.llama3-8b-instruct-v1:0",
      "model_slug": "bedrock/us-east-1/meta.llama3-8b-instruct-v1:0",
      "model_name": "Meta.llama3 8b Instruct V1:0 | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/mistral.mistral-7b-instruct-v0:2",
      "model_slug": "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2",
      "model_name": "Mistral.mistral 7b Instruct V0:2 | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/mistral.mistral-large-2402-v1:0",
      "model_slug": "bedrock/us-east-1/mistral.mistral-large-2402-v1:0",
      "model_name": "Mistral.mistral Large 2402 V1:0 | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-east-1/mistral.mixtral-8x7b-instruct-v0:1",
      "model_slug": "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1",
      "model_name": "Mistral.mixtral 8x7b Instruct V0:1 | us-east-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 4.5e-7,
      "input_cost_per_million": 0.44999999999999996,
      "output_cost_per_token": 7e-7,
      "output_cost_per_million": 0.7,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-1/meta.llama3-70b-instruct-v1:0",
      "model_slug": "bedrock/us-west-1/meta.llama3-70b-instruct-v1:0",
      "model_name": "Meta.llama3 70b Instruct V1:0 | us-west-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000265,
      "input_cost_per_million": 2.65,
      "output_cost_per_token": 0.0000035,
      "output_cost_per_million": 3.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-1/meta.llama3-8b-instruct-v1:0",
      "model_slug": "bedrock/us-west-1/meta.llama3-8b-instruct-v1:0",
      "model_name": "Meta.llama3 8b Instruct V1:0 | us-west-1",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/1-month-commitment/anthropic.claude-instant-v1",
      "model_slug": "bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1 | 1-month-commitment | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/1-month-commitment/anthropic.claude-v1",
      "model_slug": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v1",
      "model_name": "Anthropic.claude V1 | 1-month-commitment | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/1-month-commitment/anthropic.claude-v2",
      "model_slug": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2",
      "model_name": "Anthropic.claude V2 | 1-month-commitment | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/1-month-commitment/anthropic.claude-v2:1",
      "model_slug": "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1 | 1-month-commitment | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/6-month-commitment/anthropic.claude-instant-v1",
      "model_slug": "bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1 | 6-month-commitment | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/6-month-commitment/anthropic.claude-v1",
      "model_slug": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v1",
      "model_name": "Anthropic.claude V1 | 6-month-commitment | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/6-month-commitment/anthropic.claude-v2",
      "model_slug": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2",
      "model_name": "Anthropic.claude V2 | 6-month-commitment | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/6-month-commitment/anthropic.claude-v2:1",
      "model_slug": "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1 | 6-month-commitment | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/anthropic.claude-instant-v1",
      "model_slug": "bedrock/us-west-2/anthropic.claude-instant-v1",
      "model_name": "Anthropic.claude Instant V1 | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 8e-7,
      "input_cost_per_million": 0.7999999999999999,
      "output_cost_per_token": 0.0000024,
      "output_cost_per_million": 2.4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/anthropic.claude-v1",
      "model_slug": "bedrock/us-west-2/anthropic.claude-v1",
      "model_name": "Anthropic.claude V1 | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/anthropic.claude-v2",
      "model_slug": "bedrock/us-west-2/anthropic.claude-v2",
      "model_name": "Anthropic.claude V2 | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/anthropic.claude-v2:1",
      "model_slug": "bedrock/us-west-2/anthropic.claude-v2:1",
      "model_name": "Anthropic.claude V2:1 | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 100000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/mistral.mistral-7b-instruct-v0:2",
      "model_slug": "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2",
      "model_name": "Mistral.mistral 7b Instruct V0:2 | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/mistral.mistral-large-2402-v1:0",
      "model_slug": "bedrock/us-west-2/mistral.mistral-large-2402-v1:0",
      "model_name": "Mistral.mistral Large 2402 V1:0 | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us-west-2/mistral.mixtral-8x7b-instruct-v0:1",
      "model_slug": "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1",
      "model_name": "Mistral.mixtral 8x7b Instruct V0:1 | us-west-2",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 4.5e-7,
      "input_cost_per_million": 0.44999999999999996,
      "output_cost_per_token": 7e-7,
      "output_cost_per_million": 0.7,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.amazon.nova-lite-v1:0",
      "model_slug": "us.amazon.nova-lite-v1:0",
      "model_name": "Us.amazon.nova Lite V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 6e-8,
      "input_cost_per_million": 0.06,
      "output_cost_per_token": 2.4e-7,
      "output_cost_per_million": 0.24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.amazon.nova-micro-v1:0",
      "model_slug": "us.amazon.nova-micro-v1:0",
      "model_name": "Us.amazon.nova Micro V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 3.5e-8,
      "input_cost_per_million": 0.035,
      "output_cost_per_token": 1.4e-7,
      "output_cost_per_million": 0.14,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.amazon.nova-premier-v1:0",
      "model_slug": "us.amazon.nova-premier-v1:0",
      "model_name": "Us.amazon.nova Premier V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 1000000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.0000125,
      "output_cost_per_million": 12.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.amazon.nova-pro-v1:0",
      "model_slug": "us.amazon.nova-pro-v1:0",
      "model_name": "Us.amazon.nova Pro V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 300000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 8e-7,
      "input_cost_per_million": 0.7999999999999999,
      "output_cost_per_token": 0.0000032,
      "output_cost_per_million": 3.1999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
      "model_slug": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
      "model_name": "Us.anthropic.claude 3 5 Haiku 20241022 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 8e-7,
      "input_cost_per_million": 0.7999999999999999,
      "output_cost_per_token": 0.000004,
      "output_cost_per_million": 4,
      "cache_read_cost_per_token": 8e-8,
      "cache_read_cost_per_million": 0.08,
      "cache_write_cost_per_token": 0.000001,
      "cache_write_cost_per_million": 1,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "model_slug": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
      "model_name": "Us.anthropic.claude 3 5 Sonnet 20240620 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
      "model_slug": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
      "model_name": "Us.anthropic.claude 3 5 Sonnet 20241022 V2:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
      "model_slug": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
      "model_name": "Us.anthropic.claude 3 7 Sonnet 20250219 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.anthropic.claude-3-haiku-20240307-v1:0",
      "model_slug": "us.anthropic.claude-3-haiku-20240307-v1:0",
      "model_name": "Us.anthropic.claude 3 Haiku 20240307 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 0.00000125,
      "output_cost_per_million": 1.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.anthropic.claude-3-opus-20240229-v1:0",
      "model_slug": "us.anthropic.claude-3-opus-20240229-v1:0",
      "model_name": "Us.anthropic.claude 3 Opus 20240229 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.anthropic.claude-3-sonnet-20240229-v1:0",
      "model_slug": "us.anthropic.claude-3-sonnet-20240229-v1:0",
      "model_name": "Us.anthropic.claude 3 Sonnet 20240229 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.anthropic.claude-opus-4-20250514-v1:0",
      "model_slug": "us.anthropic.claude-opus-4-20250514-v1:0",
      "model_name": "Us.anthropic.claude Opus 4 20250514 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": 0.0000015,
      "cache_read_cost_per_million": 1.5,
      "cache_write_cost_per_token": 0.00001875,
      "cache_write_cost_per_million": 18.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.anthropic.claude-sonnet-4-20250514-v1:0",
      "model_slug": "us.anthropic.claude-sonnet-4-20250514-v1:0",
      "model_name": "Us.anthropic.claude Sonnet 4 20250514 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.deepseek.r1-v1:0",
      "model_slug": "us.deepseek.r1-v1:0",
      "model_name": "Us.deepseek.r1 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000135,
      "input_cost_per_million": 1.35,
      "output_cost_per_token": 0.0000054,
      "output_cost_per_million": 5.4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.meta.llama3-1-405b-instruct-v1:0",
      "model_slug": "us.meta.llama3-1-405b-instruct-v1:0",
      "model_name": "Us.meta.llama3 1 405b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00000532,
      "input_cost_per_million": 5.32,
      "output_cost_per_token": 0.000016,
      "output_cost_per_million": 16,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.meta.llama3-1-70b-instruct-v1:0",
      "model_slug": "us.meta.llama3-1-70b-instruct-v1:0",
      "model_name": "Us.meta.llama3 1 70b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 9.9e-7,
      "input_cost_per_million": 0.9900000000000001,
      "output_cost_per_token": 9.9e-7,
      "output_cost_per_million": 0.9900000000000001,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.meta.llama3-1-8b-instruct-v1:0",
      "model_slug": "us.meta.llama3-1-8b-instruct-v1:0",
      "model_name": "Us.meta.llama3 1 8b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 2.2e-7,
      "input_cost_per_million": 0.22,
      "output_cost_per_token": 2.2e-7,
      "output_cost_per_million": 0.22,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.meta.llama3-2-11b-instruct-v1:0",
      "model_slug": "us.meta.llama3-2-11b-instruct-v1:0",
      "model_name": "Us.meta.llama3 2 11b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_million": 0.35,
      "output_cost_per_token": 3.5e-7,
      "output_cost_per_million": 0.35,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.meta.llama3-2-1b-instruct-v1:0",
      "model_slug": "us.meta.llama3-2-1b-instruct-v1:0",
      "model_name": "Us.meta.llama3 2 1b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 1e-7,
      "output_cost_per_million": 0.09999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.meta.llama3-2-3b-instruct-v1:0",
      "model_slug": "us.meta.llama3-2-3b-instruct-v1:0",
      "model_name": "Us.meta.llama3 2 3b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 1.5e-7,
      "output_cost_per_million": 0.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.meta.llama3-2-90b-instruct-v1:0",
      "model_slug": "us.meta.llama3-2-90b-instruct-v1:0",
      "model_name": "Us.meta.llama3 2 90b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.meta.llama3-3-70b-instruct-v1:0",
      "model_slug": "us.meta.llama3-3-70b-instruct-v1:0",
      "model_name": "Us.meta.llama3 3 70b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7.2e-7,
      "input_cost_per_million": 0.72,
      "output_cost_per_token": 7.2e-7,
      "output_cost_per_million": 0.72,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.meta.llama4-maverick-17b-instruct-v1:0",
      "model_slug": "us.meta.llama4-maverick-17b-instruct-v1:0",
      "model_name": "Us.meta.llama4 Maverick 17b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.4e-7,
      "input_cost_per_million": 0.24,
      "output_cost_per_token": 9.7e-7,
      "output_cost_per_million": 0.9700000000000001,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.meta.llama4-scout-17b-instruct-v1:0",
      "model_slug": "us.meta.llama4-scout-17b-instruct-v1:0",
      "model_name": "Us.meta.llama4 Scout 17b Instruct V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.7e-7,
      "input_cost_per_million": 0.16999999999999998,
      "output_cost_per_token": 6.6e-7,
      "output_cost_per_million": 0.66,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "us.mistral.pixtral-large-2502-v1:0",
      "model_slug": "us.mistral.pixtral-large-2502-v1:0",
      "model_name": "Us.mistral.pixtral Large 2502 V1:0",
      "provider_id": "bedrock",
      "provider_name": "AWS Bedrock",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "cerebras": [
    {
      "model_id": "cerebras/llama-3.3-70b",
      "model_slug": "cerebras/llama-3.3-70b",
      "model_name": "Llama 3.3 70b | cerebras",
      "provider_id": "cerebras",
      "provider_name": "Cerebras",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 8.5e-7,
      "input_cost_per_million": 0.85,
      "output_cost_per_token": 0.0000012,
      "output_cost_per_million": 1.2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "cerebras/llama3.1-70b",
      "model_slug": "cerebras/llama3.1-70b",
      "model_name": "Llama 3.1 70B | cerebras",
      "provider_id": "cerebras",
      "provider_name": "Cerebras",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "cerebras/llama3.1-8b",
      "model_slug": "cerebras/llama3.1-8b",
      "model_name": "Llama 3.1 8B | cerebras",
      "provider_id": "cerebras",
      "provider_name": "Cerebras",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 1e-7,
      "output_cost_per_million": 0.09999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "cerebras/qwen-3-32b",
      "model_slug": "cerebras/qwen-3-32b",
      "model_name": "Qwen 3 32b | cerebras",
      "provider_id": "cerebras",
      "provider_name": "Cerebras",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 4e-7,
      "input_cost_per_million": 0.39999999999999997,
      "output_cost_per_token": 8e-7,
      "output_cost_per_million": 0.7999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "cloudflare": [
    {
      "model_id": "@cf/meta/llama-2-7b-chat-fp16",
      "model_slug": "cloudflare/@cf/meta/llama-2-7b-chat-fp16",
      "model_name": "Llama 2 7b Chat Fp16 | meta | @cf",
      "provider_id": "cloudflare",
      "provider_name": "Cloudflare",
      "max_input_tokens": 3072,
      "max_output_tokens": 3072,
      "input_cost_per_token": 0.000001923,
      "input_cost_per_million": 1.923,
      "output_cost_per_token": 0.000001923,
      "output_cost_per_million": 1.923,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "@cf/meta/llama-2-7b-chat-int8",
      "model_slug": "cloudflare/@cf/meta/llama-2-7b-chat-int8",
      "model_name": "Llama 2 7b Chat Int8 | meta | @cf",
      "provider_id": "cloudflare",
      "provider_name": "Cloudflare",
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0.000001923,
      "input_cost_per_million": 1.923,
      "output_cost_per_token": 0.000001923,
      "output_cost_per_million": 1.923,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "@cf/mistral/mistral-7b-instruct-v0.1",
      "model_slug": "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1",
      "model_name": "Mistral (7B) Instruct | mistral | @cf",
      "provider_id": "cloudflare",
      "provider_name": "Cloudflare",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001923,
      "input_cost_per_million": 1.923,
      "output_cost_per_token": 0.000001923,
      "output_cost_per_million": 1.923,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "@hf/thebloke/codellama-7b-instruct-awq",
      "model_slug": "cloudflare/@hf/thebloke/codellama-7b-instruct-awq",
      "model_name": "Codellama 7b Instruct Awq | thebloke | @hf",
      "provider_id": "cloudflare",
      "provider_name": "Cloudflare",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001923,
      "input_cost_per_million": 1.923,
      "output_cost_per_token": 0.000001923,
      "output_cost_per_million": 1.923,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "cohere": [
    {
      "model_id": "command",
      "model_slug": "command",
      "model_name": "Command",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "command-a-03-2025",
      "model_slug": "command-a-03-2025",
      "model_name": "Command A 03 2025",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 256000,
      "max_output_tokens": 8000,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "command-light",
      "model_slug": "command-light",
      "model_name": "Command Light",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "command-nightly",
      "model_slug": "command-nightly",
      "model_name": "Command Nightly",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "command-r",
      "model_slug": "command-r",
      "model_name": "Command R",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "command-r-08-2024",
      "model_slug": "command-r-08-2024",
      "model_name": "Command R 08 2024",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "command-r-plus",
      "model_slug": "command-r-plus",
      "model_name": "Command R Plus",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "command-r-plus-08-2024",
      "model_slug": "command-r-plus-08-2024",
      "model_name": "Command R Plus 08 2024",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "command-r7b-12-2024",
      "model_slug": "command-r7b-12-2024",
      "model_name": "Command R7b 12 2024",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 3.75e-8,
      "output_cost_per_million": 0.0375,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "embed-english-light-v2.0",
      "model_slug": "embed-english-light-v2.0",
      "model_name": "Embed English Light V2.0",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 1024,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "embed-english-light-v3.0",
      "model_slug": "embed-english-light-v3.0",
      "model_name": "Embed English Light V3.0",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 1024,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "embed-english-v2.0",
      "model_slug": "embed-english-v2.0",
      "model_name": "Embed English V2.0",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 4096,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "embed-english-v3.0",
      "model_slug": "embed-english-v3.0",
      "model_name": "Embed English V3.0",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 1024,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "embed-multilingual-v2.0",
      "model_slug": "embed-multilingual-v2.0",
      "model_name": "Embed Multilingual V2.0",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 768,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "embed-multilingual-v3.0",
      "model_slug": "embed-multilingual-v3.0",
      "model_name": "Embed Multilingual V3.0",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 1024,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "rerank-english-v2.0",
      "model_slug": "rerank-english-v2.0",
      "model_name": "Rerank English V2.0",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    },
    {
      "model_id": "rerank-english-v3.0",
      "model_slug": "rerank-english-v3.0",
      "model_name": "Rerank English V3.0",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    },
    {
      "model_id": "rerank-multilingual-v2.0",
      "model_slug": "rerank-multilingual-v2.0",
      "model_name": "Rerank Multilingual V2.0",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    },
    {
      "model_id": "rerank-multilingual-v3.0",
      "model_slug": "rerank-multilingual-v3.0",
      "model_name": "Rerank Multilingual V3.0",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    },
    {
      "model_id": "rerank-v3.5",
      "model_slug": "rerank-v3.5",
      "model_name": "Rerank V3.5",
      "provider_id": "cohere",
      "provider_name": "Cohere",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    }
  ],
  "dashscope": [
    {
      "model_id": "dashscope/qwen-max",
      "model_slug": "dashscope/qwen-max",
      "model_name": "Qwen Max | dashscope",
      "provider_id": "dashscope",
      "provider_name": "Dashscope",
      "max_input_tokens": 30720,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "dashscope/qwen-plus-latest",
      "model_slug": "dashscope/qwen-plus-latest",
      "model_name": "Qwen Plus Latest | dashscope",
      "provider_id": "dashscope",
      "provider_name": "Dashscope",
      "max_input_tokens": 129024,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "dashscope/qwen-turbo-latest",
      "model_slug": "dashscope/qwen-turbo-latest",
      "model_name": "Qwen Turbo Latest | dashscope",
      "provider_id": "dashscope",
      "provider_name": "Dashscope",
      "max_input_tokens": 129024,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "dashscope/qwen3-30b-a3b",
      "model_slug": "dashscope/qwen3-30b-a3b",
      "model_name": "Qwen3 30b A3b | dashscope",
      "provider_id": "dashscope",
      "provider_name": "Dashscope",
      "max_input_tokens": 129024,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "databricks": [
    {
      "model_id": "databricks-bge-large-en",
      "model_slug": "databricks/databricks-bge-large-en",
      "model_name": "Databricks Bge Large En",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 512,
      "max_output_tokens": null,
      "input_cost_per_token": 1.0003e-7,
      "input_cost_per_million": 0.10003000000000001,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "databricks-claude-3-7-sonnet",
      "model_slug": "databricks/databricks-claude-3-7-sonnet",
      "model_name": "Databricks Claude 3 7 Sonnet",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.000017857,
      "output_cost_per_million": 17.857,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "databricks-dbrx-instruct",
      "model_slug": "databricks/databricks-dbrx-instruct",
      "model_name": "Databricks Dbrx Instruct",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 7.4998e-7,
      "input_cost_per_million": 0.74998,
      "output_cost_per_token": 0.00000224901,
      "output_cost_per_million": 2.2490099999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "databricks-gte-large-en",
      "model_slug": "databricks/databricks-gte-large-en",
      "model_name": "Databricks Gte Large En",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 8192,
      "max_output_tokens": null,
      "input_cost_per_token": 1.2999e-7,
      "input_cost_per_million": 0.12999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "databricks-llama-2-70b-chat",
      "model_slug": "databricks/databricks-llama-2-70b-chat",
      "model_name": "Databricks Llama 2 70b Chat",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5.0001e-7,
      "input_cost_per_million": 0.5000100000000001,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "databricks-llama-4-maverick",
      "model_slug": "databricks/databricks-llama-4-maverick",
      "model_name": "Databricks Llama 4 Maverick",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "databricks-meta-llama-3-1-405b-instruct",
      "model_slug": "databricks/databricks-meta-llama-3-1-405b-instruct",
      "model_name": "Databricks Meta Llama 3 1 405b Instruct",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.00001500002,
      "output_cost_per_million": 15.00002,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "databricks-meta-llama-3-1-70b-instruct",
      "model_slug": "databricks/databricks-meta-llama-3-1-70b-instruct",
      "model_name": "Databricks Meta Llama 3 1 70b Instruct",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.00000100002,
      "input_cost_per_million": 1.0000200000000001,
      "output_cost_per_token": 0.00000299999,
      "output_cost_per_million": 2.99999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "databricks-meta-llama-3-3-70b-instruct",
      "model_slug": "databricks/databricks-meta-llama-3-3-70b-instruct",
      "model_name": "Databricks Meta Llama 3 3 70b Instruct",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.00000100002,
      "input_cost_per_million": 1.0000200000000001,
      "output_cost_per_token": 0.00000299999,
      "output_cost_per_million": 2.99999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "databricks-meta-llama-3-70b-instruct",
      "model_slug": "databricks/databricks-meta-llama-3-70b-instruct",
      "model_name": "Databricks Meta Llama 3 70b Instruct",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.00000100002,
      "input_cost_per_million": 1.0000200000000001,
      "output_cost_per_token": 0.00000299999,
      "output_cost_per_million": 2.99999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "databricks-mixtral-8x7b-instruct",
      "model_slug": "databricks/databricks-mixtral-8x7b-instruct",
      "model_name": "Databricks Mixtral 8x7b Instruct",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5.0001e-7,
      "input_cost_per_million": 0.5000100000000001,
      "output_cost_per_token": 9.9902e-7,
      "output_cost_per_million": 0.99902,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "databricks-mpt-30b-instruct",
      "model_slug": "databricks/databricks-mpt-30b-instruct",
      "model_name": "Databricks Mpt 30b Instruct",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 9.9902e-7,
      "input_cost_per_million": 0.99902,
      "output_cost_per_token": 9.9902e-7,
      "output_cost_per_million": 0.99902,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "databricks-mpt-7b-instruct",
      "model_slug": "databricks/databricks-mpt-7b-instruct",
      "model_name": "Databricks Mpt 7b Instruct",
      "provider_id": "databricks",
      "provider_name": "Databricks",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.0001e-7,
      "input_cost_per_million": 0.5000100000000001,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "deepgram": [
    {
      "model_id": "deepgram/base",
      "model_slug": "deepgram/base",
      "model_name": "Base | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/base-conversationalai",
      "model_slug": "deepgram/base-conversationalai",
      "model_name": "Base Conversationalai | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/base-finance",
      "model_slug": "deepgram/base-finance",
      "model_name": "Base Finance | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/base-general",
      "model_slug": "deepgram/base-general",
      "model_name": "Base General | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/base-meeting",
      "model_slug": "deepgram/base-meeting",
      "model_name": "Base Meeting | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/base-phonecall",
      "model_slug": "deepgram/base-phonecall",
      "model_name": "Base Phonecall | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/base-video",
      "model_slug": "deepgram/base-video",
      "model_name": "Base Video | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/base-voicemail",
      "model_slug": "deepgram/base-voicemail",
      "model_name": "Base Voicemail | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/enhanced",
      "model_slug": "deepgram/enhanced",
      "model_name": "Enhanced | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/enhanced-finance",
      "model_slug": "deepgram/enhanced-finance",
      "model_name": "Enhanced Finance | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/enhanced-general",
      "model_slug": "deepgram/enhanced-general",
      "model_name": "Enhanced General | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/enhanced-meeting",
      "model_slug": "deepgram/enhanced-meeting",
      "model_name": "Enhanced Meeting | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/enhanced-phonecall",
      "model_slug": "deepgram/enhanced-phonecall",
      "model_name": "Enhanced Phonecall | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova",
      "model_slug": "deepgram/nova",
      "model_name": "Nova | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-2",
      "model_slug": "deepgram/nova-2",
      "model_name": "Nova 2 | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-2-atc",
      "model_slug": "deepgram/nova-2-atc",
      "model_name": "Nova 2 Atc | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-2-automotive",
      "model_slug": "deepgram/nova-2-automotive",
      "model_name": "Nova 2 Automotive | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-2-conversationalai",
      "model_slug": "deepgram/nova-2-conversationalai",
      "model_name": "Nova 2 Conversationalai | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-2-drivethru",
      "model_slug": "deepgram/nova-2-drivethru",
      "model_name": "Nova 2 Drivethru | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-2-finance",
      "model_slug": "deepgram/nova-2-finance",
      "model_name": "Nova 2 Finance | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-2-general",
      "model_slug": "deepgram/nova-2-general",
      "model_name": "Nova 2 General | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-2-meeting",
      "model_slug": "deepgram/nova-2-meeting",
      "model_name": "Nova 2 Meeting | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-2-phonecall",
      "model_slug": "deepgram/nova-2-phonecall",
      "model_name": "Nova 2 Phonecall | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-2-video",
      "model_slug": "deepgram/nova-2-video",
      "model_name": "Nova 2 Video | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-2-voicemail",
      "model_slug": "deepgram/nova-2-voicemail",
      "model_name": "Nova 2 Voicemail | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-3",
      "model_slug": "deepgram/nova-3",
      "model_name": "Nova 3 | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-3-general",
      "model_slug": "deepgram/nova-3-general",
      "model_name": "Nova 3 General | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-3-medical",
      "model_slug": "deepgram/nova-3-medical",
      "model_name": "Nova 3 Medical | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-general",
      "model_slug": "deepgram/nova-general",
      "model_name": "Nova General | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/nova-phonecall",
      "model_slug": "deepgram/nova-phonecall",
      "model_name": "Nova Phonecall | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/whisper",
      "model_slug": "deepgram/whisper",
      "model_name": "Whisper | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/whisper-base",
      "model_slug": "deepgram/whisper-base",
      "model_name": "Whisper Base | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/whisper-large",
      "model_slug": "deepgram/whisper-large",
      "model_name": "Whisper Large | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/whisper-medium",
      "model_slug": "deepgram/whisper-medium",
      "model_name": "Whisper Medium | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/whisper-small",
      "model_slug": "deepgram/whisper-small",
      "model_name": "Whisper Small | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "deepgram/whisper-tiny",
      "model_slug": "deepgram/whisper-tiny",
      "model_name": "Whisper Tiny | deepgram",
      "provider_id": "deepgram",
      "provider_name": "Deepgram",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    }
  ],
  "deepinfra": [
    {
      "model_id": "01-ai/Yi-34B-200K",
      "model_slug": "deepinfra/01-ai/Yi-34B-200K",
      "model_name": "Yi 34B 200K | 01-ai",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "01-ai/Yi-34B-Chat",
      "model_slug": "deepinfra/01-ai/Yi-34B-Chat",
      "model_name": "Yi 34B Chat | 01-ai",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "01-ai/Yi-6B-200K",
      "model_slug": "deepinfra/01-ai/Yi-6B-200K",
      "model_name": "Yi 6B 200K | 01-ai",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.3e-7,
      "input_cost_per_million": 0.13,
      "output_cost_per_token": 1.3e-7,
      "output_cost_per_million": 0.13,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "amazon/MistralLite",
      "model_slug": "deepinfra/amazon/MistralLite",
      "model_name": "MistralLite | amazon",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 32768,
      "max_output_tokens": 8191,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "cognitivecomputations/dolphin-2.6-mixtral-8x7b",
      "model_slug": "deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b",
      "model_name": "Dolphin 2.6 Mixtral 8x7b | cognitivecomputations",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 32768,
      "max_output_tokens": 8191,
      "input_cost_per_token": 2.7e-7,
      "input_cost_per_million": 0.27,
      "output_cost_per_token": 2.7e-7,
      "output_cost_per_million": 0.27,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "deepinfra/airoboros-70b",
      "model_slug": "deepinfra/deepinfra/airoboros-70b",
      "model_name": "Airoboros 70b | deepinfra",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "input_cost_per_million": 0.7,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "deepinfra/mixtral",
      "model_slug": "deepinfra/deepinfra/mixtral",
      "model_name": "Mixtral | deepinfra",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.7e-7,
      "input_cost_per_million": 0.27,
      "output_cost_per_token": 2.7e-7,
      "output_cost_per_million": 0.27,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "Gryphe/MythoMax-L2-13b",
      "model_slug": "deepinfra/Gryphe/MythoMax-L2-13b",
      "model_name": "MythoMax L2 13b | Gryphe",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.2e-7,
      "input_cost_per_million": 0.22,
      "output_cost_per_token": 2.2e-7,
      "output_cost_per_million": 0.22,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "jondurbin/airoboros-l2-70b-gpt4-1.4.1",
      "model_slug": "deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1",
      "model_name": "Airoboros L2 70b Gpt4 1.4.1 | jondurbin",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "input_cost_per_million": 0.7,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "lizpreciatior/lzlv_70b_fp16_hf",
      "model_slug": "deepinfra/lizpreciatior/lzlv_70b_fp16_hf",
      "model_name": "Lzlv_70b_fp16_hf | lizpreciatior",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "input_cost_per_million": 0.7,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Meta-Llama-3.1-405B-Instruct",
      "model_slug": "deepinfra/meta-llama/Meta-Llama-3.1-405B-Instruct",
      "model_name": "Meta Llama 3.1 405B Instruct | meta-llama",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 9e-7,
      "input_cost_per_million": 0.8999999999999999,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openchat/openchat_3.5",
      "model_slug": "deepinfra/openchat/openchat_3.5",
      "model_name": "Openchat_3.5 | openchat",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.3e-7,
      "input_cost_per_million": 0.13,
      "output_cost_per_token": 1.3e-7,
      "output_cost_per_million": 0.13,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "Phind/Phind-CodeLlama-34B-v2",
      "model_slug": "deepinfra/Phind/Phind-CodeLlama-34B-v2",
      "model_name": "Phind CodeLlama 34B V2 | Phind",
      "provider_id": "deepinfra",
      "provider_name": "DeepInfra",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "deepseek": [
    {
      "model_id": "deepseek/deepseek-chat",
      "model_slug": "deepseek/deepseek-chat",
      "model_name": "Deepseek Chat | deepseek",
      "provider_id": "deepseek",
      "provider_name": "DeepSeek",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2.7e-7,
      "input_cost_per_million": 0.27,
      "output_cost_per_token": 0.0000011,
      "output_cost_per_million": 1.1,
      "cache_read_cost_per_token": 7e-8,
      "cache_read_cost_per_million": 0.07,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "deepseek/deepseek-coder",
      "model_slug": "deepseek/deepseek-coder",
      "model_name": "Deepseek Coder | deepseek",
      "provider_id": "deepseek",
      "provider_name": "DeepSeek",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.4e-7,
      "input_cost_per_million": 0.14,
      "output_cost_per_token": 2.8e-7,
      "output_cost_per_million": 0.28,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "deepseek/deepseek-r1",
      "model_slug": "deepseek/deepseek-r1",
      "model_name": "DeepSeek R1 | deepseek",
      "provider_id": "deepseek",
      "provider_name": "DeepSeek",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.5e-7,
      "input_cost_per_million": 0.55,
      "output_cost_per_token": 0.00000219,
      "output_cost_per_million": 2.1900000000000004,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "deepseek/deepseek-reasoner",
      "model_slug": "deepseek/deepseek-reasoner",
      "model_name": "Deepseek Reasoner | deepseek",
      "provider_id": "deepseek",
      "provider_name": "DeepSeek",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.5e-7,
      "input_cost_per_million": 0.55,
      "output_cost_per_token": 0.00000219,
      "output_cost_per_million": 2.1900000000000004,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "deepseek/deepseek-v3",
      "model_slug": "deepseek/deepseek-v3",
      "model_name": "DeepSeek V3 | deepseek",
      "provider_id": "deepseek",
      "provider_name": "DeepSeek",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2.7e-7,
      "input_cost_per_million": 0.27,
      "output_cost_per_token": 0.0000011,
      "output_cost_per_million": 1.1,
      "cache_read_cost_per_token": 7e-8,
      "cache_read_cost_per_million": 0.07,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "elevenlabs": [
    {
      "model_id": "elevenlabs/scribe_v1",
      "model_slug": "elevenlabs/scribe_v1",
      "model_name": "Scribe_v1 | elevenlabs",
      "provider_id": "elevenlabs",
      "provider_name": "ElevenLabs",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "elevenlabs/scribe_v1_experimental",
      "model_slug": "elevenlabs/scribe_v1_experimental",
      "model_name": "Scribe_v1_experimental | elevenlabs",
      "provider_id": "elevenlabs",
      "provider_name": "ElevenLabs",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    }
  ],
  "featherless": [
    {
      "model_id": "featherless_ai/featherless-ai/Qwerky-72B",
      "model_slug": "featherless_ai/featherless-ai/Qwerky-72B",
      "model_name": "Qwerky 72B | featherless-ai | featherless_ai",
      "provider_id": "featherless",
      "provider_name": "Featherless",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "featherless_ai/featherless-ai/Qwerky-QwQ-32B",
      "model_slug": "featherless_ai/featherless-ai/Qwerky-QwQ-32B",
      "model_name": "Qwerky QwQ 32B | featherless-ai | featherless_ai",
      "provider_id": "featherless",
      "provider_name": "Featherless",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "fireworks": [
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct",
      "model_slug": "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct",
      "model_name": "Deepseek Coder V2 Instruct | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.0000012,
      "input_cost_per_million": 1.2,
      "output_cost_per_token": 0.0000012,
      "output_cost_per_million": 1.2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1",
      "model_slug": "fireworks_ai/accounts/fireworks/models/deepseek-r1",
      "model_name": "DeepSeek R1 | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 20480,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528",
      "model_slug": "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528",
      "model_name": "Deepseek R1 0528 | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 160000,
      "max_output_tokens": 160000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic",
      "model_slug": "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic",
      "model_name": "Deepseek R1 Basic | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 20480,
      "input_cost_per_token": 5.5e-7,
      "input_cost_per_million": 0.55,
      "output_cost_per_token": 0.00000219,
      "output_cost_per_million": 2.1900000000000004,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/deepseek-v3",
      "model_slug": "fireworks_ai/accounts/fireworks/models/deepseek-v3",
      "model_name": "DeepSeek V3 | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 9e-7,
      "input_cost_per_million": 0.8999999999999999,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/firefunction-v2",
      "model_slug": "fireworks_ai/accounts/fireworks/models/firefunction-v2",
      "model_name": "Firefunction V2 | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 9e-7,
      "input_cost_per_million": 0.8999999999999999,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct",
      "model_slug": "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct",
      "model_name": "Llama V3p1 405b Instruct | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct",
      "model_slug": "fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct",
      "model_name": "Llama V3p1 8b Instruct | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 1e-7,
      "output_cost_per_million": 0.09999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct",
      "model_slug": "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct",
      "model_name": "Llama V3p2 11b Vision Instruct | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct",
      "model_slug": "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct",
      "model_name": "Llama V3p2 1b Instruct | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 1e-7,
      "output_cost_per_million": 0.09999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct",
      "model_slug": "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct",
      "model_name": "Llama V3p2 3b Instruct | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 1e-7,
      "output_cost_per_million": 0.09999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct",
      "model_slug": "fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct",
      "model_name": "Llama V3p2 90b Vision Instruct | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 9e-7,
      "input_cost_per_million": 0.8999999999999999,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic",
      "model_slug": "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic",
      "model_name": "Llama4 Maverick Instruct Basic | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2.2e-7,
      "input_cost_per_million": 0.22,
      "output_cost_per_token": 8.8e-7,
      "output_cost_per_million": 0.88,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic",
      "model_slug": "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic",
      "model_name": "Llama4 Scout Instruct Basic | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf",
      "model_slug": "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf",
      "model_name": "Mixtral 8x22b Instruct Hf | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.0000012,
      "input_cost_per_million": 1.2,
      "output_cost_per_token": 0.0000012,
      "output_cost_per_million": 1.2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct",
      "model_slug": "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct",
      "model_name": "Qwen2 72b Instruct | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 9e-7,
      "input_cost_per_million": 0.8999999999999999,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct",
      "model_slug": "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct",
      "model_name": "Qwen2p5 Coder 32b Instruct | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 9e-7,
      "input_cost_per_million": 0.8999999999999999,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/accounts/fireworks/models/yi-large",
      "model_slug": "fireworks_ai/accounts/fireworks/models/yi-large",
      "model_name": "Yi Large | models | fireworks | accounts | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/nomic-ai/nomic-embed-text-v1",
      "model_slug": "fireworks_ai/nomic-ai/nomic-embed-text-v1",
      "model_name": "Nomic Embed Text V1 | nomic-ai | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 8192,
      "max_output_tokens": null,
      "input_cost_per_token": 8e-9,
      "input_cost_per_million": 0.008,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/nomic-ai/nomic-embed-text-v1.5",
      "model_slug": "fireworks_ai/nomic-ai/nomic-embed-text-v1.5",
      "model_name": "Nomic Embed Text V1.5 | nomic-ai | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 8192,
      "max_output_tokens": null,
      "input_cost_per_token": 8e-9,
      "input_cost_per_million": 0.008,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/thenlper/gte-base",
      "model_slug": "fireworks_ai/thenlper/gte-base",
      "model_name": "Gte Base | thenlper | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 512,
      "max_output_tokens": null,
      "input_cost_per_token": 8e-9,
      "input_cost_per_million": 0.008,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/thenlper/gte-large",
      "model_slug": "fireworks_ai/thenlper/gte-large",
      "model_name": "Gte Large | thenlper | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 512,
      "max_output_tokens": null,
      "input_cost_per_token": 1.6e-8,
      "input_cost_per_million": 0.016,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks_ai/WhereIsAI/UAE-Large-V1",
      "model_slug": "fireworks_ai/WhereIsAI/UAE-Large-V1",
      "model_name": "UAE Large V1 | WhereIsAI | fireworks_ai",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": 512,
      "max_output_tokens": null,
      "input_cost_per_token": 1.6e-8,
      "input_cost_per_million": 0.016,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks-ai-4.1b-to-16b",
      "model_slug": "fireworks-ai-4.1b-to-16b",
      "model_name": "Fireworks Ai 4.1b To 16b",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks-ai-56b-to-176b",
      "model_slug": "fireworks-ai-56b-to-176b",
      "model_name": "Fireworks Ai 56b To 176b",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.0000012,
      "input_cost_per_million": 1.2,
      "output_cost_per_token": 0.0000012,
      "output_cost_per_million": 1.2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks-ai-above-16b",
      "model_slug": "fireworks-ai-above-16b",
      "model_name": "Fireworks Ai Above 16b",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 9e-7,
      "input_cost_per_million": 0.8999999999999999,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks-ai-default",
      "model_slug": "fireworks-ai-default",
      "model_name": "Fireworks Ai Default",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks-ai-embedding-150m-to-350m",
      "model_slug": "fireworks-ai-embedding-150m-to-350m",
      "model_name": "Fireworks Ai Embedding 150m To 350m",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1.6e-8,
      "input_cost_per_million": 0.016,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks-ai-embedding-up-to-150m",
      "model_slug": "fireworks-ai-embedding-up-to-150m",
      "model_name": "Fireworks Ai Embedding Up To 150m",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 8e-9,
      "input_cost_per_million": 0.008,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks-ai-moe-up-to-56b",
      "model_slug": "fireworks-ai-moe-up-to-56b",
      "model_name": "Fireworks Ai Moe Up To 56b",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "fireworks-ai-up-to-4b",
      "model_slug": "fireworks-ai-up-to-4b",
      "model_name": "Fireworks Ai Up To 4b",
      "provider_id": "fireworks",
      "provider_name": "Fireworks AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "friendliai": [
    {
      "model_id": "friendliai/meta-llama-3.1-70b-instruct",
      "model_slug": "friendliai/meta-llama-3.1-70b-instruct",
      "model_name": "Meta Llama 3.1 70b Instruct | friendliai",
      "provider_id": "friendliai",
      "provider_name": "Friendliai",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "friendliai/meta-llama-3.1-8b-instruct",
      "model_slug": "friendliai/meta-llama-3.1-8b-instruct",
      "model_name": "Meta Llama 3.1 8b Instruct | friendliai",
      "provider_id": "friendliai",
      "provider_name": "Friendliai",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 1e-7,
      "output_cost_per_million": 0.09999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "google": [
    {
      "model_id": "gemini/gemini-1.5-flash",
      "model_slug": "gemini/gemini-1.5-flash",
      "model_name": "Gemini 1.5 Flash | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-1.5-flash-001",
      "model_slug": "gemini/gemini-1.5-flash-001",
      "model_name": "Gemini 1.5 Flash 001 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": 1.875e-8,
      "cache_read_cost_per_million": 0.01875,
      "cache_write_cost_per_token": 0.000001,
      "cache_write_cost_per_million": 1,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-05-24"
    },
    {
      "model_id": "gemini/gemini-1.5-flash-002",
      "model_slug": "gemini/gemini-1.5-flash-002",
      "model_name": "Gemini 1.5 Flash 002 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": 1.875e-8,
      "cache_read_cost_per_million": 0.01875,
      "cache_write_cost_per_token": 0.000001,
      "cache_write_cost_per_million": 1,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-09-24"
    },
    {
      "model_id": "gemini/gemini-1.5-flash-8b",
      "model_slug": "gemini/gemini-1.5-flash-8b",
      "model_name": "Gemini 1.5 Flash 8B | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-1.5-flash-8b-exp-0827",
      "model_slug": "gemini/gemini-1.5-flash-8b-exp-0827",
      "model_name": "Gemini 1.5 Flash 8b Exp 0827 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-1.5-flash-8b-exp-0924",
      "model_slug": "gemini/gemini-1.5-flash-8b-exp-0924",
      "model_name": "Gemini 1.5 Flash 8b Exp 0924 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-1.5-flash-exp-0827",
      "model_slug": "gemini/gemini-1.5-flash-exp-0827",
      "model_name": "Gemini 1.5 Flash Exp 0827 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-1.5-flash-latest",
      "model_slug": "gemini/gemini-1.5-flash-latest",
      "model_name": "Gemini 1.5 Flash Latest | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-1.5-pro",
      "model_slug": "gemini/gemini-1.5-pro",
      "model_name": "Gemini 1.5 Pro | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000035,
      "input_cost_per_million": 3.5,
      "output_cost_per_token": 0.0000105,
      "output_cost_per_million": 10.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-1.5-pro-001",
      "model_slug": "gemini/gemini-1.5-pro-001",
      "model_name": "Gemini 1.5 Pro 001 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000035,
      "input_cost_per_million": 3.5,
      "output_cost_per_token": 0.0000105,
      "output_cost_per_million": 10.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-05-24"
    },
    {
      "model_id": "gemini/gemini-1.5-pro-002",
      "model_slug": "gemini/gemini-1.5-pro-002",
      "model_name": "Gemini 1.5 Pro 002 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000035,
      "input_cost_per_million": 3.5,
      "output_cost_per_token": 0.0000105,
      "output_cost_per_million": 10.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-09-24"
    },
    {
      "model_id": "gemini/gemini-1.5-pro-exp-0801",
      "model_slug": "gemini/gemini-1.5-pro-exp-0801",
      "model_name": "Gemini 1.5 Pro Exp 0801 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000035,
      "input_cost_per_million": 3.5,
      "output_cost_per_token": 0.0000105,
      "output_cost_per_million": 10.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-1.5-pro-exp-0827",
      "model_slug": "gemini/gemini-1.5-pro-exp-0827",
      "model_name": "Gemini 1.5 Pro Exp 0827 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-1.5-pro-latest",
      "model_slug": "gemini/gemini-1.5-pro-latest",
      "model_name": "Gemini 1.5 Pro Latest | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000035,
      "input_cost_per_million": 3.5,
      "output_cost_per_token": 0.00000105,
      "output_cost_per_million": 1.0499999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.0-flash",
      "model_slug": "gemini/gemini-2.0-flash",
      "model_name": "Gemini 2.0 Flash Latest | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": 2.5e-8,
      "cache_read_cost_per_million": 0.024999999999999998,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.0-flash-001",
      "model_slug": "gemini/gemini-2.0-flash-001",
      "model_name": "Gemini 2.0 Flash 001 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": 2.5e-8,
      "cache_read_cost_per_million": 0.024999999999999998,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.0-flash-exp",
      "model_slug": "gemini/gemini-2.0-flash-exp",
      "model_name": "Gemini 2.0 Flash Exp | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.0-flash-lite",
      "model_slug": "gemini/gemini-2.0-flash-lite",
      "model_name": "Gemini 2.0 Flash Lite | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": 1.875e-8,
      "cache_read_cost_per_million": 0.01875,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.0-flash-lite-preview-02-05",
      "model_slug": "gemini/gemini-2.0-flash-lite-preview-02-05",
      "model_name": "Gemini 2.0 Flash Lite Preview 02 05 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": 1.875e-8,
      "cache_read_cost_per_million": 0.01875,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.0-flash-preview-image-generation",
      "model_slug": "gemini/gemini-2.0-flash-preview-image-generation",
      "model_name": "Gemini 2.0 Flash Preview Image Generation | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": 2.5e-8,
      "cache_read_cost_per_million": 0.024999999999999998,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.0-flash-thinking-exp",
      "model_slug": "gemini/gemini-2.0-flash-thinking-exp",
      "model_name": "Gemini 2.0 Flash Thinking Exp | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.0-flash-thinking-exp-01-21",
      "model_slug": "gemini/gemini-2.0-flash-thinking-exp-01-21",
      "model_name": "Gemini 2.0 Flash Thinking Exp 01 21 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.0-pro-exp-02-05",
      "model_slug": "gemini/gemini-2.0-pro-exp-02-05",
      "model_name": "Gemini 2.0 Pro Exp 02 05 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.5-flash",
      "model_slug": "gemini/gemini-2.5-flash",
      "model_name": "Gemini 2.5 Flash | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 0.0000025,
      "output_cost_per_million": 2.5,
      "cache_read_cost_per_token": 7.5e-8,
      "cache_read_cost_per_million": 0.075,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.5-flash-lite-preview-06-17",
      "model_slug": "gemini/gemini-2.5-flash-lite-preview-06-17",
      "model_name": "Gemini 2.5 Flash Lite Preview | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": 2.5e-8,
      "cache_read_cost_per_million": 0.024999999999999998,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.5-flash-preview-04-17",
      "model_slug": "gemini/gemini-2.5-flash-preview-04-17",
      "model_name": "Gemini 2.5 Flash Preview 04 17 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": 3.75e-8,
      "cache_read_cost_per_million": 0.0375,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.5-flash-preview-05-20",
      "model_slug": "gemini/gemini-2.5-flash-preview-05-20",
      "model_name": "Gemini 2.5 Flash Preview 05 20 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 0.0000025,
      "output_cost_per_million": 2.5,
      "cache_read_cost_per_token": 7.5e-8,
      "cache_read_cost_per_million": 0.075,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.5-flash-preview-tts",
      "model_slug": "gemini/gemini-2.5-flash-preview-tts",
      "model_name": "Gemini 2.5 Flash Preview Tts | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": 3.75e-8,
      "cache_read_cost_per_million": 0.0375,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.5-pro",
      "model_slug": "gemini/gemini-2.5-pro",
      "model_name": "Gemini 2.5 Pro | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 3.125e-7,
      "cache_read_cost_per_million": 0.3125,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.5-pro-exp-03-25",
      "model_slug": "gemini/gemini-2.5-pro-exp-03-25",
      "model_name": "Gemini 2.5 Pro Exp 03 25 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.5-pro-preview-03-25",
      "model_slug": "gemini/gemini-2.5-pro-preview-03-25",
      "model_name": "Gemini 2.5 Pro Preview 03 25 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 3.125e-7,
      "cache_read_cost_per_million": 0.3125,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.5-pro-preview-05-06",
      "model_slug": "gemini/gemini-2.5-pro-preview-05-06",
      "model_name": "Gemini 2.5 Pro Preview 05 06 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 3.125e-7,
      "cache_read_cost_per_million": 0.3125,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.5-pro-preview-06-05",
      "model_slug": "gemini/gemini-2.5-pro-preview-06-05",
      "model_name": "Gemini 2.5 Pro Preview 06 05 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 3.125e-7,
      "cache_read_cost_per_million": 0.3125,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-2.5-pro-preview-tts",
      "model_slug": "gemini/gemini-2.5-pro-preview-tts",
      "model_name": "Gemini 2.5 Pro Preview Tts | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 3.125e-7,
      "cache_read_cost_per_million": 0.3125,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-exp-1114",
      "model_slug": "gemini/gemini-exp-1114",
      "model_name": "Gemini Exp 1114 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-exp-1206",
      "model_slug": "gemini/gemini-exp-1206",
      "model_name": "Gemini Exp 1206 | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-gemma-2-27b-it",
      "model_slug": "gemini/gemini-gemma-2-27b-it",
      "model_name": "Gemini Gemma 2 27b It | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": null,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_million": 0.35,
      "output_cost_per_token": 0.00000105,
      "output_cost_per_million": 1.0499999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-gemma-2-9b-it",
      "model_slug": "gemini/gemini-gemma-2-9b-it",
      "model_name": "Gemini Gemma 2 9b It | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": null,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_million": 0.35,
      "output_cost_per_token": 0.00000105,
      "output_cost_per_million": 1.0499999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-pro",
      "model_slug": "gemini/gemini-pro",
      "model_name": "Gemini Pro | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_million": 0.35,
      "output_cost_per_token": 0.00000105,
      "output_cost_per_million": 1.0499999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemini-pro-vision",
      "model_slug": "gemini/gemini-pro-vision",
      "model_name": "Gemini Pro Vision | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 30720,
      "max_output_tokens": 2048,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_million": 0.35,
      "output_cost_per_token": 0.00000105,
      "output_cost_per_million": 1.0499999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/gemma-3-27b-it",
      "model_slug": "gemini/gemma-3-27b-it",
      "model_name": "Gemma 3 27b It | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini/learnlm-1.5-pro-experimental",
      "model_slug": "gemini/learnlm-1.5-pro-experimental",
      "model_name": "Learnlm 1.5 Pro Experimental | gemini",
      "provider_id": "google",
      "provider_name": "Google",
      "max_input_tokens": 32767,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "groq": [
    {
      "model_id": "deepseek-r1-distill-llama-70b",
      "model_slug": "groq/deepseek-r1-distill-llama-70b",
      "model_name": "DeepSeek R1 Distill Llama 70B",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 7.5e-7,
      "input_cost_per_million": 0.75,
      "output_cost_per_token": 9.9e-7,
      "output_cost_per_million": 0.9900000000000001,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "distil-whisper-large-v3-en",
      "model_slug": "groq/distil-whisper-large-v3-en",
      "model_name": "Distil Whisper Large V3 En",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "gemma-7b-it",
      "model_slug": "groq/gemma-7b-it",
      "model_name": "Gemma 7b IT",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7e-8,
      "input_cost_per_million": 0.07,
      "output_cost_per_token": 7e-8,
      "output_cost_per_million": 0.07,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2024-12-18"
    },
    {
      "model_id": "gemma2-9b-it",
      "model_slug": "groq/gemma2-9b-it",
      "model_name": "Gemma 2 9B",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "llama-3.1-405b-reasoning",
      "model_slug": "groq/llama-3.1-405b-reasoning",
      "model_name": "Llama 3.1 405b Reasoning",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.9e-7,
      "input_cost_per_million": 0.59,
      "output_cost_per_token": 7.9e-7,
      "output_cost_per_million": 0.7899999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "llama-3.1-70b-versatile",
      "model_slug": "groq/llama-3.1-70b-versatile",
      "model_name": "Llama 3.1 70b Versatile",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.9e-7,
      "input_cost_per_million": 0.59,
      "output_cost_per_token": 7.9e-7,
      "output_cost_per_million": 0.7899999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-01-24"
    },
    {
      "model_id": "llama-3.1-8b-instant",
      "model_slug": "groq/llama-3.1-8b-instant",
      "model_name": "Llama 3.1 8b Instant",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5e-8,
      "input_cost_per_million": 0.049999999999999996,
      "output_cost_per_token": 8e-8,
      "output_cost_per_million": 0.08,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "llama-3.2-11b-text-preview",
      "model_slug": "groq/llama-3.2-11b-text-preview",
      "model_name": "Llama 3.2 11b Text Preview",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.8e-7,
      "input_cost_per_million": 0.18,
      "output_cost_per_token": 1.8e-7,
      "output_cost_per_million": 0.18,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2024-10-28"
    },
    {
      "model_id": "llama-3.2-11b-vision-preview",
      "model_slug": "groq/llama-3.2-11b-vision-preview",
      "model_name": "Llama 3.2 11b Vision Preview",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.8e-7,
      "input_cost_per_million": 0.18,
      "output_cost_per_token": 1.8e-7,
      "output_cost_per_million": 0.18,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-04-14"
    },
    {
      "model_id": "llama-3.2-1b-preview",
      "model_slug": "groq/llama-3.2-1b-preview",
      "model_name": "Llama 3.2 1b Preview",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 4e-8,
      "input_cost_per_million": 0.04,
      "output_cost_per_token": 4e-8,
      "output_cost_per_million": 0.04,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-04-14"
    },
    {
      "model_id": "llama-3.2-3b-preview",
      "model_slug": "groq/llama-3.2-3b-preview",
      "model_name": "Llama 3.2 3b Preview",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 6e-8,
      "input_cost_per_million": 0.06,
      "output_cost_per_token": 6e-8,
      "output_cost_per_million": 0.06,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-04-14"
    },
    {
      "model_id": "llama-3.2-90b-text-preview",
      "model_slug": "groq/llama-3.2-90b-text-preview",
      "model_name": "Llama 3.2 90b Text Preview",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 9e-7,
      "input_cost_per_million": 0.8999999999999999,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2024-11-25"
    },
    {
      "model_id": "llama-3.2-90b-vision-preview",
      "model_slug": "groq/llama-3.2-90b-vision-preview",
      "model_name": "Llama 3.2 90b Vision Preview",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 9e-7,
      "input_cost_per_million": 0.8999999999999999,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-04-14"
    },
    {
      "model_id": "llama-3.3-70b-specdec",
      "model_slug": "groq/llama-3.3-70b-specdec",
      "model_name": "Llama 3.3 70b Specdec",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.9e-7,
      "input_cost_per_million": 0.59,
      "output_cost_per_token": 9.9e-7,
      "output_cost_per_million": 0.9900000000000001,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-04-14"
    },
    {
      "model_id": "llama-3.3-70b-versatile",
      "model_slug": "groq/llama-3.3-70b-versatile",
      "model_name": "Llama 3.3 70b Versatile",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 5.9e-7,
      "input_cost_per_million": 0.59,
      "output_cost_per_token": 7.9e-7,
      "output_cost_per_million": 0.7899999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "llama-guard-3-8b",
      "model_slug": "groq/llama-guard-3-8b",
      "model_name": "Llama Guard 3 8b",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "llama2-70b-4096",
      "model_slug": "groq/llama2-70b-4096",
      "model_name": "Llama2 70b 4096",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "input_cost_per_million": 0.7,
      "output_cost_per_token": 8e-7,
      "output_cost_per_million": 0.7999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "llama3-70b-8192",
      "model_slug": "groq/llama3-70b-8192",
      "model_name": "Llama3 70b 8192",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.9e-7,
      "input_cost_per_million": 0.59,
      "output_cost_per_token": 7.9e-7,
      "output_cost_per_million": 0.7899999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "llama3-8b-8192",
      "model_slug": "groq/llama3-8b-8192",
      "model_name": "Llama3 8b 8192",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5e-8,
      "input_cost_per_million": 0.049999999999999996,
      "output_cost_per_token": 8e-8,
      "output_cost_per_million": 0.08,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "llama3-groq-70b-8192-tool-use-preview",
      "model_slug": "groq/llama3-groq-70b-8192-tool-use-preview",
      "model_name": "Llama3 Groq 70b 8192 Tool Use Preview",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 8.9e-7,
      "input_cost_per_million": 0.8899999999999999,
      "output_cost_per_token": 8.9e-7,
      "output_cost_per_million": 0.8899999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-01-06"
    },
    {
      "model_id": "llama3-groq-8b-8192-tool-use-preview",
      "model_slug": "groq/llama3-groq-8b-8192-tool-use-preview",
      "model_name": "Llama3 Groq 8b 8192 Tool Use Preview",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.9e-7,
      "input_cost_per_million": 0.19,
      "output_cost_per_token": 1.9e-7,
      "output_cost_per_million": 0.19,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-01-06"
    },
    {
      "model_id": "meta-llama/llama-4-maverick-17b-128e-instruct",
      "model_slug": "groq/meta-llama/llama-4-maverick-17b-128e-instruct",
      "model_name": "Llama 4 Maverick Instruct (17Bx128E) | meta-llama",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/llama-4-scout-17b-16e-instruct",
      "model_slug": "groq/meta-llama/llama-4-scout-17b-16e-instruct",
      "model_name": "Llama 4 Scout Instruct (17Bx16E) | meta-llama",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.1e-7,
      "input_cost_per_million": 0.11,
      "output_cost_per_token": 3.4e-7,
      "output_cost_per_million": 0.33999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-saba-24b",
      "model_slug": "groq/mistral-saba-24b",
      "model_name": "Mistral Saba 24b",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 7.9e-7,
      "input_cost_per_million": 0.7899999999999999,
      "output_cost_per_token": 7.9e-7,
      "output_cost_per_million": 0.7899999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mixtral-8x7b-32768",
      "model_slug": "groq/mixtral-8x7b-32768",
      "model_name": "Mixtral 8x7b 32768",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 2.4e-7,
      "input_cost_per_million": 0.24,
      "output_cost_per_token": 2.4e-7,
      "output_cost_per_million": 0.24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-03-20"
    },
    {
      "model_id": "moonshotai-kimi-k2-instruct",
      "model_slug": "groq/moonshotai-kimi-k2-instruct",
      "model_name": "Moonshotai Kimi K2 Instruct",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "playai-tts",
      "model_slug": "groq/playai-tts",
      "model_name": "Playai Tts",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 10000,
      "max_output_tokens": 10000,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "qwen-qwq-32b",
      "model_slug": "groq/qwen-qwq-32b",
      "model_name": "Qwen Qwq 32b",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 2.9e-7,
      "input_cost_per_million": 0.29,
      "output_cost_per_token": 3.9e-7,
      "output_cost_per_million": 0.39,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "whisper-large-v3",
      "model_slug": "groq/whisper-large-v3",
      "model_name": "Whisper Large V3",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    },
    {
      "model_id": "whisper-large-v3-turbo",
      "model_slug": "groq/whisper-large-v3-turbo",
      "model_name": "Whisper Large V3 Turbo",
      "provider_id": "groq",
      "provider_name": "Groq",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "audio",
      "deprecation_date": null
    }
  ],
  "jina": [
    {
      "model_id": "jina-reranker-v2-base-multilingual",
      "model_slug": "jina-reranker-v2-base-multilingual",
      "model_name": "Jina Reranker V2 Base Multilingual",
      "provider_id": "jina",
      "provider_name": "Jina",
      "max_input_tokens": 1024,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.8e-8,
      "input_cost_per_million": 0.018,
      "output_cost_per_token": 1.8e-8,
      "output_cost_per_million": 0.018,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    }
  ],
  "meta": [
    {
      "model_id": "meta_llama/Llama-3.3-70B-Instruct",
      "model_slug": "meta_llama/Llama-3.3-70B-Instruct",
      "model_name": "Llama 3.3 70B Instruct | meta_llama",
      "provider_id": "meta",
      "provider_name": "Meta",
      "max_input_tokens": 128000,
      "max_output_tokens": 4028,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta_llama/Llama-3.3-8B-Instruct",
      "model_slug": "meta_llama/Llama-3.3-8B-Instruct",
      "model_name": "Llama 3.3 8B Instruct | meta_llama",
      "provider_id": "meta",
      "provider_name": "Meta",
      "max_input_tokens": 128000,
      "max_output_tokens": 4028,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "model_slug": "meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "model_name": "Llama 4 Maverick 17B 128E Instruct FP8 | meta_llama",
      "provider_id": "meta",
      "provider_name": "Meta",
      "max_input_tokens": 1000000,
      "max_output_tokens": 4028,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8",
      "model_slug": "meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8",
      "model_name": "Llama 4 Scout 17B 16E Instruct FP8 | meta_llama",
      "provider_id": "meta",
      "provider_name": "Meta",
      "max_input_tokens": 10000000,
      "max_output_tokens": 4028,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "mistral": [
    {
      "model_id": "codestral-2405",
      "model_slug": "mistral/codestral-2405",
      "model_name": "Codestral 2405",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codestral-latest",
      "model_slug": "mistral/codestral-latest",
      "model_name": "Codestral",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codestral-mamba-latest",
      "model_slug": "mistral/codestral-mamba-latest",
      "model_name": "Codestral Mamba Latest",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 2.5e-7,
      "output_cost_per_million": 0.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codestral/codestral-2405",
      "model_slug": "codestral/codestral-2405",
      "model_name": "Codestral 2405 | codestral",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codestral/codestral-latest",
      "model_slug": "codestral/codestral-latest",
      "model_name": "Codestral | codestral",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "devstral-medium-2507",
      "model_slug": "mistral/devstral-medium-2507",
      "model_name": "Devstral Medium 2507",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 4e-7,
      "input_cost_per_million": 0.39999999999999997,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "devstral-small-2505",
      "model_slug": "mistral/devstral-small-2505",
      "model_name": "Devstral Small 2505",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "devstral-small-2507",
      "model_slug": "mistral/devstral-small-2507",
      "model_name": "Devstral Small 2507",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "magistral-medium-2506",
      "model_slug": "mistral/magistral-medium-2506",
      "model_name": "Magistral Medium 2506",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "magistral-medium-latest",
      "model_slug": "mistral/magistral-medium-latest",
      "model_name": "Magistral Medium Latest",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "magistral-small-2506",
      "model_slug": "mistral/magistral-small-2506",
      "model_name": "Magistral Small 2506",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "magistral-small-latest",
      "model_slug": "mistral/magistral-small-latest",
      "model_name": "Magistral Small Latest",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 40000,
      "max_output_tokens": 40000,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-embed",
      "model_slug": "mistral/mistral-embed",
      "model_name": "Mistral Embed",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 8192,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-large-2402",
      "model_slug": "mistral/mistral-large-2402",
      "model_name": "Mistral Large 2402",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000004,
      "input_cost_per_million": 4,
      "output_cost_per_token": 0.000012,
      "output_cost_per_million": 12,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-large-2407",
      "model_slug": "mistral/mistral-large-2407",
      "model_name": "Mistral Large 2407",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000009,
      "output_cost_per_million": 9,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-large-latest",
      "model_slug": "mistral/mistral-large-latest",
      "model_name": "Mistral Large",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-medium",
      "model_slug": "mistral/mistral-medium",
      "model_name": "Mistral Medium",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000027,
      "input_cost_per_million": 2.7,
      "output_cost_per_token": 0.0000081,
      "output_cost_per_million": 8.1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-medium-2312",
      "model_slug": "mistral/mistral-medium-2312",
      "model_name": "Mistral Medium 2312",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.0000027,
      "input_cost_per_million": 2.7,
      "output_cost_per_token": 0.0000081,
      "output_cost_per_million": 8.1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-medium-2505",
      "model_slug": "mistral/mistral-medium-2505",
      "model_name": "Mistral Medium 2505",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 131072,
      "max_output_tokens": 8191,
      "input_cost_per_token": 4e-7,
      "input_cost_per_million": 0.39999999999999997,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-medium-latest",
      "model_slug": "mistral/mistral-medium-latest",
      "model_name": "Mistral Medium 3",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 131072,
      "max_output_tokens": 8191,
      "input_cost_per_token": 4e-7,
      "input_cost_per_million": 0.39999999999999997,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-small",
      "model_slug": "mistral/mistral-small",
      "model_name": "Mistral Small",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-small-latest",
      "model_slug": "mistral/mistral-small-latest",
      "model_name": "Mistral Small",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-tiny",
      "model_slug": "mistral/mistral-tiny",
      "model_name": "Mistral Tiny",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 2.5e-7,
      "output_cost_per_million": 0.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "open-codestral-mamba",
      "model_slug": "mistral/open-codestral-mamba",
      "model_name": "Codestral Mamba",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 2.5e-7,
      "output_cost_per_million": 0.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "open-mistral-7b",
      "model_slug": "mistral/open-mistral-7b",
      "model_name": "Open Mistral 7b",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 2.5e-7,
      "output_cost_per_million": 0.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "open-mistral-nemo",
      "model_slug": "mistral/open-mistral-nemo",
      "model_name": "Mistral NeMo",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "open-mistral-nemo-2407",
      "model_slug": "mistral/open-mistral-nemo-2407",
      "model_name": "Open Mistral Nemo 2407",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "open-mixtral-8x22b",
      "model_slug": "mistral/open-mixtral-8x22b",
      "model_name": "Mixtral 8x22B",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 65336,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "open-mixtral-8x7b",
      "model_slug": "mistral/open-mixtral-8x7b",
      "model_name": "Open Mixtral 8x7b",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 7e-7,
      "input_cost_per_million": 0.7,
      "output_cost_per_token": 7e-7,
      "output_cost_per_million": 0.7,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "pixtral-12b-2409",
      "model_slug": "mistral/pixtral-12b-2409",
      "model_name": "Pixtral 12B",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 1.5e-7,
      "output_cost_per_million": 0.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "pixtral-large-2411",
      "model_slug": "mistral/pixtral-large-2411",
      "model_name": "Pixtral Large 2411",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "pixtral-large-latest",
      "model_slug": "mistral/pixtral-large-latest",
      "model_name": "Pixtral Large",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "text-completion-codestral/codestral-2405",
      "model_slug": "text-completion-codestral/codestral-2405",
      "model_name": "Codestral 2405 | text-completion-codestral",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "text-completion-codestral/codestral-latest",
      "model_slug": "text-completion-codestral/codestral-latest",
      "model_name": "Codestral | text-completion-codestral",
      "provider_id": "mistral",
      "provider_name": "Mistral AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    }
  ],
  "moonshot": [
    {
      "model_id": "moonshot/kimi-k2-0711-preview",
      "model_slug": "moonshot/kimi-k2-0711-preview",
      "model_name": "Kimi K2 0711 Preview | moonshot",
      "provider_id": "moonshot",
      "provider_name": "Moonshot AI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 0.0000025,
      "output_cost_per_million": 2.5,
      "cache_read_cost_per_token": 1.5e-7,
      "cache_read_cost_per_million": 0.15,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "moonshot/moonshot-v1-128k",
      "model_slug": "moonshot/moonshot-v1-128k",
      "model_name": "Moonshot V1 128k | moonshot",
      "provider_id": "moonshot",
      "provider_name": "Moonshot AI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "moonshot/moonshot-v1-128k-0430",
      "model_slug": "moonshot/moonshot-v1-128k-0430",
      "model_name": "Moonshot V1 128k 0430 | moonshot",
      "provider_id": "moonshot",
      "provider_name": "Moonshot AI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "moonshot/moonshot-v1-32k",
      "model_slug": "moonshot/moonshot-v1-32k",
      "model_name": "Moonshot V1 32k | moonshot",
      "provider_id": "moonshot",
      "provider_name": "Moonshot AI",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "moonshot/moonshot-v1-32k-0430",
      "model_slug": "moonshot/moonshot-v1-32k-0430",
      "model_name": "Moonshot V1 32k 0430 | moonshot",
      "provider_id": "moonshot",
      "provider_name": "Moonshot AI",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "moonshot/moonshot-v1-8k",
      "model_slug": "moonshot/moonshot-v1-8k",
      "model_name": "Moonshot V1 8k | moonshot",
      "provider_id": "moonshot",
      "provider_name": "Moonshot AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "moonshot/moonshot-v1-8k-0430",
      "model_slug": "moonshot/moonshot-v1-8k-0430",
      "model_name": "Moonshot V1 8k 0430 | moonshot",
      "provider_id": "moonshot",
      "provider_name": "Moonshot AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "moonshot/moonshot-v1-auto",
      "model_slug": "moonshot/moonshot-v1-auto",
      "model_name": "Moonshot V1 Auto | moonshot",
      "provider_id": "moonshot",
      "provider_name": "Moonshot AI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "nlp": [
    {
      "model_id": "chatdolphin",
      "model_slug": "chatdolphin",
      "model_name": "Chatdolphin",
      "provider_id": "nlp",
      "provider_name": "Nlp",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "dolphin",
      "model_slug": "dolphin",
      "model_name": "Dolphin",
      "provider_id": "nlp",
      "provider_name": "Nlp",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    }
  ],
  "nscale": [
    {
      "model_id": "nscale/black-forest-labs/FLUX.1-schnell",
      "model_slug": "nscale/black-forest-labs/FLUX.1-schnell",
      "model_name": "FLUX.1 Schnell | black-forest-labs | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "model_slug": "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "model_name": "DeepSeek R1 Distill Llama 70B | deepseek-ai | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 3.75e-7,
      "input_cost_per_million": 0.375,
      "output_cost_per_token": 3.75e-7,
      "output_cost_per_million": 0.375,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
      "model_slug": "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
      "model_name": "DeepSeek R1 Distill Llama 8B | deepseek-ai | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 2.5e-8,
      "input_cost_per_million": 0.024999999999999998,
      "output_cost_per_token": 2.5e-8,
      "output_cost_per_million": 0.024999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
      "model_slug": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
      "model_name": "DeepSeek R1 Distill Qwen 1.5B | deepseek-ai | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 9e-8,
      "input_cost_per_million": 0.09,
      "output_cost_per_token": 9e-8,
      "output_cost_per_million": 0.09,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "model_slug": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "model_name": "DeepSeek R1 Distill Qwen 14B | deepseek-ai | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 7e-8,
      "input_cost_per_million": 0.07,
      "output_cost_per_token": 7e-8,
      "output_cost_per_million": 0.07,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "model_slug": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "model_name": "DeepSeek R1 Distill Qwen 32B | deepseek-ai | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 1.5e-7,
      "output_cost_per_million": 0.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "model_slug": "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "model_name": "DeepSeek R1 Distill Qwen 7B | deepseek-ai | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/meta-llama/Llama-3.1-8B-Instruct",
      "model_slug": "nscale/meta-llama/Llama-3.1-8B-Instruct",
      "model_name": "Llama 3.1 8B Instruct | meta-llama | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 3e-8,
      "input_cost_per_million": 0.03,
      "output_cost_per_token": 3e-8,
      "output_cost_per_million": 0.03,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/meta-llama/Llama-3.3-70B-Instruct",
      "model_slug": "nscale/meta-llama/Llama-3.3-70B-Instruct",
      "model_name": "Llama 3.3 70B Instruct | meta-llama | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "model_slug": "nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "model_name": "Llama 4 Scout 17B 16E Instruct | meta-llama | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 9e-8,
      "input_cost_per_million": 0.09,
      "output_cost_per_token": 2.9e-7,
      "output_cost_per_million": 0.29,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/mistralai/mixtral-8x22b-instruct-v0.1",
      "model_slug": "nscale/mistralai/mixtral-8x22b-instruct-v0.1",
      "model_name": "Mixtral 8x22B Instruct v0.1 | mistralai | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/Qwen/Qwen2.5-Coder-32B-Instruct",
      "model_slug": "nscale/Qwen/Qwen2.5-Coder-32B-Instruct",
      "model_name": "Qwen2.5 Coder 32B Instruct | Qwen | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 6e-8,
      "input_cost_per_million": 0.06,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/Qwen/Qwen2.5-Coder-3B-Instruct",
      "model_slug": "nscale/Qwen/Qwen2.5-Coder-3B-Instruct",
      "model_name": "Qwen2.5 Coder 3B Instruct | Qwen | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-8,
      "input_cost_per_million": 0.01,
      "output_cost_per_token": 3e-8,
      "output_cost_per_million": 0.03,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/Qwen/Qwen2.5-Coder-7B-Instruct",
      "model_slug": "nscale/Qwen/Qwen2.5-Coder-7B-Instruct",
      "model_name": "Qwen2.5 Coder 7B Instruct | Qwen | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-8,
      "input_cost_per_million": 0.01,
      "output_cost_per_token": 3e-8,
      "output_cost_per_million": 0.03,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/Qwen/QwQ-32B",
      "model_slug": "nscale/Qwen/QwQ-32B",
      "model_name": "QwQ 32B | Qwen | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1.8e-7,
      "input_cost_per_million": 0.18,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "nscale/stabilityai/stable-diffusion-xl-base-1.0",
      "model_slug": "nscale/stabilityai/stable-diffusion-xl-base-1.0",
      "model_name": "Stable Diffusion Xl Base 1.0 | stabilityai | nscale",
      "provider_id": "nscale",
      "provider_name": "Nscale",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    }
  ],
  "ollama": [
    {
      "model_id": "ollama/codegeex4",
      "model_slug": "ollama/codegeex4",
      "model_name": "Codegeex4 | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/codegemma",
      "model_slug": "ollama/codegemma",
      "model_name": "Codegemma | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/codellama",
      "model_slug": "ollama/codellama",
      "model_name": "Codellama | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/deepseek-coder-v2-base",
      "model_slug": "ollama/deepseek-coder-v2-base",
      "model_name": "Deepseek Coder V2 Base | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/deepseek-coder-v2-instruct",
      "model_slug": "ollama/deepseek-coder-v2-instruct",
      "model_name": "Deepseek Coder V2 Instruct | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/deepseek-coder-v2-lite-base",
      "model_slug": "ollama/deepseek-coder-v2-lite-base",
      "model_name": "Deepseek Coder V2 Lite Base | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/deepseek-coder-v2-lite-instruct",
      "model_slug": "ollama/deepseek-coder-v2-lite-instruct",
      "model_name": "Deepseek Coder V2 Lite Instruct | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/internlm2_5-20b-chat",
      "model_slug": "ollama/internlm2_5-20b-chat",
      "model_name": "Internlm2_5 20b Chat | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/llama2",
      "model_slug": "ollama/llama2",
      "model_name": "Llama2 | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/llama2-uncensored",
      "model_slug": "ollama/llama2-uncensored",
      "model_name": "Llama2 Uncensored | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/llama2:13b",
      "model_slug": "ollama/llama2:13b",
      "model_name": "Llama2:13b | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/llama2:70b",
      "model_slug": "ollama/llama2:70b",
      "model_name": "Llama2:70b | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/llama2:7b",
      "model_slug": "ollama/llama2:7b",
      "model_name": "Llama2:7b | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/llama3",
      "model_slug": "ollama/llama3",
      "model_name": "Llama3 | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/llama3:70b",
      "model_slug": "ollama/llama3:70b",
      "model_name": "Llama3:70b | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/llama3:8b",
      "model_slug": "ollama/llama3:8b",
      "model_name": "Llama3:8b | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/llama3.1",
      "model_slug": "ollama/llama3.1",
      "model_name": "Llama3.1 | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/mistral",
      "model_slug": "ollama/mistral",
      "model_name": "Mistral | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/mistral-7B-Instruct-v0.1",
      "model_slug": "ollama/mistral-7B-Instruct-v0.1",
      "model_name": "Mistral 7B Instruct V0.1 | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/mistral-7B-Instruct-v0.2",
      "model_slug": "ollama/mistral-7B-Instruct-v0.2",
      "model_name": "Mistral 7B Instruct V0.2 | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/mistral-large-instruct-2407",
      "model_slug": "ollama/mistral-large-instruct-2407",
      "model_name": "Mistral Large Instruct 2407 | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/mixtral-8x22B-Instruct-v0.1",
      "model_slug": "ollama/mixtral-8x22B-Instruct-v0.1",
      "model_name": "Mixtral 8x22B Instruct V0.1 | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/mixtral-8x7B-Instruct-v0.1",
      "model_slug": "ollama/mixtral-8x7B-Instruct-v0.1",
      "model_name": "Mixtral 8x7B Instruct V0.1 | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/orca-mini",
      "model_slug": "ollama/orca-mini",
      "model_name": "Orca Mini | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "ollama/vicuna",
      "model_slug": "ollama/vicuna",
      "model_name": "Vicuna | ollama",
      "provider_id": "ollama",
      "provider_name": "Ollama",
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    }
  ],
  "openai": [
    {
      "model_id": "1024-x-1024/dall-e-2",
      "model_slug": "1024-x-1024/dall-e-2",
      "model_name": "Dall E 2 | 1024-x-1024",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "256-x-256/dall-e-2",
      "model_slug": "256-x-256/dall-e-2",
      "model_name": "Dall E 2 | 256-x-256",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "512-x-512/dall-e-2",
      "model_slug": "512-x-512/dall-e-2",
      "model_name": "Dall E 2 | 512-x-512",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "chatgpt-4o-latest",
      "model_slug": "chatgpt-4o-latest",
      "model_name": "ChatGPT-4o",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codex-mini-latest",
      "model_slug": "codex-mini-latest",
      "model_name": "Codex Mini Latest",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.0000015,
      "input_cost_per_million": 1.5,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": 3.75e-7,
      "cache_read_cost_per_million": 0.375,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ft:gpt-3.5-turbo",
      "model_slug": "ft:gpt-3.5-turbo",
      "model_name": "Ft:GPT 3.5 Turbo",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ft:gpt-3.5-turbo-0125",
      "model_slug": "ft:gpt-3.5-turbo-0125",
      "model_name": "Ft:GPT 3.5 Turbo 0125",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ft:gpt-3.5-turbo-0613",
      "model_slug": "ft:gpt-3.5-turbo-0613",
      "model_name": "Ft:GPT 3.5 Turbo 0613",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ft:gpt-3.5-turbo-1106",
      "model_slug": "ft:gpt-3.5-turbo-1106",
      "model_name": "Ft:GPT 3.5 Turbo 1106",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ft:gpt-4-0613",
      "model_slug": "ft:gpt-4-0613",
      "model_name": "Ft:GPT 4 0613",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "input_cost_per_million": 30,
      "output_cost_per_token": 0.00006,
      "output_cost_per_million": 60,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ft:gpt-4o-2024-08-06",
      "model_slug": "ft:gpt-4o-2024-08-06",
      "model_name": "Ft:GPT 4o 2024 08 06",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000375,
      "input_cost_per_million": 3.75,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ft:gpt-4o-2024-11-20",
      "model_slug": "ft:gpt-4o-2024-11-20",
      "model_name": "Ft:GPT 4o 2024 11 20",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.00000375,
      "input_cost_per_million": 3.75,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": 0.000001875,
      "cache_write_cost_per_million": 1.875,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "ft:gpt-4o-mini-2024-07-18",
      "model_slug": "ft:gpt-4o-mini-2024-07-18",
      "model_name": "Ft:GPT 4o Mini 2024 07 18",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 0.0000012,
      "output_cost_per_million": 1.2,
      "cache_read_cost_per_token": 1.5e-7,
      "cache_read_cost_per_million": 0.15,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-3.5-turbo-0301",
      "model_slug": "gpt-3.5-turbo-0301",
      "model_name": "GPT 3.5 Turbo 0301",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "input_cost_per_million": 1.5,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-3.5-turbo-0613",
      "model_slug": "gpt-3.5-turbo-0613",
      "model_name": "GPT 3.5 Turbo 0613",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 4097,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "input_cost_per_million": 1.5,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-3.5-turbo-1106",
      "model_slug": "gpt-3.5-turbo-1106",
      "model_name": "GPT 3.5T 1106",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-3.5-turbo-16k",
      "model_slug": "gpt-3.5-turbo-16k",
      "model_name": "GPT 3.5T 16k",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000004,
      "output_cost_per_million": 4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-3.5-turbo-16k-0613",
      "model_slug": "gpt-3.5-turbo-16k-0613",
      "model_name": "GPT 3.5 Turbo 16k 0613",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000004,
      "output_cost_per_million": 4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4-0314",
      "model_slug": "gpt-4-0314",
      "model_name": "GPT 4 0314",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00003,
      "input_cost_per_million": 30,
      "output_cost_per_token": 0.00006,
      "output_cost_per_million": 60,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4-1106-vision-preview",
      "model_slug": "gpt-4-1106-vision-preview",
      "model_name": "GPT 4 1106 Vision Preview",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00003,
      "output_cost_per_million": 30,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2024-12-06"
    },
    {
      "model_id": "gpt-4-32k-0314",
      "model_slug": "gpt-4-32k-0314",
      "model_name": "GPT 4 32k 0314",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00006,
      "input_cost_per_million": 60,
      "output_cost_per_token": 0.00012,
      "output_cost_per_million": 120,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4-turbo-preview",
      "model_slug": "gpt-4-turbo-preview",
      "model_name": "GPT-4 Turbo Preview",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00003,
      "output_cost_per_million": 30,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4-vision-preview",
      "model_slug": "gpt-4-vision-preview",
      "model_name": "GPT 4 Vision-Preview",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00003,
      "output_cost_per_million": 30,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2024-12-06"
    },
    {
      "model_id": "gpt-4.5-preview-2025-02-27",
      "model_slug": "gpt-4.5-preview-2025-02-27",
      "model_name": "GPT 4.5 Preview 2025 02 27",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000075,
      "input_cost_per_million": 75,
      "output_cost_per_token": 0.00015,
      "output_cost_per_million": 150,
      "cache_read_cost_per_token": 0.0000375,
      "cache_read_cost_per_million": 37.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-07-14"
    },
    {
      "model_id": "gpt-4o-audio-preview",
      "model_slug": "gpt-4o-audio-preview",
      "model_name": "GPT 4o Audio Preview",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-audio-preview-2024-10-01",
      "model_slug": "gpt-4o-audio-preview-2024-10-01",
      "model_name": "GPT 4o Audio Preview 2024 10 01",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-audio-preview-2025-06-03",
      "model_slug": "gpt-4o-audio-preview-2025-06-03",
      "model_name": "GPT 4o Audio Preview 2025 06 03",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-mini-audio-preview",
      "model_slug": "gpt-4o-mini-audio-preview",
      "model_name": "GPT 4o Mini Audio Preview",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-mini-realtime-preview",
      "model_slug": "gpt-4o-mini-realtime-preview",
      "model_name": "GPT 4o Mini Realtime Preview",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 0.0000024,
      "output_cost_per_million": 2.4,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-mini-search-preview",
      "model_slug": "gpt-4o-mini-search-preview",
      "model_name": "GPT-4o mini Search Preview",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": 7.5e-8,
      "cache_read_cost_per_million": 0.075,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-mini-search-preview-2025-03-11",
      "model_slug": "gpt-4o-mini-search-preview-2025-03-11",
      "model_name": "GPT 4o Mini Search Preview 2025 03 11",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": 7.5e-8,
      "cache_read_cost_per_million": 0.075,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-realtime-preview",
      "model_slug": "gpt-4o-realtime-preview",
      "model_name": "GPT 4o Realtime Preview",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.00002,
      "output_cost_per_million": 20,
      "cache_read_cost_per_token": 0.0000025,
      "cache_read_cost_per_million": 2.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-search-preview",
      "model_slug": "gpt-4o-search-preview",
      "model_name": "GPT-4o Search Preview",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 0.00000125,
      "cache_read_cost_per_million": 1.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-4o-search-preview-2025-03-11",
      "model_slug": "gpt-4o-search-preview-2025-03-11",
      "model_name": "GPT 4o Search Preview 2025 03 11",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 0.00000125,
      "cache_read_cost_per_million": 1.25,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o1-pro",
      "model_slug": "o1-pro",
      "model_name": "o1 Pro",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.00015,
      "input_cost_per_million": 150,
      "output_cost_per_token": 0.0006,
      "output_cost_per_million": 600,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o1-pro-2025-03-19",
      "model_slug": "o1-pro-2025-03-19",
      "model_name": "O1 Pro 2025 03 19",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.00015,
      "input_cost_per_million": 150,
      "output_cost_per_token": 0.0006,
      "output_cost_per_million": 600,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o3-deep-research-2025-06-26",
      "model_slug": "o3-deep-research-2025-06-26",
      "model_name": "O3 Deep Research 2025 06 26",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00004,
      "output_cost_per_million": 40,
      "cache_read_cost_per_token": 0.0000025,
      "cache_read_cost_per_million": 2.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o4-mini-deep-research",
      "model_slug": "o4-mini-deep-research",
      "model_name": "O4 Mini Deep Research",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": 5e-7,
      "cache_read_cost_per_million": 0.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "o4-mini-deep-research-2025-06-26",
      "model_slug": "o4-mini-deep-research-2025-06-26",
      "model_name": "O4 Mini Deep Research 2025 06 26",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": 5e-7,
      "cache_read_cost_per_million": 0.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "omni-moderation-2024-09-26",
      "model_slug": "omni-moderation-2024-09-26",
      "model_name": "Omni Moderation 2024 09 26",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 32768,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "moderation",
      "deprecation_date": null
    },
    {
      "model_id": "omni-moderation-latest",
      "model_slug": "omni-moderation-latest",
      "model_name": "Omni Moderation Latest",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 32768,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "moderation",
      "deprecation_date": null
    },
    {
      "model_id": "omni-moderation-latest-intents",
      "model_slug": "omni-moderation-latest-intents",
      "model_name": "Omni Moderation Latest Intents",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 32768,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "moderation",
      "deprecation_date": null
    },
    {
      "model_id": "text-embedding-ada-002-v2",
      "model_slug": "text-embedding-ada-002-v2",
      "model_name": "Text Embedding Ada 002 V2",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 8191,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "text-moderation-007",
      "model_slug": "text-moderation-007",
      "model_name": "Text Moderation 007",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 32768,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "moderation",
      "deprecation_date": null
    },
    {
      "model_id": "text-moderation-latest",
      "model_slug": "text-moderation-latest",
      "model_name": "Text Moderation Latest",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 32768,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "moderation",
      "deprecation_date": null
    },
    {
      "model_id": "text-moderation-stable",
      "model_slug": "text-moderation-stable",
      "model_name": "Text Moderation Stable",
      "provider_id": "openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 32768,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "moderation",
      "deprecation_date": null
    }
  ],
  "openrouter": [
    {
      "model_id": "openrouter/anthropic/claude-2",
      "model_slug": "openrouter/anthropic/claude-2",
      "model_name": "Claude 2 | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00001102,
      "input_cost_per_million": 11.02,
      "output_cost_per_token": 0.00003268,
      "output_cost_per_million": 32.68,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/anthropic/claude-3-5-haiku",
      "model_slug": "openrouter/anthropic/claude-3-5-haiku",
      "model_name": "Claude 3 5 Haiku | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/anthropic/claude-3-5-haiku-20241022",
      "model_slug": "openrouter/anthropic/claude-3-5-haiku-20241022",
      "model_name": "Claude 3.5 Haiku (Oct 2024) | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/anthropic/claude-3-haiku",
      "model_slug": "openrouter/anthropic/claude-3-haiku",
      "model_name": "Claude 3 Haiku | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 0.00000125,
      "output_cost_per_million": 1.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/anthropic/claude-3-haiku-20240307",
      "model_slug": "openrouter/anthropic/claude-3-haiku-20240307",
      "model_name": "Claude 3 Haiku | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 0.00000125,
      "output_cost_per_million": 1.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/anthropic/claude-3-opus",
      "model_slug": "openrouter/anthropic/claude-3-opus",
      "model_name": "Claude 3 Opus | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/anthropic/claude-3-sonnet",
      "model_slug": "openrouter/anthropic/claude-3-sonnet",
      "model_name": "Claude 3 Sonnet | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/anthropic/claude-3.5-sonnet",
      "model_slug": "openrouter/anthropic/claude-3.5-sonnet",
      "model_name": "Claude 3.5 Sonnet | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/anthropic/claude-3.5-sonnet:beta",
      "model_slug": "openrouter/anthropic/claude-3.5-sonnet:beta",
      "model_name": "Claude 3.5 Sonnet:beta | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/anthropic/claude-3.7-sonnet",
      "model_slug": "openrouter/anthropic/claude-3.7-sonnet",
      "model_name": "Claude 3.7 Sonnet | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/anthropic/claude-3.7-sonnet:beta",
      "model_slug": "openrouter/anthropic/claude-3.7-sonnet:beta",
      "model_name": "Claude 3.7 Sonnet:beta | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/anthropic/claude-instant-v1",
      "model_slug": "openrouter/anthropic/claude-instant-v1",
      "model_name": "Claude Instant V1 | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.00000163,
      "input_cost_per_million": 1.6300000000000001,
      "output_cost_per_token": 0.00000551,
      "output_cost_per_million": 5.51,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/anthropic/claude-sonnet-4",
      "model_slug": "openrouter/anthropic/claude-sonnet-4",
      "model_name": "Claude Sonnet 4 | anthropic | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/cognitivecomputations/dolphin-mixtral-8x7b",
      "model_slug": "openrouter/cognitivecomputations/dolphin-mixtral-8x7b",
      "model_name": "Dolphin Mixtral 8x7b | cognitivecomputations | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/cohere/command-r-plus",
      "model_slug": "openrouter/cohere/command-r-plus",
      "model_name": "Command R Plus | cohere | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/databricks/dbrx-instruct",
      "model_slug": "openrouter/databricks/dbrx-instruct",
      "model_name": "DBRX Instruct | databricks | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/deepseek/deepseek-chat",
      "model_slug": "openrouter/deepseek/deepseek-chat",
      "model_name": "Deepseek Chat | deepseek | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.4e-7,
      "input_cost_per_million": 0.14,
      "output_cost_per_token": 2.8e-7,
      "output_cost_per_million": 0.28,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/deepseek/deepseek-coder",
      "model_slug": "openrouter/deepseek/deepseek-coder",
      "model_name": "Deepseek Coder | deepseek | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 66000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.4e-7,
      "input_cost_per_million": 0.14,
      "output_cost_per_token": 2.8e-7,
      "output_cost_per_million": 0.28,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/deepseek/deepseek-r1",
      "model_slug": "openrouter/deepseek/deepseek-r1",
      "model_name": "DeepSeek R1 | deepseek | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 65336,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5.5e-7,
      "input_cost_per_million": 0.55,
      "output_cost_per_token": 0.00000219,
      "output_cost_per_million": 2.1900000000000004,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/deepseek/deepseek-r1-0528",
      "model_slug": "openrouter/deepseek/deepseek-r1-0528",
      "model_name": "Deepseek R1 0528 | deepseek | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 65336,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.00000215,
      "output_cost_per_million": 2.1500000000000004,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/fireworks/firellava-13b",
      "model_slug": "openrouter/fireworks/firellava-13b",
      "model_name": "Firellava 13b | fireworks | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/google/gemini-2.0-flash-001",
      "model_slug": "openrouter/google/gemini-2.0-flash-001",
      "model_name": "Gemini 2.0 Flash 001 | google | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/google/gemini-2.5-flash",
      "model_slug": "openrouter/google/gemini-2.5-flash",
      "model_name": "Gemini 2.5 Flash | google | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 0.0000025,
      "output_cost_per_million": 2.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/google/gemini-2.5-pro",
      "model_slug": "openrouter/google/gemini-2.5-pro",
      "model_name": "Gemini 2.5 Pro | google | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/google/gemini-pro-1.5",
      "model_slug": "openrouter/google/gemini-pro-1.5",
      "model_name": "Gemini Pro 1.5 | google | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.0000075,
      "output_cost_per_million": 7.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/google/gemini-pro-vision",
      "model_slug": "openrouter/google/gemini-pro-vision",
      "model_name": "Gemini Pro Vision | google | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 3.75e-7,
      "output_cost_per_million": 0.375,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/google/palm-2-chat-bison",
      "model_slug": "openrouter/google/palm-2-chat-bison",
      "model_name": "Palm 2 Chat Bison | google | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/google/palm-2-codechat-bison",
      "model_slug": "openrouter/google/palm-2-codechat-bison",
      "model_name": "Palm 2 Codechat Bison | google | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/gryphe/mythomax-l2-13b",
      "model_slug": "openrouter/gryphe/mythomax-l2-13b",
      "model_name": "MythoMax L2 (13B) | gryphe | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000001875,
      "input_cost_per_million": 1.875,
      "output_cost_per_token": 0.000001875,
      "output_cost_per_million": 1.875,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/jondurbin/airoboros-l2-70b-2.1",
      "model_slug": "openrouter/jondurbin/airoboros-l2-70b-2.1",
      "model_name": "Airoboros L2 70b 2.1 | jondurbin | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000013875,
      "input_cost_per_million": 13.875,
      "output_cost_per_token": 0.000013875,
      "output_cost_per_million": 13.875,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/mancer/weaver",
      "model_slug": "openrouter/mancer/weaver",
      "model_name": "Weaver | mancer | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000005625,
      "input_cost_per_million": 5.625,
      "output_cost_per_token": 0.000005625,
      "output_cost_per_million": 5.625,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/meta-llama/codellama-34b-instruct",
      "model_slug": "openrouter/meta-llama/codellama-34b-instruct",
      "model_name": "Codellama 34b Instruct | meta-llama | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/meta-llama/llama-2-13b-chat",
      "model_slug": "openrouter/meta-llama/llama-2-13b-chat",
      "model_name": "Llama 2 13b Chat | meta-llama | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/meta-llama/llama-2-70b-chat",
      "model_slug": "openrouter/meta-llama/llama-2-70b-chat",
      "model_name": "LLaMA 2 70b Chat | meta-llama | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.0000015,
      "input_cost_per_million": 1.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/meta-llama/llama-3-70b-instruct",
      "model_slug": "openrouter/meta-llama/llama-3-70b-instruct",
      "model_name": "Llama 3 70b Instruct | meta-llama | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 5.9e-7,
      "input_cost_per_million": 0.59,
      "output_cost_per_token": 7.9e-7,
      "output_cost_per_million": 0.7899999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/meta-llama/llama-3-70b-instruct:nitro",
      "model_slug": "openrouter/meta-llama/llama-3-70b-instruct:nitro",
      "model_name": "Llama 3 70b Instruct:nitro | meta-llama | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 9e-7,
      "input_cost_per_million": 0.8999999999999999,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/meta-llama/llama-3-8b-instruct:extended",
      "model_slug": "openrouter/meta-llama/llama-3-8b-instruct:extended",
      "model_name": "Llama 3 8b Instruct:extended | meta-llama | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 2.25e-7,
      "input_cost_per_million": 0.22499999999999998,
      "output_cost_per_token": 0.00000225,
      "output_cost_per_million": 2.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/meta-llama/llama-3-8b-instruct:free",
      "model_slug": "openrouter/meta-llama/llama-3-8b-instruct:free",
      "model_name": "Llama 3 8b Instruct:free | meta-llama | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/microsoft/wizardlm-2-8x22b:nitro",
      "model_slug": "openrouter/microsoft/wizardlm-2-8x22b:nitro",
      "model_name": "Wizardlm 2 8x22b:nitro | microsoft | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000001,
      "output_cost_per_million": 1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/mistralai/mistral-7b-instruct",
      "model_slug": "openrouter/mistralai/mistral-7b-instruct",
      "model_name": "Mistral 7b Instruct | mistralai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1.3e-7,
      "input_cost_per_million": 0.13,
      "output_cost_per_token": 1.3e-7,
      "output_cost_per_million": 0.13,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/mistralai/mistral-7b-instruct:free",
      "model_slug": "openrouter/mistralai/mistral-7b-instruct:free",
      "model_name": "Mistral 7b Instruct:free | mistralai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/mistralai/mistral-large",
      "model_slug": "openrouter/mistralai/mistral-large",
      "model_name": "Mistral Large | mistralai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000008,
      "input_cost_per_million": 8,
      "output_cost_per_token": 0.000024,
      "output_cost_per_million": 24,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/mistralai/mistral-small-3.1-24b-instruct",
      "model_slug": "openrouter/mistralai/mistral-small-3.1-24b-instruct",
      "model_name": "Mistral Small 3.1 24b Instruct | mistralai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/mistralai/mistral-small-3.2-24b-instruct",
      "model_slug": "openrouter/mistralai/mistral-small-3.2-24b-instruct",
      "model_name": "Mistral Small 3.2 24b Instruct | mistralai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/mistralai/mixtral-8x22b-instruct",
      "model_slug": "openrouter/mistralai/mixtral-8x22b-instruct",
      "model_name": "Mixtral 8x22b Instruct | mistralai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 6.5e-7,
      "input_cost_per_million": 0.65,
      "output_cost_per_token": 6.5e-7,
      "output_cost_per_million": 0.65,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/nousresearch/nous-hermes-llama2-13b",
      "model_slug": "openrouter/nousresearch/nous-hermes-llama2-13b",
      "model_name": "Nous: Hermes 13B | nousresearch | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/gpt-3.5-turbo",
      "model_slug": "openrouter/openai/gpt-3.5-turbo",
      "model_name": "GPT 3.5T | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.0000015,
      "input_cost_per_million": 1.5,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/gpt-3.5-turbo-16k",
      "model_slug": "openrouter/openai/gpt-3.5-turbo-16k",
      "model_name": "GPT 3.5T 16k | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000004,
      "output_cost_per_million": 4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/gpt-4",
      "model_slug": "openrouter/openai/gpt-4",
      "model_name": "GPT 4 | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.00003,
      "input_cost_per_million": 30,
      "output_cost_per_token": 0.00006,
      "output_cost_per_million": 60,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/gpt-4-vision-preview",
      "model_slug": "openrouter/openai/gpt-4-vision-preview",
      "model_name": "GPT 4 Vision Preview | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.00003,
      "output_cost_per_million": 30,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/gpt-4o",
      "model_slug": "openrouter/openai/gpt-4o",
      "model_name": "GPT 4o | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000025,
      "input_cost_per_million": 2.5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/gpt-4o-2024-05-13",
      "model_slug": "openrouter/openai/gpt-4o-2024-05-13",
      "model_name": "GPT 4o (May 2024) | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/o1",
      "model_slug": "openrouter/openai/o1",
      "model_name": "O1 | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.00006,
      "output_cost_per_million": 60,
      "cache_read_cost_per_token": 0.0000075,
      "cache_read_cost_per_million": 7.5,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/o1-mini",
      "model_slug": "openrouter/openai/o1-mini",
      "model_name": "O1 mini | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000012,
      "output_cost_per_million": 12,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/o1-mini-2024-09-12",
      "model_slug": "openrouter/openai/o1-mini-2024-09-12",
      "model_name": "O1 Mini 2024 09 12 | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000012,
      "output_cost_per_million": 12,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/o1-preview",
      "model_slug": "openrouter/openai/o1-preview",
      "model_name": "O1 Preview | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.00006,
      "output_cost_per_million": 60,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/o1-preview-2024-09-12",
      "model_slug": "openrouter/openai/o1-preview-2024-09-12",
      "model_name": "O1 Preview 2024 09 12 | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.00006,
      "output_cost_per_million": 60,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/o3-mini",
      "model_slug": "openrouter/openai/o3-mini",
      "model_name": "O3 mini | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.0000011,
      "input_cost_per_million": 1.1,
      "output_cost_per_token": 0.0000044,
      "output_cost_per_million": 4.4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/openai/o3-mini-high",
      "model_slug": "openrouter/openai/o3-mini-high",
      "model_name": "O3 Mini High | openai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0.0000011,
      "input_cost_per_million": 1.1,
      "output_cost_per_token": 0.0000044,
      "output_cost_per_million": 4.4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/pygmalionai/mythalion-13b",
      "model_slug": "openrouter/pygmalionai/mythalion-13b",
      "model_name": "Mythalion 13b | pygmalionai | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000001875,
      "input_cost_per_million": 1.875,
      "output_cost_per_token": 0.000001875,
      "output_cost_per_million": 1.875,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/qwen/qwen-2.5-coder-32b-instruct",
      "model_slug": "openrouter/qwen/qwen-2.5-coder-32b-instruct",
      "model_name": "Qwen 2.5 Coder 32B Instruct | qwen | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": 33792,
      "max_output_tokens": 33792,
      "input_cost_per_token": 1.8e-7,
      "input_cost_per_million": 0.18,
      "output_cost_per_token": 1.8e-7,
      "output_cost_per_million": 0.18,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "openrouter/undi95/remm-slerp-l2-13b",
      "model_slug": "openrouter/undi95/remm-slerp-l2-13b",
      "model_name": "Remm Slerp L2 13b | undi95 | openrouter",
      "provider_id": "openrouter",
      "provider_name": "OpenRouter",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000001875,
      "input_cost_per_million": 1.875,
      "output_cost_per_token": 0.000001875,
      "output_cost_per_million": 1.875,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "palm": [
    {
      "model_id": "palm/chat-bison",
      "model_slug": "palm/chat-bison",
      "model_name": "Chat Bison | palm",
      "provider_id": "palm",
      "provider_name": "Palm AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "palm/chat-bison-001",
      "model_slug": "palm/chat-bison-001",
      "model_name": "Chat Bison 001 | palm",
      "provider_id": "palm",
      "provider_name": "Palm AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "palm/text-bison",
      "model_slug": "palm/text-bison",
      "model_name": "Text Bison | palm",
      "provider_id": "palm",
      "provider_name": "Palm AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "palm/text-bison-001",
      "model_slug": "palm/text-bison-001",
      "model_name": "Text Bison 001 | palm",
      "provider_id": "palm",
      "provider_name": "Palm AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "palm/text-bison-safety-off",
      "model_slug": "palm/text-bison-safety-off",
      "model_name": "Text Bison Safety Off | palm",
      "provider_id": "palm",
      "provider_name": "Palm AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "palm/text-bison-safety-recitation-off",
      "model_slug": "palm/text-bison-safety-recitation-off",
      "model_name": "Text Bison Safety Recitation Off | palm",
      "provider_id": "palm",
      "provider_name": "Palm AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    }
  ],
  "perplexity": [
    {
      "model_id": "codellama-34b-instruct",
      "model_slug": "perplexity/codellama-34b-instruct",
      "model_name": "Codellama 34b Instruct",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_million": 0.35,
      "output_cost_per_token": 0.0000014,
      "output_cost_per_million": 1.4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codellama-70b-instruct",
      "model_slug": "perplexity/codellama-70b-instruct",
      "model_name": "Codellama 70b Instruct",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 7e-7,
      "input_cost_per_million": 0.7,
      "output_cost_per_token": 0.0000028,
      "output_cost_per_million": 2.8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "llama-2-70b-chat",
      "model_slug": "perplexity/llama-2-70b-chat",
      "model_name": "LLaMA 2 70b Chat",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "input_cost_per_million": 0.7,
      "output_cost_per_token": 0.0000028,
      "output_cost_per_million": 2.8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "llama-3.1-70b-instruct",
      "model_slug": "perplexity/llama-3.1-70b-instruct",
      "model_name": "Llama 3.1 70b Instruct",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000001,
      "output_cost_per_million": 1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "llama-3.1-8b-instruct",
      "model_slug": "perplexity/llama-3.1-8b-instruct",
      "model_name": "Llama 3.1 8b Instruct",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "llama-3.1-sonar-huge-128k-online",
      "model_slug": "perplexity/llama-3.1-sonar-huge-128k-online",
      "model_name": "Llama 3.1 Sonar Huge 128k Online",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 127072,
      "max_output_tokens": 127072,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-02-22"
    },
    {
      "model_id": "llama-3.1-sonar-large-128k-chat",
      "model_slug": "perplexity/llama-3.1-sonar-large-128k-chat",
      "model_name": "Llama 3.1 Sonar Large 128k Chat",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000001,
      "output_cost_per_million": 1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-02-22"
    },
    {
      "model_id": "llama-3.1-sonar-large-128k-online",
      "model_slug": "perplexity/llama-3.1-sonar-large-128k-online",
      "model_name": "Llama 3.1 Sonar Large 128k Online",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 127072,
      "max_output_tokens": 127072,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000001,
      "output_cost_per_million": 1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-02-22"
    },
    {
      "model_id": "llama-3.1-sonar-small-128k-chat",
      "model_slug": "perplexity/llama-3.1-sonar-small-128k-chat",
      "model_name": "Llama 3.1 Sonar Small 128k Chat",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-02-22"
    },
    {
      "model_id": "llama-3.1-sonar-small-128k-online",
      "model_slug": "perplexity/llama-3.1-sonar-small-128k-online",
      "model_name": "Llama 3.1 Sonar Small 128k Online",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 127072,
      "max_output_tokens": 127072,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-02-22"
    },
    {
      "model_id": "mistral-7b-instruct",
      "model_slug": "perplexity/mistral-7b-instruct",
      "model_name": "Mistral 7b Instruct",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-8,
      "input_cost_per_million": 0.07,
      "output_cost_per_token": 2.8e-7,
      "output_cost_per_million": 0.28,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mixtral-8x7b-instruct",
      "model_slug": "perplexity/mixtral-8x7b-instruct",
      "model_name": "Mixtral 8x7b Instruct",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-8,
      "input_cost_per_million": 0.07,
      "output_cost_per_token": 2.8e-7,
      "output_cost_per_million": 0.28,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "pplx-70b-chat",
      "model_slug": "perplexity/pplx-70b-chat",
      "model_name": "Pplx 70b Chat",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 7e-7,
      "input_cost_per_million": 0.7,
      "output_cost_per_token": 0.0000028,
      "output_cost_per_million": 2.8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "pplx-70b-online",
      "model_slug": "perplexity/pplx-70b-online",
      "model_name": "Pplx 70b Online",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0.0000028,
      "output_cost_per_million": 2.8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "pplx-7b-chat",
      "model_slug": "perplexity/pplx-7b-chat",
      "model_name": "Pplx 7b Chat",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7e-8,
      "input_cost_per_million": 0.07,
      "output_cost_per_token": 2.8e-7,
      "output_cost_per_million": 0.28,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "pplx-7b-online",
      "model_slug": "perplexity/pplx-7b-online",
      "model_name": "Pplx 7b Online",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 2.8e-7,
      "output_cost_per_million": 0.28,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sonar",
      "model_slug": "perplexity/sonar",
      "model_name": "Sonar",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 128000,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000001,
      "output_cost_per_million": 1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sonar-deep-research",
      "model_slug": "perplexity/sonar-deep-research",
      "model_name": "Sonar Deep Research",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 128000,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sonar-medium-chat",
      "model_slug": "perplexity/sonar-medium-chat",
      "model_name": "Sonar Medium Chat",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 0.0000018,
      "output_cost_per_million": 1.7999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sonar-medium-online",
      "model_slug": "perplexity/sonar-medium-online",
      "model_name": "Sonar Medium Online",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 12000,
      "max_output_tokens": 12000,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0.0000018,
      "output_cost_per_million": 1.7999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sonar-pro",
      "model_slug": "perplexity/sonar-pro",
      "model_name": "Sonar Pro",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 8000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sonar-reasoning",
      "model_slug": "perplexity/sonar-reasoning",
      "model_name": "Sonar Reasoning",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 128000,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sonar-reasoning-pro",
      "model_slug": "perplexity/sonar-reasoning-pro",
      "model_name": "Sonar Reasoning Pro",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 128000,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000008,
      "output_cost_per_million": 8,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sonar-small-chat",
      "model_slug": "perplexity/sonar-small-chat",
      "model_name": "Sonar Small Chat",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 7e-8,
      "input_cost_per_million": 0.07,
      "output_cost_per_token": 2.8e-7,
      "output_cost_per_million": 0.28,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sonar-small-online",
      "model_slug": "perplexity/sonar-small-online",
      "model_name": "Sonar Small Online",
      "provider_id": "perplexity",
      "provider_name": "Perplexity AI",
      "max_input_tokens": 12000,
      "max_output_tokens": 12000,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 2.8e-7,
      "output_cost_per_million": 0.28,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "replicate": [
    {
      "model_id": "meta/llama-2-13b",
      "model_slug": "replicate/meta/llama-2-13b",
      "model_name": "Llama 2 13b | meta",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-2-13b-chat",
      "model_slug": "replicate/meta/llama-2-13b-chat",
      "model_name": "Llama 2 13b Chat | meta",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-2-70b",
      "model_slug": "replicate/meta/llama-2-70b",
      "model_name": "Llama 2 70b | meta",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6.5e-7,
      "input_cost_per_million": 0.65,
      "output_cost_per_token": 0.00000275,
      "output_cost_per_million": 2.75,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-2-70b-chat",
      "model_slug": "replicate/meta/llama-2-70b-chat",
      "model_name": "LLaMA 2 70b Chat | meta",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 6.5e-7,
      "input_cost_per_million": 0.65,
      "output_cost_per_token": 0.00000275,
      "output_cost_per_million": 2.75,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-2-7b",
      "model_slug": "replicate/meta/llama-2-7b",
      "model_name": "Llama 2 7b | meta",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-8,
      "input_cost_per_million": 0.049999999999999996,
      "output_cost_per_token": 2.5e-7,
      "output_cost_per_million": 0.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-2-7b-chat",
      "model_slug": "replicate/meta/llama-2-7b-chat",
      "model_name": "Llama 2 7b Chat | meta",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-8,
      "input_cost_per_million": 0.049999999999999996,
      "output_cost_per_token": 2.5e-7,
      "output_cost_per_million": 0.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-3-70b",
      "model_slug": "replicate/meta/llama-3-70b",
      "model_name": "Llama 3 70b | meta",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 6.5e-7,
      "input_cost_per_million": 0.65,
      "output_cost_per_token": 0.00000275,
      "output_cost_per_million": 2.75,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-3-70b-instruct",
      "model_slug": "replicate/meta/llama-3-70b-instruct",
      "model_name": "Llama 3 70b Instruct | meta",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 6.5e-7,
      "input_cost_per_million": 0.65,
      "output_cost_per_token": 0.00000275,
      "output_cost_per_million": 2.75,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-3-8b",
      "model_slug": "replicate/meta/llama-3-8b",
      "model_name": "Llama 3 8b | meta",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 8086,
      "max_output_tokens": 8086,
      "input_cost_per_token": 5e-8,
      "input_cost_per_million": 0.049999999999999996,
      "output_cost_per_token": 2.5e-7,
      "output_cost_per_million": 0.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-3-8b-instruct",
      "model_slug": "replicate/meta/llama-3-8b-instruct",
      "model_name": "Llama 3 8b Instruct | meta",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 8086,
      "max_output_tokens": 8086,
      "input_cost_per_token": 5e-8,
      "input_cost_per_million": 0.049999999999999996,
      "output_cost_per_token": 2.5e-7,
      "output_cost_per_million": 0.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistralai/mistral-7b-instruct-v0.2",
      "model_slug": "replicate/mistralai/mistral-7b-instruct-v0.2",
      "model_name": "Mistral (7B) Instruct v0.2 | mistralai",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-8,
      "input_cost_per_million": 0.049999999999999996,
      "output_cost_per_token": 2.5e-7,
      "output_cost_per_million": 0.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistralai/mistral-7b-v0.1",
      "model_slug": "replicate/mistralai/mistral-7b-v0.1",
      "model_name": "Mistral 7b V0.1 | mistralai",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-8,
      "input_cost_per_million": 0.049999999999999996,
      "output_cost_per_token": 2.5e-7,
      "output_cost_per_million": 0.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistralai/mixtral-8x7b-instruct-v0.1",
      "model_slug": "replicate/mistralai/mixtral-8x7b-instruct-v0.1",
      "model_name": "Mixtral 8x7B Instruct v0.1 | mistralai",
      "provider_id": "replicate",
      "provider_name": "Replicate",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 0.000001,
      "output_cost_per_million": 1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "sagemaker": [
    {
      "model_id": "sagemaker/meta-textgeneration-llama-2-13b",
      "model_slug": "sagemaker/meta-textgeneration-llama-2-13b",
      "model_name": "Meta Textgeneration Llama 2 13b | sagemaker",
      "provider_id": "sagemaker",
      "provider_name": "AWS Sage Maker",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "sagemaker/meta-textgeneration-llama-2-13b-f",
      "model_slug": "sagemaker/meta-textgeneration-llama-2-13b-f",
      "model_name": "Meta Textgeneration Llama 2 13b F | sagemaker",
      "provider_id": "sagemaker",
      "provider_name": "AWS Sage Maker",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sagemaker/meta-textgeneration-llama-2-70b",
      "model_slug": "sagemaker/meta-textgeneration-llama-2-70b",
      "model_name": "Meta Textgeneration Llama 2 70b | sagemaker",
      "provider_id": "sagemaker",
      "provider_name": "AWS Sage Maker",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "sagemaker/meta-textgeneration-llama-2-70b-b-f",
      "model_slug": "sagemaker/meta-textgeneration-llama-2-70b-b-f",
      "model_name": "Meta Textgeneration Llama 2 70b B F | sagemaker",
      "provider_id": "sagemaker",
      "provider_name": "AWS Sage Maker",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sagemaker/meta-textgeneration-llama-2-7b",
      "model_slug": "sagemaker/meta-textgeneration-llama-2-7b",
      "model_name": "Meta Textgeneration Llama 2 7b | sagemaker",
      "provider_id": "sagemaker",
      "provider_name": "AWS Sage Maker",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "sagemaker/meta-textgeneration-llama-2-7b-f",
      "model_slug": "sagemaker/meta-textgeneration-llama-2-7b-f",
      "model_name": "Meta Textgeneration Llama 2 7b F | sagemaker",
      "provider_id": "sagemaker",
      "provider_name": "AWS Sage Maker",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "sambanova": [
    {
      "model_id": "sambanova/DeepSeek-R1",
      "model_slug": "sambanova/DeepSeek-R1",
      "model_name": "DeepSeek R1 | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.000007,
      "output_cost_per_million": 7,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/DeepSeek-R1-Distill-Llama-70B",
      "model_slug": "sambanova/DeepSeek-R1-Distill-Llama-70B",
      "model_name": "DeepSeek R1 Distill Llama 70B | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 7e-7,
      "input_cost_per_million": 0.7,
      "output_cost_per_token": 0.0000014,
      "output_cost_per_million": 1.4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/DeepSeek-V3-0324",
      "model_slug": "sambanova/DeepSeek-V3-0324",
      "model_name": "DeepSeek V3 0324 | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.0000045,
      "output_cost_per_million": 4.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/Llama-4-Maverick-17B-128E-Instruct",
      "model_slug": "sambanova/Llama-4-Maverick-17B-128E-Instruct",
      "model_name": "Llama 4 Maverick 17B 128E Instruct | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 6.3e-7,
      "input_cost_per_million": 0.63,
      "output_cost_per_token": 0.0000018,
      "output_cost_per_million": 1.7999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/Llama-4-Scout-17B-16E-Instruct",
      "model_slug": "sambanova/Llama-4-Scout-17B-16E-Instruct",
      "model_name": "Llama 4 Scout 17B 16E Instruct | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 4e-7,
      "input_cost_per_million": 0.39999999999999997,
      "output_cost_per_token": 7e-7,
      "output_cost_per_million": 0.7,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/Meta-Llama-3.1-405B-Instruct",
      "model_slug": "sambanova/Meta-Llama-3.1-405B-Instruct",
      "model_name": "Meta Llama 3.1 405B Instruct | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/Meta-Llama-3.1-8B-Instruct",
      "model_slug": "sambanova/Meta-Llama-3.1-8B-Instruct",
      "model_name": "Meta Llama 3.1 8B Instruct | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/Meta-Llama-3.2-1B-Instruct",
      "model_slug": "sambanova/Meta-Llama-3.2-1B-Instruct",
      "model_name": "Meta Llama 3.2 1B Instruct | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 4e-8,
      "input_cost_per_million": 0.04,
      "output_cost_per_token": 8e-8,
      "output_cost_per_million": 0.08,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/Meta-Llama-3.2-3B-Instruct",
      "model_slug": "sambanova/Meta-Llama-3.2-3B-Instruct",
      "model_name": "Meta Llama 3.2 3B Instruct | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 8e-8,
      "input_cost_per_million": 0.08,
      "output_cost_per_token": 1.6e-7,
      "output_cost_per_million": 0.16,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/Meta-Llama-3.3-70B-Instruct",
      "model_slug": "sambanova/Meta-Llama-3.3-70B-Instruct",
      "model_name": "Meta Llama 3.3 70B Instruct | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 0.0000012,
      "output_cost_per_million": 1.2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/Meta-Llama-Guard-3-8B",
      "model_slug": "sambanova/Meta-Llama-Guard-3-8B",
      "model_name": "Meta Llama Guard 3 8B | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/Qwen2-Audio-7B-Instruct",
      "model_slug": "sambanova/Qwen2-Audio-7B-Instruct",
      "model_name": "Qwen2 Audio 7B Instruct | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0001,
      "output_cost_per_million": 100,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/Qwen3-32B",
      "model_slug": "sambanova/Qwen3-32B",
      "model_name": "Qwen3 32B | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 4e-7,
      "input_cost_per_million": 0.39999999999999997,
      "output_cost_per_token": 8e-7,
      "output_cost_per_million": 0.7999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "sambanova/QwQ-32B",
      "model_slug": "sambanova/QwQ-32B",
      "model_name": "QwQ 32B | sambanova",
      "provider_id": "sambanova",
      "provider_name": "Sambanova",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.000001,
      "output_cost_per_million": 1,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "snowflake": [
    {
      "model_id": "snowflake/claude-3-5-sonnet",
      "model_slug": "snowflake/claude-3-5-sonnet",
      "model_name": "Claude 3 5 Sonnet | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 18000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/deepseek-r1",
      "model_slug": "snowflake/deepseek-r1",
      "model_name": "DeepSeek R1 | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/gemma-7b",
      "model_slug": "snowflake/gemma-7b",
      "model_name": "Gemma 7b | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 8000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/jamba-1.5-large",
      "model_slug": "snowflake/jamba-1.5-large",
      "model_name": "Jamba 1.5 Large | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 256000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/jamba-1.5-mini",
      "model_slug": "snowflake/jamba-1.5-mini",
      "model_name": "Jamba 1.5 Mini | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 256000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/jamba-instruct",
      "model_slug": "snowflake/jamba-instruct",
      "model_name": "Jamba Instruct | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 256000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/llama2-70b-chat",
      "model_slug": "snowflake/llama2-70b-chat",
      "model_name": "Llama2 70b Chat | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 4096,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/llama3-70b",
      "model_slug": "snowflake/llama3-70b",
      "model_name": "Llama 3 70B | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 8000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/llama3-8b",
      "model_slug": "snowflake/llama3-8b",
      "model_name": "Llama 3 8B | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 8000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/llama3.1-405b",
      "model_slug": "snowflake/llama3.1-405b",
      "model_name": "Llama3.1 405b | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/llama3.1-70b",
      "model_slug": "snowflake/llama3.1-70b",
      "model_name": "Llama 3.1 70B | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/llama3.1-8b",
      "model_slug": "snowflake/llama3.1-8b",
      "model_name": "Llama 3.1 8B | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/llama3.2-1b",
      "model_slug": "snowflake/llama3.2-1b",
      "model_name": "Llama 3.2 1B | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/llama3.2-3b",
      "model_slug": "snowflake/llama3.2-3b",
      "model_name": "Llama 3.2 3B | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/llama3.3-70b",
      "model_slug": "snowflake/llama3.3-70b",
      "model_name": "Llama 3.3 70B | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/mistral-7b",
      "model_slug": "snowflake/mistral-7b",
      "model_name": "Mistral 7B | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/mistral-large",
      "model_slug": "snowflake/mistral-large",
      "model_name": "Mistral Large | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/mistral-large2",
      "model_slug": "snowflake/mistral-large2",
      "model_name": "Mistral Large2 | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/mixtral-8x7b",
      "model_slug": "snowflake/mixtral-8x7b",
      "model_name": "Mixtral 8x7b | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/reka-core",
      "model_slug": "snowflake/reka-core",
      "model_name": "Reka Core | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/reka-flash",
      "model_slug": "snowflake/reka-flash",
      "model_name": "Reka Flash | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 100000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/snowflake-arctic",
      "model_slug": "snowflake/snowflake-arctic",
      "model_name": "Snowflake Arctic | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 4096,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/snowflake-llama-3.1-405b",
      "model_slug": "snowflake/snowflake-llama-3.1-405b",
      "model_name": "Snowflake Llama 3.1 405b | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 8000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "snowflake/snowflake-llama-3.3-70b",
      "model_slug": "snowflake/snowflake-llama-3.3-70b",
      "model_name": "Snowflake Llama 3.3 70b | snowflake",
      "provider_id": "snowflake",
      "provider_name": "Snowflake",
      "max_input_tokens": 8000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "text-completion-openai": [
    {
      "model_id": "babbage-002",
      "model_slug": "babbage-002",
      "model_name": "Babbage 002",
      "provider_id": "text-completion-openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 4e-7,
      "input_cost_per_million": 0.39999999999999997,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "davinci-002",
      "model_slug": "davinci-002",
      "model_name": "Davinci 002",
      "provider_id": "text-completion-openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "ft:babbage-002",
      "model_slug": "ft:babbage-002",
      "model_name": "Ft:babbage 002",
      "provider_id": "text-completion-openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 4e-7,
      "input_cost_per_million": 0.39999999999999997,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "ft:davinci-002",
      "model_slug": "ft:davinci-002",
      "model_name": "Ft:davinci 002",
      "provider_id": "text-completion-openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 16384,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-3.5-turbo-instruct",
      "model_slug": "gpt-3.5-turbo-instruct",
      "model_name": "GPT 3.5T Instruct",
      "provider_id": "text-completion-openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.0000015,
      "input_cost_per_million": 1.5,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "gpt-3.5-turbo-instruct-0914",
      "model_slug": "gpt-3.5-turbo-instruct-0914",
      "model_name": "GPT 3.5 Turbo Instruct 0914",
      "provider_id": "text-completion-openai",
      "provider_name": "OpenAI",
      "max_input_tokens": 8192,
      "max_output_tokens": 4097,
      "input_cost_per_token": 0.0000015,
      "input_cost_per_million": 1.5,
      "output_cost_per_token": 0.000002,
      "output_cost_per_million": 2,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    }
  ],
  "together": [
    {
      "model_id": "deepseek-ai/DeepSeek-R1",
      "model_slug": "together_ai/deepseek-ai/DeepSeek-R1",
      "model_name": "DeepSeek R1 | deepseek-ai",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000007,
      "output_cost_per_million": 7,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "deepseek-ai/DeepSeek-V3",
      "model_slug": "together_ai/deepseek-ai/DeepSeek-V3",
      "model_name": "DeepSeek V3 | deepseek-ai",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00000125,
      "output_cost_per_million": 1.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Llama-3.2-3B-Instruct-Turbo",
      "model_slug": "together_ai/meta-llama/Llama-3.2-3B-Instruct-Turbo",
      "model_name": "Llama 3.2 3B Instruct Turbo | meta-llama",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
      "model_slug": "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo",
      "model_name": "Llama 3.3 70B Instruct Turbo | meta-llama",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 8.8e-7,
      "input_cost_per_million": 0.88,
      "output_cost_per_token": 8.8e-7,
      "output_cost_per_million": 0.88,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
      "model_slug": "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
      "model_name": "Llama 3.3 70B Instruct Turbo Free | meta-llama",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "model_slug": "together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "model_name": "Llama 4 Maverick 17B 128E Instruct FP8 | meta-llama",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 2.7e-7,
      "input_cost_per_million": 0.27,
      "output_cost_per_token": 8.5e-7,
      "output_cost_per_million": 0.85,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "model_slug": "together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "model_name": "Llama 4 Scout 17B 16E Instruct | meta-llama",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1.8e-7,
      "input_cost_per_million": 0.18,
      "output_cost_per_token": 5.9e-7,
      "output_cost_per_million": 0.59,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
      "model_slug": "together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
      "model_name": "Meta Llama 3.1 405B Instruct Turbo | meta-llama",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.0000035,
      "input_cost_per_million": 3.5,
      "output_cost_per_token": 0.0000035,
      "output_cost_per_million": 3.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "model_slug": "together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "model_name": "Meta Llama 3.1 70B Instruct Turbo | meta-llama",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 8.8e-7,
      "input_cost_per_million": 0.88,
      "output_cost_per_token": 8.8e-7,
      "output_cost_per_million": 0.88,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
      "model_slug": "together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
      "model_name": "Meta Llama 3.1 8B Instruct Turbo | meta-llama",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1.8e-7,
      "input_cost_per_million": 0.18,
      "output_cost_per_token": 1.8e-7,
      "output_cost_per_million": 0.18,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistralai/Mistral-Small-24B-Instruct-2501",
      "model_slug": "together_ai/mistralai/Mistral-Small-24B-Instruct-2501",
      "model_name": "Mistral Small 24B Instruct 2501 | mistralai",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "moonshotai/Kimi-K2-Instruct",
      "model_slug": "together_ai/moonshotai/Kimi-K2-Instruct",
      "model_name": "Kimi K2 Instruct | moonshotai",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "Qwen/Qwen2.5-72B-Instruct-Turbo",
      "model_slug": "together_ai/Qwen/Qwen2.5-72B-Instruct-Turbo",
      "model_name": "Qwen2.5 72B Instruct Turbo | Qwen",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "Qwen/Qwen2.5-7B-Instruct-Turbo",
      "model_slug": "together_ai/Qwen/Qwen2.5-7B-Instruct-Turbo",
      "model_name": "Qwen2.5 7B Instruct Turbo | Qwen",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "together-ai-21.1b-41b",
      "model_slug": "together-ai-21.1b-41b",
      "model_name": "Together Ai 21.1b 41b",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 8e-7,
      "input_cost_per_million": 0.7999999999999999,
      "output_cost_per_token": 8e-7,
      "output_cost_per_million": 0.7999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "together-ai-4.1b-8b",
      "model_slug": "together-ai-4.1b-8b",
      "model_name": "Together Ai 4.1b 8b",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 2e-7,
      "output_cost_per_million": 0.19999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "together-ai-41.1b-80b",
      "model_slug": "together-ai-41.1b-80b",
      "model_name": "Together Ai 41.1b 80b",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 9e-7,
      "input_cost_per_million": 0.8999999999999999,
      "output_cost_per_token": 9e-7,
      "output_cost_per_million": 0.8999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "together-ai-8.1b-21b",
      "model_slug": "together-ai-8.1b-21b",
      "model_name": "Together Ai 8.1b 21b",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "together-ai-81.1b-110b",
      "model_slug": "together-ai-81.1b-110b",
      "model_name": "Together Ai 81.1b 110b",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0.0000018,
      "input_cost_per_million": 1.7999999999999998,
      "output_cost_per_token": 0.0000018,
      "output_cost_per_million": 1.7999999999999998,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "together-ai-embedding-151m-to-350m",
      "model_slug": "together-ai-embedding-151m-to-350m",
      "model_name": "Together Ai Embedding 151m To 350m",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1.6e-8,
      "input_cost_per_million": 0.016,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "together-ai-embedding-up-to-150m",
      "model_slug": "together-ai-embedding-up-to-150m",
      "model_name": "Together Ai Embedding Up To 150m",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 8e-9,
      "input_cost_per_million": 0.008,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "together-ai-up-to-4b",
      "model_slug": "together-ai-up-to-4b",
      "model_name": "Together Ai Up To 4b",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 1e-7,
      "output_cost_per_million": 0.09999999999999999,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "togethercomputer/CodeLlama-34b-Instruct",
      "model_slug": "together_ai/togethercomputer/CodeLlama-34b-Instruct",
      "model_name": "CodeLlama 34b Instruct | togethercomputer",
      "provider_id": "together",
      "provider_name": "Together AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "vertex": [
    {
      "model_id": "chat-bison",
      "model_slug": "chat-bison",
      "model_name": "Chat Bison",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "chat-bison-32k",
      "model_slug": "chat-bison-32k",
      "model_name": "Chat Bison 32k",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "chat-bison-32k@002",
      "model_slug": "chat-bison-32k@002",
      "model_name": "Chat Bison 32k@002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "chat-bison@001",
      "model_slug": "chat-bison@001",
      "model_name": "Chat Bison@001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "chat-bison@002",
      "model_slug": "chat-bison@002",
      "model_name": "Chat Bison@002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-04-09"
    },
    {
      "model_id": "claude-3-5-haiku",
      "model_slug": "vertex_ai/claude-3-5-haiku",
      "model_name": "Claude 3 5 Haiku",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-3-5-haiku@20241022",
      "model_slug": "vertex_ai/claude-3-5-haiku@20241022",
      "model_name": "Claude 3 5 Haiku@20241022",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-3-5-sonnet",
      "model_slug": "vertex_ai/claude-3-5-sonnet",
      "model_name": "Claude 3 5 Sonnet",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-3-5-sonnet-v2",
      "model_slug": "vertex_ai/claude-3-5-sonnet-v2",
      "model_name": "Claude 3 5 Sonnet V2",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-3-5-sonnet-v2@20241022",
      "model_slug": "vertex_ai/claude-3-5-sonnet-v2@20241022",
      "model_name": "Claude 3 5 Sonnet V2@20241022",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-3-5-sonnet@20240620",
      "model_slug": "vertex_ai/claude-3-5-sonnet@20240620",
      "model_name": "Claude 3 5 Sonnet@20240620",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-3-7-sonnet@20250219",
      "model_slug": "vertex_ai/claude-3-7-sonnet@20250219",
      "model_name": "Claude 3 7 Sonnet@20250219",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-06-01"
    },
    {
      "model_id": "claude-3-haiku",
      "model_slug": "vertex_ai/claude-3-haiku",
      "model_name": "Claude 3 Haiku",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 0.00000125,
      "output_cost_per_million": 1.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-3-haiku@20240307",
      "model_slug": "vertex_ai/claude-3-haiku@20240307",
      "model_name": "Claude 3 Haiku@20240307",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 0.00000125,
      "output_cost_per_million": 1.25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-3-opus",
      "model_slug": "vertex_ai/claude-3-opus",
      "model_name": "Claude 3 Opus",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-3-opus@20240229",
      "model_slug": "vertex_ai/claude-3-opus@20240229",
      "model_name": "Claude 3 Opus@20240229",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-3-sonnet",
      "model_slug": "vertex_ai/claude-3-sonnet",
      "model_name": "Claude 3 Sonnet",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-3-sonnet@20240229",
      "model_slug": "vertex_ai/claude-3-sonnet@20240229",
      "model_name": "Claude 3 Sonnet@20240229",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-opus-4",
      "model_slug": "vertex_ai/claude-opus-4",
      "model_name": "Claude Opus 4",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": 0.0000015,
      "cache_read_cost_per_million": 1.5,
      "cache_write_cost_per_token": 0.00001875,
      "cache_write_cost_per_million": 18.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-opus-4@20250514",
      "model_slug": "vertex_ai/claude-opus-4@20250514",
      "model_name": "Claude Opus 4@20250514",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0.000015,
      "input_cost_per_million": 15,
      "output_cost_per_token": 0.000075,
      "output_cost_per_million": 75,
      "cache_read_cost_per_token": 0.0000015,
      "cache_read_cost_per_million": 1.5,
      "cache_write_cost_per_token": 0.00001875,
      "cache_write_cost_per_million": 18.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-sonnet-4",
      "model_slug": "vertex_ai/claude-sonnet-4",
      "model_name": "Claude Sonnet 4",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "claude-sonnet-4@20250514",
      "model_slug": "vertex_ai/claude-sonnet-4@20250514",
      "model_name": "Claude Sonnet 4@20250514",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": 3e-7,
      "cache_read_cost_per_million": 0.3,
      "cache_write_cost_per_token": 0.00000375,
      "cache_write_cost_per_million": 3.75,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "code-bison",
      "model_slug": "code-bison",
      "model_name": "Code Bison",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "code-bison-32k@002",
      "model_slug": "code-bison-32k@002",
      "model_name": "Code Bison 32k@002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "code-bison@001",
      "model_slug": "code-bison@001",
      "model_name": "Code Bison@001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "code-bison@002",
      "model_slug": "code-bison@002",
      "model_name": "Code Bison@002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "code-bison32k",
      "model_slug": "code-bison32k",
      "model_name": "Code Bison32k",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "code-gecko",
      "model_slug": "code-gecko",
      "model_name": "Code Gecko",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "code-gecko-latest",
      "model_slug": "code-gecko-latest",
      "model_name": "Code Gecko Latest",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "code-gecko@001",
      "model_slug": "code-gecko@001",
      "model_name": "Code Gecko@001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "code-gecko@002",
      "model_slug": "code-gecko@002",
      "model_name": "Code Gecko@002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2048,
      "max_output_tokens": 64,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "codechat-bison",
      "model_slug": "codechat-bison",
      "model_name": "Codechat Bison",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codechat-bison-32k",
      "model_slug": "codechat-bison-32k",
      "model_name": "Codechat Bison 32k",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codechat-bison-32k@002",
      "model_slug": "codechat-bison-32k@002",
      "model_name": "Codechat Bison 32k@002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codechat-bison@001",
      "model_slug": "codechat-bison@001",
      "model_name": "Codechat Bison@001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codechat-bison@002",
      "model_slug": "codechat-bison@002",
      "model_name": "Codechat Bison@002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codechat-bison@latest",
      "model_slug": "codechat-bison@latest",
      "model_name": "Codechat Bison@latest",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 6144,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codestral-2501",
      "model_slug": "vertex_ai/codestral-2501",
      "model_name": "Codestral 2501",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codestral@2405",
      "model_slug": "vertex_ai/codestral@2405",
      "model_name": "Codestral@2405",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "codestral@latest",
      "model_slug": "vertex_ai/codestral@latest",
      "model_name": "Codestral@latest",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 2e-7,
      "input_cost_per_million": 0.19999999999999998,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-1.0-pro",
      "model_slug": "gemini-1.0-pro",
      "model_name": "Gemini 1.0 Pro",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-1.0-pro-001",
      "model_slug": "gemini-1.0-pro-001",
      "model_name": "Gemini 1.0 Pro 001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-04-09"
    },
    {
      "model_id": "gemini-1.0-pro-002",
      "model_slug": "gemini-1.0-pro-002",
      "model_name": "Gemini 1.0 Pro 002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-04-09"
    },
    {
      "model_id": "gemini-1.0-pro-vision",
      "model_slug": "gemini-1.0-pro-vision",
      "model_name": "Gemini 1.0 Pro Vision",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-1.0-pro-vision-001",
      "model_slug": "gemini-1.0-pro-vision-001",
      "model_name": "Gemini 1.0 Pro Vision 001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-04-09"
    },
    {
      "model_id": "gemini-1.0-ultra",
      "model_slug": "gemini-1.0-ultra",
      "model_name": "Gemini 1.0 Ultra",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-1.0-ultra-001",
      "model_slug": "gemini-1.0-ultra-001",
      "model_name": "Gemini 1.0 Ultra 001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-1.5-flash",
      "model_slug": "gemini-1.5-flash",
      "model_name": "Gemini 1.5 Flash",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-1.5-flash-001",
      "model_slug": "gemini-1.5-flash-001",
      "model_name": "Gemini 1.5 Flash 001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-05-24"
    },
    {
      "model_id": "gemini-1.5-flash-002",
      "model_slug": "gemini-1.5-flash-002",
      "model_name": "Gemini 1.5 Flash 002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-09-24"
    },
    {
      "model_id": "gemini-1.5-flash-exp-0827",
      "model_slug": "gemini-1.5-flash-exp-0827",
      "model_name": "Gemini 1.5 Flash Exp 0827",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 4.688e-9,
      "input_cost_per_million": 0.004688,
      "output_cost_per_token": 4.6875e-9,
      "output_cost_per_million": 0.0046875,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-1.5-flash-preview-0514",
      "model_slug": "gemini-1.5-flash-preview-0514",
      "model_name": "Gemini 1.5 Flash Preview 0514",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 4.6875e-9,
      "output_cost_per_million": 0.0046875,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-1.5-pro",
      "model_slug": "gemini-1.5-pro",
      "model_name": "Gemini 1.5 Pro",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-1.5-pro-001",
      "model_slug": "gemini-1.5-pro-001",
      "model_name": "Gemini 1.5 Pro 001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-05-24"
    },
    {
      "model_id": "gemini-1.5-pro-002",
      "model_slug": "gemini-1.5-pro-002",
      "model_name": "Gemini 1.5 Pro 002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.000005,
      "output_cost_per_million": 5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2025-09-24"
    },
    {
      "model_id": "gemini-1.5-pro-preview-0215",
      "model_slug": "gemini-1.5-pro-preview-0215",
      "model_name": "Gemini 1.5 Pro Preview 0215",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.8125e-8,
      "input_cost_per_million": 0.078125,
      "output_cost_per_token": 3.125e-7,
      "output_cost_per_million": 0.3125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-1.5-pro-preview-0409",
      "model_slug": "gemini-1.5-pro-preview-0409",
      "model_name": "Gemini 1.5 Pro Preview 0409",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.8125e-8,
      "input_cost_per_million": 0.078125,
      "output_cost_per_token": 3.125e-7,
      "output_cost_per_million": 0.3125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-1.5-pro-preview-0514",
      "model_slug": "gemini-1.5-pro-preview-0514",
      "model_name": "Gemini 1.5 Pro Preview 0514",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.8125e-8,
      "input_cost_per_million": 0.078125,
      "output_cost_per_token": 3.125e-7,
      "output_cost_per_million": 0.3125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.0-flash",
      "model_slug": "gemini-2.0-flash",
      "model_name": "Gemini 2.0 Flash Latest",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": 2.5e-8,
      "cache_read_cost_per_million": 0.024999999999999998,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.0-flash-001",
      "model_slug": "gemini-2.0-flash-001",
      "model_name": "Gemini 2.0 Flash 001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": 3.75e-8,
      "cache_read_cost_per_million": 0.0375,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2026-02-05"
    },
    {
      "model_id": "gemini-2.0-flash-exp",
      "model_slug": "gemini-2.0-flash-exp",
      "model_name": "Gemini 2.0 Flash Exp",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": 3.75e-8,
      "cache_read_cost_per_million": 0.0375,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.0-flash-lite",
      "model_slug": "gemini-2.0-flash-lite",
      "model_name": "Gemini 2.0 Flash-Lite",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": 1.875e-8,
      "cache_read_cost_per_million": 0.01875,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.0-flash-lite-001",
      "model_slug": "gemini-2.0-flash-lite-001",
      "model_name": "Gemini 2.0 Flash Lite 001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 7.5e-8,
      "input_cost_per_million": 0.075,
      "output_cost_per_token": 3e-7,
      "output_cost_per_million": 0.3,
      "cache_read_cost_per_token": 1.875e-8,
      "cache_read_cost_per_million": 0.01875,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": "2026-02-25"
    },
    {
      "model_id": "gemini-2.0-flash-preview-image-generation",
      "model_slug": "gemini-2.0-flash-preview-image-generation",
      "model_name": "Gemini 2.0 Flash Preview Image Generation",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": 2.5e-8,
      "cache_read_cost_per_million": 0.024999999999999998,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.0-flash-thinking-exp",
      "model_slug": "gemini-2.0-flash-thinking-exp",
      "model_name": "Gemini 2.0 Flash Thinking Exp",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.0-flash-thinking-exp-01-21",
      "model_slug": "gemini-2.0-flash-thinking-exp-01-21",
      "model_name": "Gemini 2.0 Flash Thinking Exp 01 21",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.0-pro-exp-02-05",
      "model_slug": "gemini-2.0-pro-exp-02-05",
      "model_name": "Gemini 2.0 Pro Exp 02 05",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2097152,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 3.125e-7,
      "cache_read_cost_per_million": 0.3125,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.5-flash",
      "model_slug": "gemini-2.5-flash",
      "model_name": "Gemini 2.5 Flash",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 0.0000025,
      "output_cost_per_million": 2.5,
      "cache_read_cost_per_token": 7.5e-8,
      "cache_read_cost_per_million": 0.075,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.5-flash-lite-preview-06-17",
      "model_slug": "gemini-2.5-flash-lite-preview-06-17",
      "model_name": "Gemini 2.5 Flash-Lite Preview",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 4e-7,
      "output_cost_per_million": 0.39999999999999997,
      "cache_read_cost_per_token": 2.5e-8,
      "cache_read_cost_per_million": 0.024999999999999998,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.5-flash-preview-04-17",
      "model_slug": "gemini-2.5-flash-preview-04-17",
      "model_name": "Gemini 2.5 Flash Preview 04 17",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 6e-7,
      "output_cost_per_million": 0.6,
      "cache_read_cost_per_token": 3.75e-8,
      "cache_read_cost_per_million": 0.0375,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.5-flash-preview-05-20",
      "model_slug": "gemini-2.5-flash-preview-05-20",
      "model_name": "Gemini 2.5 Flash Preview 05 20",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 0.0000025,
      "output_cost_per_million": 2.5,
      "cache_read_cost_per_token": 7.5e-8,
      "cache_read_cost_per_million": 0.075,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.5-pro",
      "model_slug": "gemini-2.5-pro",
      "model_name": "Gemini 2.5 Pro",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 3.125e-7,
      "cache_read_cost_per_million": 0.3125,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.5-pro-exp-03-25",
      "model_slug": "gemini-2.5-pro-exp-03-25",
      "model_name": "Gemini 2.5 Pro Exp 03 25",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 3.125e-7,
      "cache_read_cost_per_million": 0.3125,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.5-pro-preview-03-25",
      "model_slug": "gemini-2.5-pro-preview-03-25",
      "model_name": "Gemini 2.5 Pro Preview 03 25",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 3.125e-7,
      "cache_read_cost_per_million": 0.3125,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.5-pro-preview-05-06",
      "model_slug": "gemini-2.5-pro-preview-05-06",
      "model_name": "Gemini 2.5 Pro Preview 05 06",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 3.125e-7,
      "cache_read_cost_per_million": 0.3125,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.5-pro-preview-06-05",
      "model_slug": "gemini-2.5-pro-preview-06-05",
      "model_name": "Gemini 2.5 Pro Preview 06 05",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 3.125e-7,
      "cache_read_cost_per_million": 0.3125,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-2.5-pro-preview-tts",
      "model_slug": "gemini-2.5-pro-preview-tts",
      "model_name": "Gemini 2.5 Pro Preview Tts",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_token": 0.00000125,
      "input_cost_per_million": 1.25,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": 3.125e-7,
      "cache_read_cost_per_million": 0.3125,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": true,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-embedding-001",
      "model_slug": "gemini-embedding-001",
      "model_name": "Gemini Embedding 001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2048,
      "max_output_tokens": null,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-flash-experimental",
      "model_slug": "gemini-flash-experimental",
      "model_name": "Gemini Flash Experimental",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-pro",
      "model_slug": "gemini-pro",
      "model_name": "Gemini Pro",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32760,
      "max_output_tokens": 8192,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-pro-experimental",
      "model_slug": "gemini-pro-experimental",
      "model_name": "Gemini Pro Experimental",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "gemini-pro-vision",
      "model_slug": "gemini-pro-vision",
      "model_name": "Gemini Pro Vision",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "input_cost_per_token": 5e-7,
      "input_cost_per_million": 0.5,
      "output_cost_per_token": 0.0000015,
      "output_cost_per_million": 1.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": true,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "imagegeneration@006",
      "model_slug": "vertex_ai/imagegeneration@006",
      "model_name": "Imagegeneration@006",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "imagen-3.0-fast-generate-001",
      "model_slug": "vertex_ai/imagen-3.0-fast-generate-001",
      "model_name": "Imagen 3.0 Fast Generate 001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "imagen-3.0-generate-001",
      "model_slug": "vertex_ai/imagen-3.0-generate-001",
      "model_name": "Imagen 3.0 Generate 001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "imagen-3.0-generate-002",
      "model_slug": "vertex_ai/imagen-3.0-generate-002",
      "model_name": "Imagen 3.0 Generate 002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "imagen-4.0-fast-generate-preview-06-06",
      "model_slug": "vertex_ai/imagen-4.0-fast-generate-preview-06-06",
      "model_name": "Imagen 4.0 Fast Generate Preview 06 06",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "imagen-4.0-generate-preview-06-06",
      "model_slug": "vertex_ai/imagen-4.0-generate-preview-06-06",
      "model_name": "Imagen 4.0 Generate Preview 06 06",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "imagen-4.0-ultra-generate-preview-06-06",
      "model_slug": "vertex_ai/imagen-4.0-ultra-generate-preview-06-06",
      "model_name": "Imagen 4.0 Ultra Generate Preview 06 06",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": null,
      "max_output_tokens": null,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "image",
      "deprecation_date": null
    },
    {
      "model_id": "medlm-large",
      "model_slug": "medlm-large",
      "model_name": "Medlm Large",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "medlm-medium",
      "model_slug": "medlm-medium",
      "model_name": "Medlm Medium",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-3.2-90b-vision-instruct-maas",
      "model_slug": "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas",
      "model_name": "Llama 3.2 90b Vision Instruct Maas | meta",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-4-maverick-17b-128e-instruct-maas",
      "model_slug": "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas",
      "model_name": "Llama 4 Maverick 17b 128e Instruct Maas | meta",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_million": 0.35,
      "output_cost_per_token": 0.00000115,
      "output_cost_per_million": 1.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-4-maverick-17b-16e-instruct-maas",
      "model_slug": "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas",
      "model_name": "Llama 4 Maverick 17b 16e Instruct Maas | meta",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_token": 3.5e-7,
      "input_cost_per_million": 0.35,
      "output_cost_per_token": 0.00000115,
      "output_cost_per_million": 1.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-4-scout-17b-128e-instruct-maas",
      "model_slug": "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas",
      "model_name": "Llama 4 Scout 17b 128e Instruct Maas | meta",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 10000000,
      "max_output_tokens": 10000000,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 7e-7,
      "output_cost_per_million": 0.7,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama-4-scout-17b-16e-instruct-maas",
      "model_slug": "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas",
      "model_name": "Llama 4 Scout 17b 16e Instruct Maas | meta",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 10000000,
      "max_output_tokens": 10000000,
      "input_cost_per_token": 2.5e-7,
      "input_cost_per_million": 0.25,
      "output_cost_per_token": 7e-7,
      "output_cost_per_million": 0.7,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama3-405b-instruct-maas",
      "model_slug": "vertex_ai/meta/llama3-405b-instruct-maas",
      "model_name": "Llama3 405b Instruct Maas | meta",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama3-70b-instruct-maas",
      "model_slug": "vertex_ai/meta/llama3-70b-instruct-maas",
      "model_name": "Llama3 70b Instruct Maas | meta",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "meta/llama3-8b-instruct-maas",
      "model_slug": "vertex_ai/meta/llama3-8b-instruct-maas",
      "model_name": "Llama3 8b Instruct Maas | meta",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-large-2411",
      "model_slug": "vertex_ai/mistral-large-2411",
      "model_name": "Mistral Large 2411",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-large@2407",
      "model_slug": "vertex_ai/mistral-large@2407",
      "model_name": "Mistral Large@2407",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-large@2411-001",
      "model_slug": "vertex_ai/mistral-large@2411-001",
      "model_name": "Mistral Large@2411 001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-large@latest",
      "model_slug": "vertex_ai/mistral-large@latest",
      "model_name": "Mistral Large@latest",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.000006,
      "output_cost_per_million": 6,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-nemo@2407",
      "model_slug": "vertex_ai/mistral-nemo@2407",
      "model_name": "Mistral Nemo@2407",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-nemo@latest",
      "model_slug": "vertex_ai/mistral-nemo@latest",
      "model_name": "Mistral Nemo@latest",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 1.5e-7,
      "input_cost_per_million": 0.15,
      "output_cost_per_token": 1.5e-7,
      "output_cost_per_million": 0.15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-small-2503",
      "model_slug": "vertex_ai/mistral-small-2503",
      "model_name": "Mistral Small 2503",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "mistral-small-2503@001",
      "model_slug": "vertex_ai/mistral-small-2503@001",
      "model_name": "Mistral Small 2503@001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 32000,
      "max_output_tokens": 8191,
      "input_cost_per_token": 0.000001,
      "input_cost_per_million": 1,
      "output_cost_per_token": 0.000003,
      "output_cost_per_million": 3,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "multimodalembedding",
      "model_slug": "multimodalembedding",
      "model_name": "Multimodalembedding",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2048,
      "max_output_tokens": null,
      "input_cost_per_token": 8e-7,
      "input_cost_per_million": 0.7999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "multimodalembedding@001",
      "model_slug": "multimodalembedding@001",
      "model_name": "Multimodalembedding@001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2048,
      "max_output_tokens": null,
      "input_cost_per_token": 8e-7,
      "input_cost_per_million": 0.7999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "text-bison",
      "model_slug": "text-bison",
      "model_name": "Text Bison",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "text-bison@001",
      "model_slug": "text-bison@001",
      "model_name": "Text Bison@001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "text-bison@002",
      "model_slug": "text-bison@002",
      "model_name": "Text Bison@002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 0,
      "input_cost_per_million": 0,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "text-bison32k",
      "model_slug": "text-bison32k",
      "model_name": "Text Bison32k",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "text-bison32k@002",
      "model_slug": "text-bison32k@002",
      "model_name": "Text Bison32k@002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 1.25e-7,
      "input_cost_per_million": 0.125,
      "output_cost_per_token": 1.25e-7,
      "output_cost_per_million": 0.125,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "text-embedding-004",
      "model_slug": "text-embedding-004",
      "model_name": "Text Embedding 004",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2048,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "text-embedding-005",
      "model_slug": "text-embedding-005",
      "model_name": "Text Embedding 005",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2048,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "text-embedding-large-exp-03-07",
      "model_slug": "text-embedding-large-exp-03-07",
      "model_name": "Text Embedding Large Exp 03 07",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "text-embedding-preview-0409",
      "model_slug": "text-embedding-preview-0409",
      "model_name": "Text Embedding Preview 0409",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 3072,
      "max_output_tokens": null,
      "input_cost_per_token": 6.25e-9,
      "input_cost_per_million": 0.0062499999999999995,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "text-multilingual-embedding-002",
      "model_slug": "text-multilingual-embedding-002",
      "model_name": "Text Multilingual Embedding 002",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 2048,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "text-multilingual-embedding-preview-0409",
      "model_slug": "text-multilingual-embedding-preview-0409",
      "model_name": "Text Multilingual Embedding Preview 0409",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 3072,
      "max_output_tokens": null,
      "input_cost_per_token": 6.25e-9,
      "input_cost_per_million": 0.0062499999999999995,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "text-unicorn",
      "model_slug": "text-unicorn",
      "model_name": "Text Unicorn",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.000028,
      "output_cost_per_million": 28,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "text-unicorn@001",
      "model_slug": "text-unicorn@001",
      "model_name": "Text Unicorn@001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 0.00001,
      "input_cost_per_million": 10,
      "output_cost_per_token": 0.000028,
      "output_cost_per_million": 28,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "completion",
      "deprecation_date": null
    },
    {
      "model_id": "textembedding-gecko",
      "model_slug": "textembedding-gecko",
      "model_name": "Textembedding Gecko",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 3072,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "textembedding-gecko-multilingual",
      "model_slug": "textembedding-gecko-multilingual",
      "model_name": "Textembedding Gecko Multilingual",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 3072,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "textembedding-gecko-multilingual@001",
      "model_slug": "textembedding-gecko-multilingual@001",
      "model_name": "Textembedding Gecko Multilingual@001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 3072,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "textembedding-gecko@001",
      "model_slug": "textembedding-gecko@001",
      "model_name": "Textembedding Gecko@001",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 3072,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "textembedding-gecko@003",
      "model_slug": "textembedding-gecko@003",
      "model_name": "Textembedding Gecko@003",
      "provider_id": "vertex",
      "provider_name": "Google Vertex AI",
      "max_input_tokens": 3072,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    }
  ],
  "voyage": [
    {
      "model_id": "rerank-2",
      "model_slug": "voyage/rerank-2",
      "model_name": "Rerank 2",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 16000,
      "max_output_tokens": 16000,
      "input_cost_per_token": 5e-8,
      "input_cost_per_million": 0.049999999999999996,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    },
    {
      "model_id": "rerank-2-lite",
      "model_slug": "voyage/rerank-2-lite",
      "model_name": "Rerank 2 Lite",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 8000,
      "max_output_tokens": 8000,
      "input_cost_per_token": 2e-8,
      "input_cost_per_million": 0.02,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "rerank",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-01",
      "model_slug": "voyage/voyage-01",
      "model_name": "Voyage 01",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 4096,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-2",
      "model_slug": "voyage/voyage-2",
      "model_name": "Voyage 2",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 4000,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-3",
      "model_slug": "voyage/voyage-3",
      "model_name": "Voyage 3",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 32000,
      "max_output_tokens": null,
      "input_cost_per_token": 6e-8,
      "input_cost_per_million": 0.06,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-3-large",
      "model_slug": "voyage/voyage-3-large",
      "model_name": "Voyage 3 Large",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 32000,
      "max_output_tokens": null,
      "input_cost_per_token": 1.8e-7,
      "input_cost_per_million": 0.18,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-3-lite",
      "model_slug": "voyage/voyage-3-lite",
      "model_name": "Voyage 3 Lite",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 32000,
      "max_output_tokens": null,
      "input_cost_per_token": 2e-8,
      "input_cost_per_million": 0.02,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-code-2",
      "model_slug": "voyage/voyage-code-2",
      "model_name": "Voyage Code 2",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 16000,
      "max_output_tokens": null,
      "input_cost_per_token": 1.2e-7,
      "input_cost_per_million": 0.12,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-code-3",
      "model_slug": "voyage/voyage-code-3",
      "model_name": "Voyage Code 3",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 32000,
      "max_output_tokens": null,
      "input_cost_per_token": 1.8e-7,
      "input_cost_per_million": 0.18,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-finance-2",
      "model_slug": "voyage/voyage-finance-2",
      "model_name": "Voyage Finance 2",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 32000,
      "max_output_tokens": null,
      "input_cost_per_token": 1.2e-7,
      "input_cost_per_million": 0.12,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-large-2",
      "model_slug": "voyage/voyage-large-2",
      "model_name": "Voyage Large 2",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 16000,
      "max_output_tokens": null,
      "input_cost_per_token": 1.2e-7,
      "input_cost_per_million": 0.12,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-law-2",
      "model_slug": "voyage/voyage-law-2",
      "model_name": "Voyage Law 2",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 16000,
      "max_output_tokens": null,
      "input_cost_per_token": 1.2e-7,
      "input_cost_per_million": 0.12,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-lite-01",
      "model_slug": "voyage/voyage-lite-01",
      "model_name": "Voyage Lite 01",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 4096,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-lite-02-instruct",
      "model_slug": "voyage/voyage-lite-02-instruct",
      "model_name": "Voyage Lite 02 Instruct",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 4000,
      "max_output_tokens": null,
      "input_cost_per_token": 1e-7,
      "input_cost_per_million": 0.09999999999999999,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    },
    {
      "model_id": "voyage-multimodal-3",
      "model_slug": "voyage/voyage-multimodal-3",
      "model_name": "Voyage Multimodal 3",
      "provider_id": "voyage",
      "provider_name": "Voyage AI",
      "max_input_tokens": 32000,
      "max_output_tokens": null,
      "input_cost_per_token": 1.2e-7,
      "input_cost_per_million": 0.12,
      "output_cost_per_token": 0,
      "output_cost_per_million": 0,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": false,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "embedding",
      "deprecation_date": null
    }
  ],
  "watsonx": [
    {
      "model_id": "watsonx/ibm/granite-3-8b-instruct",
      "model_slug": "watsonx/ibm/granite-3-8b-instruct",
      "model_name": "Granite 3 8b Instruct | ibm | watsonx",
      "provider_id": "watsonx",
      "provider_name": "IBM Watsonx",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_token": 0.0002,
      "input_cost_per_million": 200,
      "output_cost_per_token": 0.0002,
      "output_cost_per_million": 200,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "watsonx/mistralai/mistral-large",
      "model_slug": "watsonx/mistralai/mistral-large",
      "model_name": "Mistral Large | mistralai | watsonx",
      "provider_id": "watsonx",
      "provider_name": "IBM Watsonx",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": true,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ],
  "xai": [
    {
      "model_id": "grok-2",
      "model_slug": "xai/grok-2",
      "model_name": "Grok 2",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-2-1212",
      "model_slug": "xai/grok-2-1212",
      "model_name": "Grok 2 1212",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-2-latest",
      "model_slug": "xai/grok-2-latest",
      "model_name": "Grok 2 Latest",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-2-vision",
      "model_slug": "xai/grok-2-vision",
      "model_name": "Grok 2 Vision",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-2-vision-1212",
      "model_slug": "xai/grok-2-vision-1212",
      "model_name": "Grok 2 Vision 1212",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-2-vision-latest",
      "model_slug": "xai/grok-2-vision-latest",
      "model_name": "Grok 2 Vision Latest",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_token": 0.000002,
      "input_cost_per_million": 2,
      "output_cost_per_token": 0.00001,
      "output_cost_per_million": 10,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-3",
      "model_slug": "xai/grok-3",
      "model_name": "Grok 3",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-3-beta",
      "model_slug": "xai/grok-3-beta",
      "model_name": "Grok 3 Beta",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-3-fast-beta",
      "model_slug": "xai/grok-3-fast-beta",
      "model_name": "Grok 3 Fast Beta",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.000025,
      "output_cost_per_million": 25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-3-fast-latest",
      "model_slug": "xai/grok-3-fast-latest",
      "model_name": "Grok 3 Fast Latest",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.000025,
      "output_cost_per_million": 25,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-3-latest",
      "model_slug": "xai/grok-3-latest",
      "model_name": "Grok 3 Latest",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-3-mini",
      "model_slug": "xai/grok-3-mini",
      "model_name": "Grok 3 Mini",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-3-mini-beta",
      "model_slug": "xai/grok-3-mini-beta",
      "model_name": "Grok 3 Mini Beta",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-3-mini-fast",
      "model_slug": "xai/grok-3-mini-fast",
      "model_name": "Grok 3 Mini Fast",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 0.000004,
      "output_cost_per_million": 4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-3-mini-fast-beta",
      "model_slug": "xai/grok-3-mini-fast-beta",
      "model_name": "Grok 3 Mini Fast Beta",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 0.000004,
      "output_cost_per_million": 4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-3-mini-fast-latest",
      "model_slug": "xai/grok-3-mini-fast-latest",
      "model_name": "Grok 3 Mini Fast Latest",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 6e-7,
      "input_cost_per_million": 0.6,
      "output_cost_per_token": 0.000004,
      "output_cost_per_million": 4,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-3-mini-latest",
      "model_slug": "xai/grok-3-mini-latest",
      "model_name": "Grok 3 Mini Latest",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 3e-7,
      "input_cost_per_million": 0.3,
      "output_cost_per_token": 5e-7,
      "output_cost_per_million": 0.5,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-4",
      "model_slug": "xai/grok-4",
      "model_name": "Grok 4",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-4-0709",
      "model_slug": "xai/grok-4-0709",
      "model_name": "Grok 4 0709",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-4-latest",
      "model_slug": "xai/grok-4-latest",
      "model_name": "Grok 4 Latest",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_token": 0.000003,
      "input_cost_per_million": 3,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": false,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-beta",
      "model_slug": "xai/grok-beta",
      "model_name": "Grok Beta",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    },
    {
      "model_id": "grok-vision-beta",
      "model_slug": "xai/grok-vision-beta",
      "model_name": "Grok Vision Beta",
      "provider_id": "xai",
      "provider_name": "xAI",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_token": 0.000005,
      "input_cost_per_million": 5,
      "output_cost_per_token": 0.000015,
      "output_cost_per_million": 15,
      "cache_read_cost_per_token": null,
      "cache_read_cost_per_million": null,
      "cache_write_cost_per_token": null,
      "cache_write_cost_per_million": null,
      "supports_function_calling": true,
      "supports_vision": true,
      "supports_json_mode": false,
      "supports_parallel_functions": false,
      "supports_streaming": true,
      "model_type": "chat",
      "deprecation_date": null
    }
  ]
}