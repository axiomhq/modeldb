import type { Model } from '../../src/schema';

export const testModels: Model[] = [
  {
    model_id: 'gpt-4',
    model_name: 'GPT-4',
    provider_id: 'openai',
    provider_name: 'OpenAI',
    model_type: 'chat',
    max_input_tokens: 8192,
    max_output_tokens: 4096,
    input_cost_per_token: 0.00003,
    input_cost_per_million: 30,
    output_cost_per_token: 0.00006,
    output_cost_per_million: 60,
    cache_read_cost_per_token: null,
    cache_read_cost_per_million: null,
    cache_write_cost_per_token: null,
    cache_write_cost_per_million: null,
    supports_function_calling: true,
    supports_vision: false,
    supports_json_mode: true,
    supports_parallel_functions: true,
    deprecation_date: null,
  },
  {
    model_id: 'gpt-4-vision-preview',
    model_name: 'GPT-4 Vision Preview',
    provider_id: 'openai',
    provider_name: 'OpenAI',
    model_type: 'chat',
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 0.00001,
    input_cost_per_million: 10,
    output_cost_per_token: 0.00003,
    output_cost_per_million: 30,
    cache_read_cost_per_token: null,
    cache_read_cost_per_million: null,
    cache_write_cost_per_token: null,
    cache_write_cost_per_million: null,
    supports_function_calling: true,
    supports_vision: true,
    supports_json_mode: true,
    supports_parallel_functions: true,
    deprecation_date: null,
  },
  {
    model_id: 'claude-3-opus',
    model_name: 'Claude 3 Opus',
    provider_id: 'anthropic',
    provider_name: 'Anthropic',
    model_type: 'chat',
    max_input_tokens: 200000,
    max_output_tokens: 4096,
    input_cost_per_token: 0.000015,
    input_cost_per_million: 15,
    output_cost_per_token: 0.000075,
    output_cost_per_million: 75,
    cache_read_cost_per_token: 0.0000015,
    cache_read_cost_per_million: 1.5,
    cache_write_cost_per_token: 0.00001875,
    cache_write_cost_per_million: 18.75,
    supports_function_calling: true,
    supports_vision: true,
    supports_json_mode: false,
    supports_parallel_functions: false,
    deprecation_date: null,
  },
  {
    model_id: 'text-embedding-ada-002',
    model_name: 'Text Embedding Ada 002',
    provider_id: 'openai',
    provider_name: 'OpenAI',
    model_type: 'embedding',
    max_input_tokens: 8192,
    max_output_tokens: null,
    input_cost_per_token: 0.0000001,
    input_cost_per_million: 0.1,
    output_cost_per_token: 0,
    output_cost_per_million: 0,
    cache_read_cost_per_token: null,
    cache_read_cost_per_million: null,
    cache_write_cost_per_token: null,
    cache_write_cost_per_million: null,
    supports_function_calling: false,
    supports_vision: false,
    supports_json_mode: false,
    supports_parallel_functions: false,
    deprecation_date: null,
  },
  {
    model_id: 'gpt-3.5-turbo-0301',
    model_name: 'GPT-3.5 Turbo 0301',
    provider_id: 'openai',
    provider_name: 'OpenAI',
    model_type: 'chat',
    max_input_tokens: 4096,
    max_output_tokens: 4096,
    input_cost_per_token: 0.0000015,
    input_cost_per_million: 1.5,
    output_cost_per_token: 0.000002,
    output_cost_per_million: 2,
    cache_read_cost_per_token: null,
    cache_read_cost_per_million: null,
    cache_write_cost_per_token: null,
    cache_write_cost_per_million: null,
    supports_function_calling: false,
    supports_vision: false,
    supports_json_mode: false,
    supports_parallel_functions: false,
    deprecation_date: '2024-06-13',
  },
  {
    model_id: 'gemini-pro',
    model_name: 'Gemini Pro',
    provider_id: 'google',
    provider_name: 'Google',
    model_type: 'chat',
    max_input_tokens: 32760,
    max_output_tokens: 8192,
    input_cost_per_token: 0.00000125,
    input_cost_per_million: 1.25,
    output_cost_per_token: 0.00000375,
    output_cost_per_million: 3.75,
    cache_read_cost_per_token: null,
    cache_read_cost_per_million: null,
    cache_write_cost_per_token: null,
    cache_write_cost_per_million: null,
    supports_function_calling: true,
    supports_vision: false,
    supports_json_mode: true,
    supports_parallel_functions: false,
    deprecation_date: null,
  },
  {
    model_id: 'rerank-english-v2.0',
    model_name: 'Rerank English v2.0',
    provider_id: 'cohere',
    provider_name: 'Cohere',
    model_type: 'rerank',
    max_input_tokens: null,
    max_output_tokens: null,
    input_cost_per_token: 0.000001,
    input_cost_per_million: 1,
    output_cost_per_token: 0,
    output_cost_per_million: 0,
    cache_read_cost_per_token: null,
    cache_read_cost_per_million: null,
    cache_write_cost_per_token: null,
    cache_write_cost_per_million: null,
    supports_function_calling: false,
    supports_vision: false,
    supports_json_mode: false,
    supports_parallel_functions: false,
    deprecation_date: null,
  },
];

export const testModelMap: Record<string, Model> = Object.fromEntries(
  testModels.map((model) => [model.model_id, model])
);

export const testProviders = {
  openai: testModels.filter((m) => m.provider_id === 'openai'),
  anthropic: testModels.filter((m) => m.provider_id === 'anthropic'),
  google: testModels.filter((m) => m.provider_id === 'google'),
  cohere: testModels.filter((m) => m.provider_id === 'cohere'),
};
